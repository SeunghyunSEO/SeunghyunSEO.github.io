---
title: (미완)Recurrent Neural Network(RNN) Familiy 
categories: DeepLearning
tag: [tmp]

toc: true
toc_sticky: true
---

---
< 목차 >
{: class="table-of-content"}
* TOC
{:toc}
---

## <mark style='background-color: #fff5b1'> Recurrent Neural Network (RNN) </mark>

## <mark style='background-color: #fff5b1'> Vanilla RNN </mark>

## <mark style='background-color: #fff5b1'> Vanishing Gradient </mark>

## <mark style='background-color: #fff5b1'> Long Short Term Memory (LSTM) </mark>

## <mark style='background-color: #fff5b1'> Gated Recurrent Unit (GRU) </mark>




## <mark style='background-color: #fff5b1'> Furthur Study </mark>

## <mark style='background-color: #fff5b1'> Transformer </mark>




## <mark style='background-color: #fff5b1'> References </mark>

- Blog
  - [CS230 Cheating Sheet : Recurrent Neural Networks cheatsheet By Afshine Amidi and Shervine Amidi](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)
- Paper
  - [Long Short-Term Memory](https://direct.mit.edu/neco/article-pdf/9/8/1735/813796/neco.1997.9.8.1735.pdf)
  - [quence Labelling with Recurrent Neural Networks. Studies in Computational Intelligence](https://www.cs.toronto.edu/~graves/preprint.pdf)
  - [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/pdf/1406.1078)
  - [Recurrent Neural Network Regularization](https://arxiv.org/pdf/1409.2329)
  - [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](https://proceedings.neurips.cc/paper/2016/file/076a0c97d09cf1a0ec3e19c7f2529f2b-Paper.pdf)
  - [Attention Is All You Need](https://arxiv.org/pdf/1706.03762)
- Others
  - [DeepMind x UCL | Deep Learning Lectures | 6/12 | Sequences and Recurrent Networks](https://www.youtube.com/watch?v=87kLfzmYBy8)
  - [DeepMind x UCL | Deep Learning Lectures | 7/12 | Deep Learning for Natural Language Processing](https://www.youtube.com/watch?v=8zAP2qWAsKg)
  - [DeepMind x UCL | Deep Learning Lectures | 8/12 | Attention and Memory in Deep Learning](https://www.youtube.com/watch?v=AIiwuClvH6k)
