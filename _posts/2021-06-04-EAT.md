---
title: (Paper) EAT - Enhanced ASR-TTS for Self-supervised Speech Recognition
categories: Speech_Recognition
tag: [tmp]

toc: true
toc_sticky: true

comments: true
---


이번 글에서는 [EAT: Enhanced ASR-TTS for Self-supervised Speech Recognition](https://arxiv.org/pdf/2104.07474) 라는 논문을 요약해서 리뷰해 보려고 합니다. 


---
< 목차 >
{: class="table-of-content"}
* TOC
{:toc}
---


## <mark style='background-color: #fff5b1'> Problem Definition and Contibution Point </mark>

본 논문에서의 Problem 정의와 Contribution Point는 다음과 같습니다.

- 1.Self-Supervised `ASR-TTS` 모델이 가지는 단점은 out-of-domain 문제다. 
- 2.본 논문에서는 강화된 (Enhanced) ASR-TTS 모델을 제시하는데 이는 두 가지 feature가 결합된것이다.
  - a) ASR $$\rightarrow$$ TTS (Speech Only, `SO`) : 음성인식 (ASR)을 해서 얻은 문장을 가지고 TTS에 넣어서 다시 음성을 만들어내는데 이 때 Language Model (LM)이 ASR이 실제정답과 얼마나 틀린 문장을 뱉어냈는지를 추정해서 모델에 penalty를 준다.
  - b) TTS $$\rightarrow$$ ASR (Text Only, `TO`) : TTS가 만들어낸 음성을 기반으로 다시 ASR을 하는데 이 데이터는 out-of-domain 데이터 이므로 ASR모듈에 넣기 전에 attention context 를 scaling 하는 하이퍼 파라메터를 집어넣는다.
- 3.결과적으로 EAT는 Librispeech와 BABEL이라는 두개의 데이터셋에 대해서 supervised와 self-supervised 학습 방법론의 격차를 줄였다 



## <mark style='background-color: #fff5b1'> Enhanced ASR-TTS (EAT) </mark>

![eat_figure1](/assets/images/EAT/eat_figure1.png)



### <mark style='background-color: #dcffe4'> Adding a RNNLM penalty for regularization </mark>

### <mark style='background-color: #dcffe4'> Making TTS -> SR robust to out-of-domain </mark>

![eat_figure1](/assets/images/EAT/eat_figure2.png)

![eat_figure1](/assets/images/EAT/eat_figure3.png)

### <mark style='background-color: #dcffe4'> Improvements in architecture and training </mark>


## <mark style='background-color: #fff5b1'> Results and Discussion </mark>

![eat_table1](/assets/images/EAT/eat_table1.png)
![eat_table2](/assets/images/EAT/eat_table2.png)
![eat_table3](/assets/images/EAT/eat_table3.png)
![eat_table4](/assets/images/EAT/eat_table4.png)
![eat_table5](/assets/images/EAT/eat_table5.png)




## <mark style='background-color: #fff5b1'> Reference </mark>

- [EAT: Enhanced ASR-TTS for Self-supervised Speech Recognition](https://arxiv.org/pdf/2104.07474) 
