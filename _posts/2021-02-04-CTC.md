---
title: 2006, ICML, Connectionist Temporal Classification - Labelling Unsegmented Sequence Data With Recurrent Neural Networks
categories: Speech_Recognition
tag: [tmp]

toc: true
toc_sticky: true
---

- <mark style='background-color: #fff5b1'> Connectionist Temporal Classification, CTC </mark>

CTC는 무엇일까요? 간단하게 말해서 음성인식같은 task에서 입력이 되는 음성의 시퀀스길이와 출력이 되는(디코딩 되는) 받아쓰기(dictation)한 텍스트의 길이가 맞지 않아 발생하는 

Miss-Alignment 문제를 해결하기 위해 2006년 [Alex Graves](https://www.cs.toronto.edu/~graves/)라는 딥마인드의 세계적인 석학에 의해 2006년에 제안된 기법입니다.

![image](https://user-images.githubusercontent.com/48202736/106895390-7fcbfc80-6733-11eb-803c-da984525e0b2.png)
*Fig. 1. Alex Graves의 홈페이지에 있는 그의 사진*

그는 Toronto 대학 출신의, 세계적인 석학 [Geoffrey E. Hinton](http://www.cs.toronto.edu/~hinton/)의 제자이며, 


CTC 이외에도 ([A novel connectionist system for unconstrained handwriting recognition](PDF), OCR논문), ([Practical Variational Inference for Neural Networks](https://www.cs.toronto.edu/~graves/nips_2011.pdf), 베이지안 방법론에 쓰이는 VI), ([Sequence transduction with recurrent neural networks](https://arxiv.org/pdf/1211.3711), E2E음성인식의 모델의 큰 축 중 하나인 RNN Transducer), ([Generating sequences with recurrent neural networks](https://arxiv.org/pdf/1308.0850)), ([Towards End-To-End Speech Recognition with Recurrent Neural Networks](http://proceedings.mlr.press/v32/graves14.pdf)) 등등의 굵직한 음성인식(ASR), 활자인식(OCR) 논문에 참여 (아니 혼자 쓴 논문이 많아서 혼자 만들었다고 해야하나... CTC도 혼자쓰셨다...)하거나 


음성 합성 ([Wavenet: A generative model for raw audio](https://arxiv.org/pdf/1609.03499)), ([Parallel wavenet: Fast high-fidelity speech synthesis](https://arxiv.org/pdf/1711.10433)) 논문들, 


그리고 굵직한 강화학습 논문들 ([Playing atari with deep reinforcement learning](https://arxiv.org/pdf/1312.5602)), ([Human-level control through deep reinforcement learning](https://www.nature.com/articles/nature14236)) 에도 참여하는 등 굵직한 업적을 남기고 있습니다...(정말 대단합니다)


아무튼 CTC는 그가 쓴 논문들에서도 알 수 있다 싶이, 음성인식, 활자인식 등에서 출력값을 어떻게 align 해서 뽑을거냐를 해결한 방법론이고, 

음성인식에서는 아직까지도 크게 CTC, 즉 CTC loss를 통해서 시퀀스 모델링을 했느냐, 아니면 Attentio Mechanism을 사용한 Seq2Seq(Encoder-Decoder 계열) 했느냐로 
나눠서 생각할 정도로 영향력이 어마어마한 논문입니다. (+ RNN Transducer) 


자 이제 그럼 앞으로, 언급햇던 Miss Alignment 문제가 무엇인지, 그리고 CTC가 무엇인지에 대해서 깊이 파고들어가 보도록 하겠습니다.

- <mark style='background-color: #fff5b1'> Miss Alignment Problem </mark>

- <mark style='background-color: #fff5b1'> Sequence Generation Task </mark>

- <mark style='background-color: #dcffe4'> Automatic Speech Recognition (ASR) </mark> 

- <mark style='background-color: #dcffe4'> Optical Character Recognition(OCR) </mark>

- <mark style='background-color: #fff5b1'> CTC </mark>

- <mark style='background-color: #fff5b1'> CTC의 단점 </mark>

- <mark style='background-color: #fff5b1'> Seq2Seq with Attention </mark>

- <mark style='background-color: #fff5b1'> Hybrid Model </mark>

- <mark style='background-color: #fff5b1'> References </mark>

- 1.[Attention in end-to-end Automatic Speech Recognition](https://medium.com/intel-student-ambassadors/attention-in-end-to-end-automatic-speech-recognition-9f9e42718d21)

- 2.[An Intuitive Explanation of Connectionist Temporal Classification]()

- 3.[Distill Blog : Sequence Modeling With CTC](https://distill.pub/2017/ctc/)

- 4.[Multi-Digit Sequence Recognition With CRNN and CTC Loss Using PyTorch Framework](https://medium.com/swlh/multi-digit-sequence-recognition-with-crnn-and-ctc-loss-using-pytorch-framework-269a7aca2a6)

- 5.[ Natural Language Processing with Deep Learning CS224N/Ling284 - Lecture 12: End-to-end models for Speech Processing](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1174/lectures/cs224n-2017-lecture12.pdf)

- 6.[]()

