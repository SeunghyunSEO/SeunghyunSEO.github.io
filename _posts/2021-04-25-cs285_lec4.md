---
title: (미완) Lecture 4 - Introduction to Reinforcement Learning

categories: CS285
tag: [RL]

toc: true
toc_sticky: true
---


이 글은 UC Berkeley 의 심층 강화 학습 (Deep Reinforcement Learning) 강의인 [CS285](http://rail.eecs.berkeley.edu/deeprlcourse/)를 듣고 기록하기 위해 작성한 글 입니다. 
강의 자료가 잘 구성되어 있으며, 강화학습 분야의 세계적인 석학인 [Sergey Levine](http://people.eecs.berkeley.edu/~svlevine/)의 강의 흐름을 그대로 따라가는게 낫겠다고 생각하여 슬라이드들을 그대로 사용해서 글을 전개하려고 합니다. (강의를 들으면서 가능하다면 이해를 돕기 위해 추가 자료를 중간 중간 첨부할 예정입니다.)


Lecture 4의 강의 영상과 자료는 아래에서 확인하실 수 있습니다. 
- [Lecture Video Link (Youtube)](https://www.youtube.com/watch?v=jds0Wh9jTvE&list=PL_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc&index=11)
- [Lecture Slide Link](http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-4.pdf)


---
< 목차 >
{: class="table-of-content"}
* TOC
{:toc}
---

이번 강의의 주제는 "Introduction to Reinforcement Learning" 입니다. 본격적으로 강화 학습이 무엇인지에 대한 정의와 컨셉에 대해서 알아보는 챕터 입니다. 

![slide1](/assets/images/CS285/lec-4/slide1.png)
*Slide. 1.*


## <mark style='background-color: #fff5b1'> Definitions </mark>

2장에서 배웠던 걸 다시 생각해 보도록 하겠습니다.

![slide3](/assets/images/CS285/lec-4/slide3.png)
*Slide. 3.*

다 익숙한 `notation`과 `teminology`들 일거라 생각하고 넘어가겠습니다. 강화학습의 목표는 `정책 (Policy)` $$\pi_{\theta}(a_t \vert s_t)$$를 학습하는 것 입니다. 심층 강화학습 에서는 이 정책이 `심층 신경망 (Deep Neural Network)`으로 디자인 되어 있으며, 이러한 정책을 하는 방법은 크게 두 가지로 나눌 수 있습니다.

- policy를 directly 하는 방법 
- 다른 가치 함수 (Value Function) 같은 Object를 통해 implicitly 학습하는 방법

이러한 방법론들에 대해서 앞으로 알아보게 될겁니다.

![slide4](/assets/images/CS285/lec-4/slide4.png)
*Slide. 4.*



![slide5](/assets/images/CS285/lec-4/slide5.png)
*Slide. 5.*


![slide6](/assets/images/CS285/lec-4/slide6.png)
*Slide. 6.*

![slide7](/assets/images/CS285/lec-4/slide7.png)
*Slide. 7.*


![slide8](/assets/images/CS285/lec-4/slide8.png)
*Slide. 8.*

![slide9](/assets/images/CS285/lec-4/slide9.png)
*Slide. 9.*

![slide10](/assets/images/CS285/lec-4/slide10.png)
*Slide. 10.*

![slide11](/assets/images/CS285/lec-4/slide11.png)
*Slide. 11.*

![slide12](/assets/images/CS285/lec-4/slide12.png)
*Slide. 12.*

![slide13](/assets/images/CS285/lec-4/slide13.png)
*Slide. 13.*

![slide14](/assets/images/CS285/lec-4/slide14.png)
*Slide. 14.*


![slide15](/assets/images/CS285/lec-4/slide15.png)
*Slide. 15.*

![slide16](/assets/images/CS285/lec-4/slide16.png)
*Slide. 16.*







## <mark style='background-color: #fff5b1'> Algorithms </mark>

![slide18](/assets/images/CS285/lec-4/slide18.png)
*Slide. 18.*

![slide19](/assets/images/CS285/lec-4/slide19.png)
*Slide. 19.*

![slide20](/assets/images/CS285/lec-4/slide20.png)
*Slide. 19.*

![slide21](/assets/images/CS285/lec-4/slide21.png)
*Slide. 21.*







## <mark style='background-color: #fff5b1'> Value Functions </mark>


![slide23](/assets/images/CS285/lec-4/slide23.png)
*Slide. 23.*

![slide24](/assets/images/CS285/lec-4/slide24.png)
*Slide. 24.*

![slide25](/assets/images/CS285/lec-4/slide25.png)
*Slide. 25.*

![slide26](/assets/images/CS285/lec-4/slide26.png)
*Slide. 26.*






## <mark style='background-color: #fff5b1'> Types of Algorithms </mark>

![slide28](/assets/images/CS285/lec-4/slide28.png)
*Slide. 28.*

![slide29](/assets/images/CS285/lec-4/slide29.png)
*Slide. 29.*

![slide30](/assets/images/CS285/lec-4/slide30.png)
*Slide. 30.*

![slide31](/assets/images/CS285/lec-4/slide31.png)
*Slide. 31.*

![slide32](/assets/images/CS285/lec-4/slide32.png)
*Slide. 32.*

![slide33](/assets/images/CS285/lec-4/slide33.png)
*Slide. 33.*






### <mark style='background-color: #dcffe4'> Tradeoffs Between Algorithms </mark>

![slide35](/assets/images/CS285/lec-4/slide35.png)
*Slide. 35.*

![slide36](/assets/images/CS285/lec-4/slide36.png)
*Slide. 36.*

![slide37](/assets/images/CS285/lec-4/slide37.png)
*Slide. 37.*

![slide38](/assets/images/CS285/lec-4/slide38.png)
*Slide. 38.*

![slide39](/assets/images/CS285/lec-4/slide39.png)
*Slide. 39.*

![slide40](/assets/images/CS285/lec-4/slide40.png)
*Slide. 40.*






### <mark style='background-color: #dcffe4'> Examples of Algorithms </mark>

![slide42](/assets/images/CS285/lec-4/slide42.png)
*Slide. 42.*

![slide43](/assets/images/CS285/lec-4/slide43.png)
*Slide. 43.*

![slide44](/assets/images/CS285/lec-4/slide44.png)
*Slide. 44.*

![slide45](/assets/images/CS285/lec-4/slide45.png)
*Slide. 45.*

![slide46](/assets/images/CS285/lec-4/slide46.png)
*Slide. 46.*








## <mark style='background-color: #fff5b1'> Reference </mark>

- [CS 285 at UC Berkeley : Deep Reinforcement Learning](http://rail.eecs.berkeley.edu/deeprlcourse/)














