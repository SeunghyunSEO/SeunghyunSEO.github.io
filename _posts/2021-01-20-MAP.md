---
title: Maximum A Posterior, MAP
categories: MachineLearning
tag: [MachineLearning,ML]

toc: true
toc_sticky: true

comments: true
---

- <mark style='background-color: #fff5b1'> 최대사후확률 (Maximum A Posterior)란 무엇인가? </mark>

지난 글에서 ML에 대해서 간단하게 살펴봤습니다. 이제 MAP에 대해서 이야기해보도록 하겠습니다. 

마찬가지로 다음의 수식과 정의에 대해서 익숙해지셔야 합니다. 

> 1. $$likelihood : p(x\mid\theta)$$ <br>
> 2. $$posterior \propto likelihood \times prior : p(\theta \mid x) \propto p(x \mid \theta)p(\theta)$$ <br> 



- <mark style='background-color: #fff5b1'> MAP </mark>

지난 글에서 ML의 문제점에 대해 이야기하면서 MAP를 잠깐 언급했었습니다.

![mles](https://user-images.githubusercontent.com/48202736/106449796-b271bd00-64c7-11eb-8ea0-782819ef999a.png)
{: style="width: 60%;" class="center"}

ML에서 한발 더 나아가 likelihood에 prior를 곱해 파라메터의 값들에 대한 정보를 주어 posterior를 구하고 이것을 maximize하는 단 하나의 솔루션을 구하는게 MAP 라고 할 수 있습니다.

이럴 경우 MAP는 데이터가 적을 때는 prior의 영향력이 커서 추정 값이 너무 편향되지 않게 잡아주고, 데이터가 많을 경우에는 likelihood의 영향력이 커져 결국 데이터로부터 얻은 정보를 최대한 활용하게 된다고 볼 수 있는 장점이 있습니다.


좀 더 와닿게 예를 들어보자면, 멀쩡하게 생긴 동전을 세 번 던졌는데, 세 번 다 앞면이 나온 경우를 생각해봅시다. MLE를 통해 추론하게 되면 앞면이 나올 확률이 1이라는 베르누이 분포를 가지고 추론하기 때문에 미래의 모든 동전 던지기에 대해서 앞면이라고 예측하게 될 겁니다. 하지만 우리는 동전 던지기가 그렇지 않다는 것을 압니다. 이럴 경우 사전 확률을 통해서 어느정도 likelihood를 보정해주게 된다면 그렇지 않게되겠죠?

바로 맨처음에 언급했던 

$$posterior \propto likelihood \times prior : p(\theta \mid x) \propto p(x \mid \theta)p(\theta)$$

식을 통해 posterior를 고려하면 결과는 더 합리적으로? 바뀔 수 있다는 겁니다.


위의 수식에 대한 이해를 돕기위해 그림을 첨부했습니다. 
아래를 보시면 맨 오른쪽에 있는 posterior는 likelihood와 prior를 곱한 것의 분포입니다.

![22](https://user-images.githubusercontent.com/48202736/106450161-29a75100-64c8-11eb-99ac-feabe70c6b03.png)

한눈에 봐도 likelihood 분포에서 peak를 찍는것과 posterior에서 peak를 찍는 것은 달라보입니다.
(이는 나중에 설명하겠지만 데이터 개수가 적을수록 확연히 달라집니다.)


- <mark style='background-color: #fff5b1'> Prior란? </mark>

prior는 말그대로 사전 지식입니다. 이전에 ML에는 prior가 없었는데 prior가 있다는 것의 의미는 무엇일까요? 바로 추정하고자 하는 파라메터(가우시안의 경우 mean, variance)에 대해서 '실험은 안해봤지만 그냥 일반적으로 보니까 mean,variance가 값이 1일 확률이 가장 높던데?' 같은 정보를 주는겁니다. prior는 바로 (추정하고자 하는 확률 분포의)파라메터에 대한 사전 확률 분포(데이터를 보기 전에 임의로 주는)인거죠.


이때 likelihood가 Normal Distribution(가우시안 분포)를 따른다면 prior로는 conjugate distribution인 Normal Inverse Gamma Distribution을 따르는 것이 좋습니다.
왜냐면 아래의 수식처럼 둘을 곱할건데 conjugate family인 분포로 모델링을 하게 되면 수학적으로 굉장히 쉽게 계산이 되기 때문이죠.



$$posterior \propto likelihood \times prior : p(\theta \mid x) \propto p(x \mid \theta)p(\theta)$$


Univarite Normal Distribution (Gaussian Distribution)의 수식과 그림

![normal](https://user-images.githubusercontent.com/48202736/106450499-9d495e00-64c8-11eb-9472-cae56f6e0cbf.png)
{: style="width: 60%;" class="center"}

![normal2](https://user-images.githubusercontent.com/48202736/106450504-9e7a8b00-64c8-11eb-8e56-16af4a74b875.png)
{: style="width: 60%;" class="center"}

Normal Inverse Gamma Distribution의 수식과 그림

![inverse1](https://user-images.githubusercontent.com/48202736/106450512-9fabb800-64c8-11eb-9809-1a2a9884288c.png)

![inverse2](https://user-images.githubusercontent.com/48202736/106450520-a0dce500-64c8-11eb-9161-2b267899e409.png)
{: style="width: 70%;" class="center"}

위의 두 분포는 Conjugate Distributions입니다.



- <mark style='background-color: #fff5b1'> ML vs MAP </mark>



maximum likelihood를 사용하는 빈도적 확률 관점(frequent) 과 prior를 추가해 posterior를 사용하는 베이지안 확률 관점(MAP가 bayes' rule에서 기인함) 중 어떤 것이 더 상대적으로 우수한지에 대해서는 끊임없이 논쟁이 있다고 합니다. 


여기서 베이지안 접근법에 대해 널리 알려진 비판 중 하나는 바로 사전 분포가 실제 사전의 믿음을 반영하기 보다는 수학적인 편리성을 위해 선택하는 것이 아니냐 라는 것이라고 합니다.


위에서 말한 prior를 likelihood의 conjugate distribution으로 설정하는것이 주관이 포함된게 아니냐는 것인데, 
그렇기 때문에 MAP, bayesian을 사용할 때 Jeffreys Prior 등의 주관이 들어가지 않은, 무정보적(non-informative) prior를 사용하기도 한다고 합니다. 


- <mark style='background-color: #fff5b1'> 수식으로 보는 MAP </mark>

사족이 많았는데, 이제 수식으로 MAP를 알아보도록 하겠습니다.
우리가 하고 싶은것은 posterior를 maximize 하는 것입니다.

<center>$$\hat{\Theta}=argmax_\theta[Pr(\theta \mid x_{1...I})]$$</center>

여기서 잘 알려진 Bayes' Rule을 사용하면 다음과 같이 나타낼 수 있습니다.

<center>$$Pr(\theta \mid x_{1...I})=\frac{Pr(x_{1...I} \mid \theta)Pr(\theta)}{Pr(x_{1...I})}$$</center>

<center>$$\hat{\Theta}=argmax_\theta[\frac{Pr(x_{1...I} \mid \theta)Pr(\theta)}{Pr(x_{1...I})}]$$</center>

<center>$$\hat{\Theta}=argmax_\theta[\frac{\prod_{i=1}^{I}Pr(x_i \mid \theta)Pr(\theta)}{Pr(x_{1...I})}]$$</center>

여기서 분모에 있는 것은 Evidence 라고도 하는데, 우리가 추정하고자 하는 파라메터와 관련이 없으므로 떼어놓고 생각할 수 있습니다.

<center>$$\hat{\Theta}=argmax_\theta[ {\prod_{i=1}^{I} Pr(x_i \mid \theta) Pr(\theta)} ]$$</center>

- <mark style='background-color: #fff5b1'> MAP solution </mark>

이제 ML solution을 구한것과 마찬가지로 가우시안 분포를 피팅하는 경우에 대한 MAP solution을 구해보도록 하겠습니다.

<center>$$\hat{\Theta}=argmax_\theta[ {\prod_{i=1}^{I} Pr(x_i \mid \theta) Pr(\theta)} ]$$</center>

likelihood는 다음의 가우시안 분포를 따르고

<center>$$Pr(x\mid\mu,\sigma^2)=Norm_x[\mu,\sigma^2]=\frac{1}{\sqrt{2\pi\sigma^2}}exp[-0.5\frac{(x-\mu)^2}{\sigma^2}]$$</center> 

prior는 다음의 Normal inverse gamma 분포를 따릅니다.

<center>$$Pr(\mu,\sigma^2) = NormInvGam_{\mu,\sigma^2}[\alpha, \beta, \gamma, \delta]$$</center> 

<center>$$Pr(\mu,\sigma^2) = \frac{sqrt{\gamma}}{\alpha\sqrt{2\pi}} \frac{\beta^{\alpha}}{\Gamma[\alpha]}(\frac{1}{sigma^2})^{\alpha+1}exp[-\frac{2\beta+\gamma(\delta-\mu)^2}{2\sigma^2}]$$</center> 


그러므로 사후 확률은 다음과 같이 계산할 수 있습니다.


<center>$$\hat{\mu},\hat{\sigma^2}=argmax_{\mu,\sigma^2}[posterior]$$</center>

<center>$$\hat{\mu},\hat{\sigma^2}=argmax_{\mu,\sigma^2}[likelihood \times prior]$$</center>

<center>$$\hat{\mu},\hat{\sigma^2}=argmax_{\mu,\sigma^2}[\prod_{i=1}^{I}Pr(x_{i}\mid\mu,\sigma^2)Pr(\mu,\sigma^2)]$$</center>

<center>$$\hat{\mu},\hat{\sigma^2}=argmax_{\mu,\sigma^2}[\prod_{i=1}^{I}Norm_{x_i}[\mu,\sigma^2]NormInvGam_{\mu,\sigma^2}[\alpha,\beta,\gamma,\delta]]$$</center>

ML때와 마찬가지로 log를 취해 maximize해도 원래의 식을 maximize하는것과 다름 없기 때문에 계산상의 편의를 위해 log를 취합니다.

<center>$$\hat{\mu},\hat{\sigma^2}=argmax_{\mu,\sigma^2}[\sum_{i=1}^{I}log[Norm_{x_i}[\mu,\sigma^2]]+log[NormInvGam_{\mu,\sigma^2}[\alpha,\beta,\gamma,\delta]]]$$</center>

(위에서는 그대로 log 때문에 두 분포가 분리되는 것처럼 보이는데, 이 두 분포는 conjugate distribution 이기 때문에 $$ [Gaussian] \times [Normal Inverse Gamma] = 새로운 [Normal Inverse Gamma]$$가 되고 그에 대해서 구해도 됩니다. )

(혹은 likelihood의 각각의 mean의 파라메터, variance의 파라메터에 대해서 따로 사전분포를 정해줄 수도 있습니다. 각각에 대해 가우시안 분포를 사전확률로 주면 ... 복잡해집니다)

이제 미분을 취해 값을 0 으로 두고 그 때의 평균, 분산 값을 구하면 됩니다.

<center>$$ \hat{\mu} = \frac{\sum_{i=1}x_i+\gamma\delta}{I+\gamma} $$</center>

<center>$$ \hat{\mu} = \frac{I\bar{x}+\gamma\delta}{I+\gamma} $$</center>

마찬가지로 sigma에 대해서도 구할 수 있습니다.

- <mark style='background-color: #fff5b1'> 다시 ML vs MAP </mark>

사후확률을 최대화 하는것은 데이터로부터 얻은 정보와, '파라메터가 사실은 어떤 값을 가질 확률이 어떻게 된다'라는 사전 정보 (혹은 주관적인? 믿음)을 고려해 파라메터를 최적화 한 것이기 때문에 ML과 결과가 다릅니다.

아래의 그림에서 보시면 데이터 개수가 많아지면 MAP와 ML 이 굉장히 유사한 것을 볼 수 있고 (likelihood가 prior를 압도함)

데이터가 적을 때는 다른 것을 볼 수 있습니다. (덜 편향됐을 가능성이 높습니다.)

![mle_vs_map](https://user-images.githubusercontent.com/48202736/106448976-d254b100-64c6-11eb-8216-fc5ffdef5828.png)

+ 그리고 데이터가 많아지면 많이질수록 posterior 분포의 크기가 줄어드는 것을 알 수 있습니다. (굉장히 날카로워짐)


극단적으로 데이터가 엄청 많다고 생각하면 거의 하나의 점이 될 테고 그럴 때는 MAP로 구한 파라메터나, 점 같은 분포에서 아무거나 찍어 뽑은 파라메터나 비슷하게 될 것입니다.  


- <mark style='background-color: #fff5b1'> Bayesian? </mark>

베이지안은 그렇다면 MAP, ML과는 또 어떤 차이가 있을까요?

다음 그림을 보면 쉽게 알 수 있습니다.

![bayesian vs map](https://user-images.githubusercontent.com/48202736/106450353-6a9f6580-64c8-11eb-8e09-a80b0fc260ae.png)

MAP는 최대 사후 확률이라는 뜻에서도 알 수 있듯이 사후확률이 최대가 되는 파라메터 하나만 구하게 되는 것인데, (영어로도 maximum 'A' posterior)

베이지안 방법은 사후확률 분포를 구하고 나서 가능한 파라메터(예시로 들었던 경우를 생각하면 mean,variance)에 대해서 모두 고려하여(적분하여) 사용하겠다는 것입니다.

위의 그림에서 posterior로 부터 샘플링한 분포를 보여주는 (b)의 파란색 선들은 일부만 보여준 것이고, 원래는 모든 구간에 대해서 적분을하게 됩니다.


당연히 계산상으로 이슈가 있다거나 하는 문제가 있을겁니다.

이는 다음 글에서 설명해보도록 하겠습니다.


- <mark style='background-color: #fff5b1'> References </mark>

1. [Prince, Simon JD. Computer vision: models, learning, and inference. Cambridge University Press, 2012.](http://www.computervisionmodels.com/)

2. [Bishop, Christopher M. Pattern recognition and machine learning. springer, 2006.](https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/)
