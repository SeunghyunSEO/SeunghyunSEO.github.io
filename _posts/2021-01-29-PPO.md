---
title: 2017, Proximal Policy Optimization Algorithms
categories: Deep_Reinforcement_Learning_Paper_Review
tag: [DeepLearning]

toc: true
toc_sticky: true
---

- <mark style='background-color: #fff5b1'> Proximal Policy Optimization Algorithms (PPO) </mark>

```
Proximal Policy Optimization Algorithms
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov
OpenAI
{joschu, filip, prafulla, alec, oleg}@openai.com
```

이 논문은 2017년에 OpenAI에서 공개된 논문으로 입니다. 어떻게 하면 Policy Optimization을 잘 할 수 있는가에 대한 내용으로 굉장히 유명한 논문이라고 합니다.

사실 제가 딥러닝 연구를 하면서 항상 심층 강화 학습 (Deep Reinforcement Learning)에 대해 흥미가 있어 따로 공부를 하거나 프로젝트를 진행해보고 싶었지만 따로 시간을 내기가 .
그래서 이제부터는 심층 강화 학습 분야의 굵직한 논문들을 최대한 디테일하게 리뷰하면서 



- <mark style='background-color: #fff5b1'> 0. Abstract </mark>


- <mark style='background-color: #fff5b1'> 1. Introduction </mark>


- <mark style='background-color: #fff5b1'> 2. Background: Policy Optimization </mark>


- <mark style='background-color: #dcffe4'> Policy Gradient Methods </mark>
  
<center>$$ \hat{g} = \E $$</center>
  
  
- <mark style='background-color: #dcffe4'> Trust Region Methods </mark>


- <mark style='background-color: #fff5b1'> 3. Clipped Surrogate Objective </mark>


- <mark style='background-color: #fff5b1'> 4. Adaptive KL Penalty Coefficient </mark>


- <mark style='background-color: #fff5b1'> 5. Algorithm </mark>


- <mark style='background-color: #fff5b1'> 6. Experiments </mark>


- <mark style='background-color: #fff5b1'> 7. Conclusion </mark>
