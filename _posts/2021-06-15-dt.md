---
title: (yet) Decision Transformer, Reinforcement Learning via Sequence Modeling
categories: Reinforcement_Learning_and_Deep_Reinforcement_Learning
tag: [RL]

toc: true
toc_sticky: true
---

---
< 목차 >
{: class="table-of-content"}
* TOC
{:toc}
---



## <mark style='background-color: #fff5b1'> Problem Definition and Contribution Points </mark>

![dt_paper_figure1](/assets/images/dt/dt_paper_figure1.png)
*Fig.*



## <mark style='background-color: #fff5b1'> What is Transformer? </mark>

![lilian_transformer1](/assets/images/dt/lilian_transformer1.png)
*Fig.*

### <mark style='background-color: #dcffe4'> Self-Attention </mark>

![ucl_deepmind_transformer1](/assets/images/dt/ucl_deepmind_transformer1.png)
*Fig.*

![ucl_deepmind_transformer2](/assets/images/dt/ucl_deepmind_transformer2.png)
*Fig.*

![ucl_deepmind_transformer3](/assets/images/dt/ucl_deepmind_transformer3.png)
*Fig.*

### <mark style='background-color: #dcffe4'> RNN vs CNN vs Transformer </mark>

![ucl_deepmind_transformer4](/assets/images/dt/ucl_deepmind_transformer4.png)
*Fig.*

### <mark style='background-color: #dcffe4'> Seq2Seq with RNN vs Transformer  </mark>


![rnn_seq2seq](/assets/images/dt/rnn_seq2seq.png)
*Fig.*

![EncoderDecoder](/assets/images/dt/EncoderDecoder.png)
*Fig.*

![EncoderDecoder_step_by_step](/assets/images/dt/EncoderDecoder_step_by_step.png)
*Fig.*

![encoder_decoder_detail](/assets/images/dt/encoder_decoder_detail.png)
*Fig.*






## <mark style='background-color: #fff5b1'> Why Transformer? </mark>

### <mark style='background-color: #dcffe4'> Can We Train Decoder-Only Model? </mark>

![decoder_only](/assets/images/dt/decoder_only.png)
*Fig.*

![gpt](/assets/images/dt/gpt.png)
*Fig.*

![dalle](/assets/images/dt/dalle.png)
*Fig.*

![dalle2](/assets/images/dt/dalle2.png)
*Fig.*

![dalle3](/assets/images/dt/dalle3.png)
*Fig.*

### <mark style='background-color: #dcffe4'> GPT (v.1~3) and DALL-E from OpenAI</mark>

![gpt3](/assets/images/dt/gpt3.png)
*Fig.*

![gpt_and_dalle](/assets/images/dt/gpt_and_dalle.png)
*Fig.*

## <mark style='background-color: #fff5b1'> RL Problem </mark>

![dt_paper_figure2](/assets/images/dt/dt_paper_figure2.png)
*Fig.*





## <mark style='background-color: #fff5b1'> Decision Transformer </mark>

![dt_paper_figure1](/assets/images/dt/dt_paper_figure1.png)
*Fig.*


![dt_paper_figure3](/assets/images/dt/dt_paper_figure3.png)
*Fig.*

![lilian_sinoidual-positional-encoding](/assets/images/dt/lilian_sinoidual-positional-encoding.png)
*Fig.*




## <mark style='background-color: #fff5b1'> Experiment </mark>

### <mark style='background-color: #dcffe4'> Model Setting </mark>

![dt_paper_figure14](/assets/images/dt/dt_paper_figure14.png)
*Fig.*
![dt_paper_figure15](/assets/images/dt/dt_paper_figure15.png)
*Fig.*
![dt_paper_figure16](/assets/images/dt/dt_paper_figure16.png)
*Fig.*





### <mark style='background-color: #dcffe4'> Results </mark>

![dt_paper_figure4](/assets/images/dt/dt_paper_figure4.png)
*Fig.*
![dt_paper_figure5](/assets/images/dt/dt_paper_figure5.png)
*Fig.*
![dt_paper_figure6](/assets/images/dt/dt_paper_figure6.png)
*Fig.*
![dt_paper_figure7](/assets/images/dt/dt_paper_figure7.png)
*Fig.*
![dt_paper_figure8](/assets/images/dt/dt_paper_figure8.png)
*Fig.*
![dt_paper_figure9](/assets/images/dt/dt_paper_figure9.png)
*Fig.*
![dt_paper_figure10](/assets/images/dt/dt_paper_figure10.png)
*Fig.*
![dt_paper_figure11](/assets/images/dt/dt_paper_figure11.png)
*Fig.*
![dt_paper_figure12](/assets/images/dt/dt_paper_figure12.png)
*Fig.*
![dt_paper_figure13](/assets/images/dt/dt_paper_figure13.png)
*Fig.*





## <mark style='background-color: #fff5b1'> References </mark>

- Blog
  - [The Transformer Family](https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html)
  - [Transformers-based Encoder-Decoder Models](https://huggingface.co/blog/encoder-decoder)
- Paper
- Others
