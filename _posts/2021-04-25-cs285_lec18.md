---
title: (미완) Lecture 18 - Variational Inference and Generative Models

categories: CS285
tag: [RL]

toc: true
toc_sticky: true
---


이 글은 UC Berkeley 의 심층 강화 학습 (Deep Reinforcement Learning) 강의인 [CS285](http://rail.eecs.berkeley.edu/deeprlcourse/)를 듣고 기록하기 위해 작성한 글 입니다. 
강의 자료가 잘 구성되어 있으며, 강화학습 분야의 세계적인 석학인 [Sergey Levine](http://people.eecs.berkeley.edu/~svlevine/)의 강의 흐름을 그대로 따라가는게 낫겠다고 생각하여 슬라이드들을 그대로 사용해서 글을 전개하려고 합니다. (강의를 들으면서 가능하다면 이해를 돕기 위해 추가 자료를 중간 중간 첨부할 예정입니다.)


Lecture 18의 강의 영상과 자료는 아래에서 확인하실 수 있습니다. 
- [Lecture Video Link (Youtube)](https://www.youtube.com/watch?v=UTMpM4orS30&list=PL_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc&index=79)
- [Lecture Slide Link](http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-18.pdf)

---
< 목차 >
{: class="table-of-content"}
* TOC
{:toc}
---

![slide1](/assets/images/CS285/lec-18/slide1.png)
*Slide. 1.*

이번 강의에서 다루게 될 내용은 새로운 강화 학습 알고리즘 아니지만 강화 학습과 깊은 관련이 있는(있을) 변분 추론 (Variational Inference) 과 확률적 생성 모델 (Probabilistic Generative Models) 이라고 합니다. 변분 추론은 앞으로도 계속 등장할 것인데 Model-Based RL, Inverse RL(앞으로 배울거임), exploration 등등 가릴 것 없이 중요하게 쓰일 개념이라고 합니다. 목차는 아래와 같습니다.

![slide2](/assets/images/CS285/lec-18/slide2.png)
*Slide. 2.*



## <mark style='background-color: #fff5b1'> Probabilistic latent variable models </mark>


![slide3](/assets/images/CS285/lec-18/slide3.png)
*Slide. 3.*

Sergey는 먼저 본 수업을 진행하면서 다뤘던 확률 모델에 대해서 다시 remind를 합니다.
확률 모델이란 뭘까요? 위의 그림에서 말 그대로 모델 출력으로 확률 분포를 에측하는 것이죠.


첫 번째 그림 (우상단)은 우리가 가지고 있는 어떤 데이터 샘플들이 있을 때 이 데이터가 어디로부터 샘플링 됐을까를 알아내기 위한 목적으로 $$ p(x) $$ 를 모델링 한 것으로, 우리는 이를 예를들어 다변수 가우시안 분포 (Multivariate Gaussian Distribution)을 사용해 모델링 할 수 있을 겁니다.

두 번째 그림 (하단)은 $$ p(y \vert x) $$을 모델링 한 것이며 (그림에서는 선형 회귀) 이는 위와 다르게 $$x$$를 입력으로 했을 때 출력 $$y$$의 분포를 모델링 한 것입니다. (일반적으로 회귀 문제를 풀 때는 가우시안 분포를 사용하죠.)


두 가지의 차이점은 $$p(x)$$를 모델링 하느냐, $$p(y \vert x)$$를 모델링 하느냐 인데, $$p(x)$$를 모델링 한 경우에도 `Bayes Rule`을 사용해서 똑같이 $$p(y \vert x)$$를 만들어 사용할 수 있으며, $$p(x)$$를 모델링 하는 것을 일반적으로 `생성 모델(Generative Model)`, $$p(y \vert x)$$를 모델링 하는 것을 `판별 모델(Discriminative Model)` 이라고 합니다. 특히 생성모델의 경우 판별 모델처럼 목표는 $$p(y \vert x)$$로 같은데 번거롭게 $$p(x)$$ 분포를 모델링 하는 이유는 이름에서 알 수 있듯이, $$p(x)$$를 모델링 할 수 있다면 데이터가 어떤 분포(true distribution)로 부터 샘플링 됐는지를 알 수 있게 되어 이 분포로 부터 다른 데이터(unseen data)를 샘플링할 수 있다는 장점이 있습니다.


$$p(y \vert x)$$, 즉 Conditonal Probablistic Model의 경우 우리가 본 강의에서 계속 봐 왔던 것인데, 이는 바로 정책들(Policies) 입니다.


![slide4](/assets/images/CS285/lec-18/slide4.png)
*Slide. 4.*

아무튼 이번 수업에서 다룰 중요한 내용은 잠재 변수 (latent variable)가 추가된 모델들 (생성, 판별모델) 인데요, 이는 evidence 와 query 이외에 다른 변수를 의미합니다.
($$p(x)$$에서는 evidence는 존재하지 않고, query만 존재하며($$x$$), $$p(y \vert x)$$에서는 evidence가 $$x$$이며, query는 $$y$$ 라고 합니다. (???)) 

이 변수는 원래 존재하던 것이 아니라 우리가 정의한 '모델 내에 잠재 되어 있는 변수'이기 때문에 우리가 따로 `Integrated out` 해서 표현해야 하는데요, 위의 *Slide. 4.*에서 보시는 바와 같이 예를 들어 $$p(x)$$를 $$p(x \vert z) p(z)$$ 로 만들 수 있으며 우리는 이를 다루는 모델들에 대해서 살펴보도록 할 것입니다.


위의 슬라이드에서 보시는 바와 같이 우리가 흔하게 사용하는 잠재 변수 모델 (latent variable model)은 `Mixture Model`인데요, 알 수 없는(원래는 집단화 되어 있지 않은, 색상으로는 3개의 cluster지만) 많은 데이터 샘플을 나타내는 변수에 대해서 전통적인 머신러닝 알고리즘들은 `Gaussian Mixtrue Model`을 사용해서 $$p(x)$$를 조금 더 풍부하게 표현해오곤 했습니다. 보시는 바와 같이 한개의 봉우리 (Mode)를 가지는 가우시안 분포로는 $$p(x)$$를 완벽하게 표현할 수는 없지만, 3개의 가우시안 분포를 합쳐서 봉우리가 3개인 분포를 이용하면 잘 표현할 수 있다는 걸 알 수 있는데, 이 때 어떻게 해서 봉우리가 3개인 Mixture Model을 만드는가를 잠재 변수를 통해 배우게 됩니다.

여기서 잠재 변수 $$z$$는 3개 중 하나를 택하는 Categorical Distribution입니다.


우리는 생성 모델 뿐만 아니라 판별 모델에 대해서도 똑같이 이러한 잠재 변수를 `Integrated out` 시켜 생각해 볼 수 있는데요 (수식을 어떻게 decomposition 하는지는 유저가 판단할 수 있지만, 우선 위의 수식이라고 생각하도록 하겠습니다.), 마찬가지로 $$z$$가 Discrete Categorical Distribution 이라면 이는 전에 Imitation Learning에서 살펴봤던 Mixture Density Network 같은 것이 됩니다.


![slide5](/assets/images/CS285/lec-18/slide5.png)
*Slide. 5.*

자, 이제 조금 생각을 해보도록 하겠습니다. 우리가 잠재 변수를 도입하는 이유는 왜 일까요? 간단한게 말해서 복잡한 분포를 나타내기 위함 입니다.

우리가 머신러닝을 통해 찾고자 하는 $$p(x)$$ 분포가 굉장히 복잡한 분포라고 생각을 해 봅시다. 이 아이디어의 핵심은 우리가 어떤 잠재 변수를 나타내는 분포 $$p(z)$$와 $$x$$사이를 매핑해주는 $$p(x|z)$$를 알면, 이 둘을 적분하여 복잡한 분포 $$p(x)$$를 알아낼 수 있다는 겁니다. 여기서 이 두 가지 분포가 매우 간단한, 연속 변수의 경우 예를들어 `가우시안 분포(Gaussian Distribution)` 이어도 상관이 없는데, 즉 우리는 복잡한 분포 하나를 두 개의 단순한 분포의 곱으로 나타낼 수 있다는 겁니다.


![slide6](/assets/images/CS285/lec-18/slide6.png)
*Slide. 6.*


![slide7](/assets/images/CS285/lec-18/slide7.png)
*Slide. 7.*

![slide8](/assets/images/CS285/lec-18/slide8.png)
*Slide. 8.*

![slide9](/assets/images/CS285/lec-18/slide9.png)
*Slide. 9.*


## <mark style='background-color: #fff5b1'> Variational inference </mark>

![slide11](/assets/images/CS285/lec-18/slide11.png)
*Slide. 11.*

![slide12](/assets/images/CS285/lec-18/slide12.png)
*Slide. 12.*

![slide13](/assets/images/CS285/lec-18/slide13.png)
*Slide. 13.*

![slide14](/assets/images/CS285/lec-18/slide14.png)
*Slide. 14.*


![slide15](/assets/images/CS285/lec-18/slide15.png)
*Slide. 15.*

![slide16](/assets/images/CS285/lec-18/slide16.png)
*Slide. 16.*

![slide17](/assets/images/CS285/lec-18/slide17.png)
*Slide. 17.*

![slide18](/assets/images/CS285/lec-18/slide18.png)
*Slide. 18.*

## <mark style='background-color: #fff5b1'> Amortized variational inference </mark>


![slide20](/assets/images/CS285/lec-18/slide20.png)
*Slide. 20.*

![slide21](/assets/images/CS285/lec-18/slide21.png)
*Slide. 21.*

![slide22](/assets/images/CS285/lec-18/slide22.png)
*Slide. 22.*

![slide23](/assets/images/CS285/lec-18/slide23.png)
*Slide. 23.*

![slide24](/assets/images/CS285/lec-18/slide24.png)
*Slide. 24.*

![slide25](/assets/images/CS285/lec-18/slide25.png)
*Slide. 25.*

## <mark style='background-color: #fff5b1'> Generative models: variational autoencoders </mark>

![slide27](/assets/images/CS285/lec-18/slide27.png)
*Slide. 27.*

![slide28](/assets/images/CS285/lec-18/slide28.png)
*Slide. 28.*

![slide29](/assets/images/CS285/lec-18/slide29.png)
*Slide. 29.*

![slide30](/assets/images/CS285/lec-18/slide30.png)
*Slide. 30.*

![slide31](/assets/images/CS285/lec-18/slide31.png)
*Slide. 31.*

![slide32](/assets/images/CS285/lec-18/slide32.png)
*Slide. 32.*

![slide33](/assets/images/CS285/lec-18/slide33.png)
*Slide. 33.*

![slide34](/assets/images/CS285/lec-18/slide34.png)
*Slide. 34.*

### <mark style='background-color: #dcffe4'> asd </mark>

## <mark style='background-color: #fff5b1'> Reference </mark>

- [CS 285 at UC Berkeley : Deep Reinforcement Learning](http://rail.eecs.berkeley.edu/deeprlcourse/)

