---
title: (미완) Lecture 18 - Variational Inference and Generative Models

categories: CS285
tag: [RL]

toc: true
toc_sticky: true
---


이 글은 UC Berkeley 의 심층 강화 학습 (Deep Reinforcement Learning) 강의인 [CS285](http://rail.eecs.berkeley.edu/deeprlcourse/)를 듣고 기록하기 위해 작성한 글 입니다. 
강의 자료가 잘 구성되어 있으며, 강화학습 분야의 세계적인 석학인 [Sergey Levine](http://people.eecs.berkeley.edu/~svlevine/)의 강의 흐름을 그대로 따라가는게 낫겠다고 생각하여 슬라이드들을 그대로 사용해서 글을 전개하려고 합니다. (강의를 들으면서 가능하다면 이해를 돕기 위해 추가 자료를 중간 중간 첨부할 예정입니다.)


Lecture 18의 강의 영상과 자료는 아래에서 확인하실 수 있습니다. 
- [Lecture Video Link (Youtube)](https://www.youtube.com/watch?v=UTMpM4orS30&list=PL_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc&index=79)
- [Lecture Slide Link](http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-18.pdf)

---
< 목차 >
{: class="table-of-content"}
* TOC
{:toc}
---

![slide1](/assets/images/CS285/lec-18/slide1.png)
*Slide. 1.*

이번 강의에서 다루게 될 내용은 새로운 강화 학습 알고리즘 아니지만 강화 학습과 깊은 관련이 있는(있을) 변분 추론 (Variational Inference) 과 확률적 생성 모델 (Probabilistic Generative Models) 이라고 합니다. 변분 추론은 앞으로도 계속 등장할 것인데 Model-Based RL, Inverse RL(앞으로 배울거임), exploration 등등 가릴 것 없이 중요하게 쓰일 개념이라고 합니다. 목차는 아래와 같습니다.

![slide2](/assets/images/CS285/lec-18/slide2.png)
*Slide. 2.*



## <mark style='background-color: #fff5b1'> Probabilistic latent variable models </mark>


![slide3](/assets/images/CS285/lec-18/slide3.png)
*Slide. 3.*

Sergey는 먼저 본 수업을 진행하면서 다뤘던 확률 모델에 대해서 다시 remind를 합니다.
확률 모델이란 뭘까요? 위의 그림에서 말 그대로 모델 출력으로 확률 분포를 에측하는 것이죠.


첫 번째 그림 (우상단)은 우리가 가지고 있는 어떤 데이터 샘플들이 있을 때 이 데이터가 어디로부터 샘플링 됐을까를 알아내기 위한 목적으로 $$ p(x) $$ 를 모델링 한 것으로, 우리는 이를 예를들어 다변수 가우시안 분포 (Multivariate Gaussian Distribution)을 사용해 모델링 할 수 있을 겁니다.

두 번째 그림 (하단)은 $$ p(y \vert x) $$을 모델링 한 것이며 (그림에서는 선형 회귀) 이는 위와 다르게 $$x$$를 입력으로 했을 때 출력 $$y$$의 분포를 모델링 한 것입니다. (일반적으로 회귀 문제를 풀 때는 가우시안 분포를 사용하죠.)


두 가지의 차이점은 $$p(x)$$를 모델링 하느냐, $$p(y \vert x)$$를 모델링 하느냐 인데, $$p(x)$$를 모델링 한 경우에도 **<span style="color:#e01f1f">Bayes Rule</span>** 을 사용해서 똑같이 $$p(y \vert x)$$를 만들어 사용할 수 있으며, $$p(x)$$를 모델링 하는 것을 일반적으로 `생성 모델(Generative Model)`, $$p(y \vert x)$$를 모델링 하는 것을 `판별 모델(Discriminative Model)` 이라고 합니다. 특히 생성모델의 경우 판별 모델처럼 목표는 $$p(y \vert x)$$로 같은데 번거롭게 $$p(x)$$ 분포를 모델링 하는 이유는 이름에서 알 수 있듯이, $$p(x)$$를 모델링 할 수 있다면 데이터가 어떤 분포(true distribution)로 부터 샘플링 됐는지를 알 수 있게 되어 이 분포로 부터 다른 데이터(unseen data)를 샘플링(생성) 할 수 있기 때문입니다..


판별 모델 $$p(y \vert x)$$ 의 경우 일반적으로 딥러닝에서 가장 많이 사용되는 모델로, $$x$$를 **<span style="color:#e01f1f">조건부(conditional)</span>** 로 $$y$$의 분포를 예측하는, 즉 `Conditonal Probablistic Model`로 이는 우리가 본 강의에서 계속 봐 왔던 것인데, 바로 정책들(Policies) 이라고 할 수 .


![slide4](/assets/images/CS285/lec-18/slide4.png)
*Slide. 4.*

아무튼 이번 수업에서 다룰 중요한 내용은 잠재 변수 (latent variable)가 추가된 모델들 (생성, 판별모델) 인데요, 이는 evidence 와 query 이외에 다른 변수가 추가된 모델 의미합니다.
($$p(x)$$에서는 evidence는 존재하지 않고, query만 존재하며($$x$$), $$p(y \vert x)$$에서는 evidence가 $$x$$이며, query는 $$y$$ 라고 합니다. (???)) 

이 변수는 원래 존재하던 것이 아니라 우리가 정의한 '모델 내에 잠재 되어 있는 변수'이기 때문에 우리가 따로 `Integrated out` 해서 표현해야 하는데요, 위의 *Slide. 4.*에서 보시는 바와 같이 예를 들어 $$p(x)$$를 $$p(x \vert z) p(z)$$ 로 만들 수 있으며 우리는 이를 다루는 모델들에 대해서 살펴보도록 할 것입니다.


위의 슬라이드에서 보시는 바와 같이 우리가 흔하게 사용하는 잠재 변수 모델 (latent variable model)은 `Mixture Model`인데요, 알 수 없는(원래는 집단화 되어 있지 않은, 색상으로는 3개의 cluster지만) 많은 데이터 샘플을 나타내는 변수에 대해서 전통적인 머신러닝 알고리즘들은 `Gaussian Mixtrue Model`을 사용해서 $$p(x)$$를 조금 더 풍부하게 표현해오곤 했습니다. 보시는 바와 같이 한개의 봉우리 (Mode)를 가지는 가우시안 분포로는 $$p(x)$$를 완벽하게 표현할 수는 없지만, 3개의 가우시안 분포를 합쳐서 봉우리가 3개인 분포를 이용하면 잘 표현할 수 있다는 걸 알 수 있는데, 이 때 어떻게 해서 봉우리가 3개인 Mixture Model을 만드는가를 잠재 변수를 통해 배우게 됩니다.

(그림에서 잠재 변수 $$z$$는 3개 중 하나를 택하는 Categorical Distribution입니다.)


우리는 생성 모델 뿐만 아니라 판별 모델에 대해서도 똑같이 이러한 잠재 변수를 `Integrated out` 시켜 생각해 볼 수 있는데요 (수식을 어떻게 decomposition 하는지는 유저가 판단할 수 있지만, 우선 위의 수식이라고 생각하도록 하겠습니다.), 마찬가지로 $$z$$가 Discrete Categorical Distribution 이라면 이는 전에 Imitation Learning에서 살펴봤던 Mixture Density Network 같은 것이 됩니다.


![slide5](/assets/images/CS285/lec-18/slide5.png)
*Slide. 5.*

자, 이제 조금 생각을 해보도록 하겠습니다. 우리가 잠재 변수를 도입하는 이유는 왜 일까요? 간단한게 말해서 복잡한 분포를 나타내기 위함 입니다.

우리가 머신러닝을 통해 찾고자 하는 $$p(x)$$ 분포가 굉장히 복잡한 분포라고 생각을 해 봅시다. 이 아이디어의 핵심은 우리가 어떤 잠재 변수를 나타내는 분포 $$p(z)$$와 $$x$$사이를 매핑해주는 $$p(x \vert z)$$를 알면, 이 둘을 적분하여 복잡한 분포 $$p(x)$$를 알아낼 수 있다는 겁니다. 여기서 이 두 가지 분포가 매우 간단한, 연속 변수의 경우 예를들어 `가우시안 분포(Gaussian Distribution)` 이어도 상관이 없는데, 즉 우리는 복잡한 분포 하나를 두 개의 단순한 분포의 곱으로 나타낼 수 있다는 겁니다.


일반적으로 $$p(X)$$를 모델링 하는 생성 모델은 그 분포가 매우 복잡해서 학습이 어려운 경우가 많기 때문에, latent variable을 사용하는 모델을 사용하는 것이 훨씬 쉽다고 합니다.


![slide6](/assets/images/CS285/lec-18/slide6.png)
*Slide. 6.*

![slide7](/assets/images/CS285/lec-18/slide7.png)
*Slide. 7.*

***

하지만 사실 latent variable을 사용하는 모델을 학습하는게 그다지 쉽지는 않은데요, 이제 왜 그런지, 또 그렇다면 어떻게 학습하는지에 대해서 알아보도록 하겠습니다.


![slide8](/assets/images/CS285/lec-18/slide8.png)
*Slide. 8.*

위의 슬라이드는 일반적인 생성 모델의 Maximum Likelihood Estimation (MLE) 수식(좌)과 (모든 데이터들에 대해서 $$logp(x)$$ 를 구하고 이를 더한 것의 값을 크게(확률이 크게) 하는 방향으로 학습), latent variable 을 사용했을때의 MLE 수식(우)를 나타냅니다.


오른쪽이 딱봐도 어려운데, 그 이유는 매 gradient step을 진행하려고 할 때 마다 $$\sum$$ 수식 내의 $$\int$$을 계산해야 하기 때문이고 이는 일반적으로 불가능 (intractable) 하기 때문입니다.


(일반적으로 가우시안 분포 두개의 곱은 가우시안 분포라 계산이 쉬울 것 같지만 이마저도 쉽지 않다고 하는 듯?)



![slide9](/assets/images/CS285/lec-18/slide9.png)
*Slide. 9.*

그래서 이러한 문제를 해결하기 위해서 흔히 사용되는 방법이 있는데, 이것을 Expectred Log Likielihood 라고 하, 이는 직관적으로 $$p(x \vert z)$$가 무엇인지 추측(guess)해보는 겁니다.
데이터가 $$x$$ 와 $$z$$에 대한 정보를 모두 가지고 있긴 할텐데, 우리가 볼 수 있는것은 오직 $$x$$인 상황에서 "음 이 데이터 포인트 $$x_i$$는 아무래도 $$z$$의 value를 가질 것 같은데?(가령 A,B,C 3개의 cluster 중 A에 속할 것 같은데?)" 같이 fake label을 붙히는 거죠. 그리고는 이 $$x$$에 대해서 MLE를 하던거에서 ($$p(x)$$에 대해서만) $$x,z$$에 대해서 MLE를 하는 거 ($$p(x,z)$$에 대해서) 라고 생각을 하는겁니다. 

***

Intuition : "guess" most likely z given $$x_i$$, and pretend it's the right one
... but there are many possible values of z, so we use the distribution $$p(z \vert x_i)$$

***

실제에서는 하나의 $$z$$ value만을 사용할 수 없으며 가능한 $$z$$는 엄청 많기 때문에 분포에 대해서 전부 sum을(Expectation, $$\mathbb{E}$$ 해서 사용합니다 (z를 right one이라고 가정하긴 하나 분포로 생각, 가령 ~일 확률 0.3이 되는 것). 그런데 여기서 또 모든 $$z$$에 대해서 생각할 필요는 없기 때문에 사후 확률 분포 (posterior) $$p(z \vert x_i)$$에서 샘플링을 해서 (unbaised) 사용합니다. 그리고는 하던대로 모든 데이터 포인트 $$x_1,\cdots,n$$에 대해서 log-likelihood 를 더해서 하던대로 하면 됩니다. 


하지만 이는 *Slide. 7.* 의 오른편에 있는 $$\int$$ 가 있는 수식에서는 사용할 수 없는데, 적분식은 Linearly Decoposition 되지 않기 때문입니다.
(아마 나중에 다루게 될 것 같은데, 그래서 보통 적분을 몬테카를로 방법으로 생각해 sum으로 바꾸고 진행 했던 것 같습니다.)


자 이제 우리는 조금 더 tractable한 수식을 찾아냈는데, 여기서 문제는 '과연 어떻게 $$p(z \vert x)$$를 찾아낼 것인가?' 입니다.




## <mark style='background-color: #fff5b1'> Variational inference </mark>

이제부터 다룰 부분이 이번 강의의 핵심(main)인 변분 추론 (Variational Inference) 입니다.

***

'과연 어떻게 $$p(z \vert x)$$를 찾아낼 것인가?'

***

![slide11](/assets/images/CS285/lec-18/slide11.png)
*Slide. 11.*

(슬라이드를 그대로 따라가다 보니, 강의자의 의도와 조금 다르게 슬라이드 마다의 애니메이션이 없어져 보기가 쉽지 않지만...)

아까 latent variable을 사용하는 model이 '두 개의 간단한 분포, $$p(z)$$와 $$p(x \vert z)$$(z를 x로 매핑하는 함수)를 곱해(정확히는 적분까지) 복잡한 분포를 마들어낸다' 였음을 기억하시나요?
우리가 원하는 것은 $$p(x \vert z)$$(z를 x로 매핑하는 함수)의 반대인 $$p(z \vert x)$$(x를 z로 매핑하는 함수) 입니다.

![slide12](/assets/images/CS285/lec-18/slide12.png)
*Slide. 12.*

![slide13](/assets/images/CS285/lec-18/slide13.png)
*Slide. 13.*

잠깐 Variational Inference (VI)가 정말로 뭘 하는지를 알기 위해서 Recap을 해 보자면, 엔트로피는 두 가지 intuition을 나타내는 지표였습니다.

***

- 'how random is the random variable?' $$\rightarrow$$ 즉, 랜덤할수록 (Uniform에 가까울 수록) 값이 큽니다.
- 'how large is the log probaility in expectation under itself' $$\rightarrow$$ 슬라이드의 intuition 부분 오른쪽을 보시면 아시겠지만 몇개의 포인트에 대해서만 log probability가 엄청나게 큰 분포는 엔트로피가 작습니다.
- 
***

![slide14](/assets/images/CS285/lec-18/slide14.png)
*Slide. 14.*


![slide15](/assets/images/CS285/lec-18/slide15.png)
*Slide. 15.*

![slide16](/assets/images/CS285/lec-18/slide16.png)
*Slide. 16.*

![slide17](/assets/images/CS285/lec-18/slide17.png)
*Slide. 17.*

이제 모든것이 clear해졌고, 다시 우리의 목적 함수 (Objective Function)를 생각해보면, 우리는 일반적으로 딥 러닝 알고리즘에 사용되는 단순한 MLE 수식의 log-likelihood인 $$L$$ 를 Lower Bound $$L$$로 바꿀 수 있습니다. 이제 미니배치에 대해서 파라메터를 업데이트하는 일반적인 Stochastic Gradient Descent 에 대해서 생각해보면 각 데이터마다 Lower Bound를 계산하고 이를 모델 파라메터에 대해서 미분하여 업데이트 하면 됩니다. 여기서 파라메터와 관련이 없는 term들을 제외하게 되면 이는 결국 $$p(x \vert z)$$ 를 maximize하는 것과 다름 없으며, 파라메터를 업데이트 한 뒤 우리는 한번 더 Lower Bound를 업데이트 최대화 하는 방향으로 $$q_i$$를 업데이트 해주면 됩니다.


하지만 $$q$$를 어떻게 업데이트 할까요?


슬라이드가 애니메이션 없이 Full로 나와있어서 김이 새긴 하지만 우측 하단에 보시면 방법이 나와있습니다. 
에를 들어 우리가 $$q_i$$를 아주 간단한 가우시안 분포라고 가정했다면, 가우시안 분포의 두 가지 파라메터 평균(mean, $$\mu$$), 분산(variance, $$\sigma$$)에 대해서 각각 미분해주고 이를 경사 상승법(gradient ascent)에 따라 업데이트 해주면 됩니다.



![slide18](/assets/images/CS285/lec-18/slide18.png)
*Slide. 18.*

하지만 여기에 문제점이 있는데요, 이는 '그렇다면 네트워크에 업데이트 해야 할 파라메터는 얼마나 많은건가?' 입니다.


자 우리는 원래의 모델 파라메터에, 각 데이터 $$x_i$$ 마다 fake label을 나타내는 $$z_i$$에 대한 분포 $$q(z_i)$$를 가지고 있습니다.
그리고 이들은 또 여기서 각각 $$\mu$$, $$\sigma$$를 가지고 있죠. (...)


만약 데이터가 수천개 정도라면 상관 없지만 데이터가 수백만이라면 얘기는 달라집니다. (일반적인 딥러닝 문제에서는 불가능에 가깝다는 거죠.) 

그래서 여기에 매 데이터 포인트들 마다 새로운 분포의 파라메터를 따로 생각하지 말고, 어떠한 $$x$$ 데이터를 받으면 $$z$$를 예측 해주는 함수를 따로 두는 방법을 생각해 봅니다.

우리가 잘 아는 `Universal Function Approximator`가 있죠? 네 그렇습니다 Deep Neural Network를 따로 하나 더 둬서 데이터가 들어오면 분포를 예측하는 하나의 네트워크 (하나의 파라메터 세트만!)를 만들어 보는 . 즉 슬라이드의 최하단 그림에서 처럼 $$\pi$$로 파라메터화 된 $$q_{\pi}(z \ vert x)$$ 분포를 예측하는 네트워크를 하나 더 둬서, 두개의 네트워크를 학습하는 거죠. 이 네트워크는 출력 분포가 우리가 설정했던 대로 가우시안 분포 이므로 $$\mu, \sigma$$ 두 가지를 예측합니다.



## <mark style='background-color: #fff5b1'> Amortized variational inference </mark>

![slide21](/assets/images/CS285/lec-18/slide21.png)
*Slide. 21.*

자 이제 우리는 두 개의 네트워크가 있습니다. 하나는 $$z$$를 given으로 $$x$$를 만들어 내는 `Generative Network`이구요, 나머지는 $$q(z|x)$$ 분포를 예측하는 `Inference Network` 입니다.
*Slide. 21.* 의 우측 수식에서 $$q_i$$가 $$q_{\pi}$$의 하나의 네트워크로 변한 것이 보이시죠? 학습하는 방법은 왼쪽에 나와있는 것을 따라가시면 됩니다 (앞서 다룬 내용과 같음).

![slide22](/assets/images/CS285/lec-18/slide22.png)
*Slide. 22.*

![slide23](/assets/images/CS285/lec-18/slide23.png)
*Slide. 23.*

![slide24](/assets/images/CS285/lec-18/slide24.png)
*Slide. 24.*

![slide25](/assets/images/CS285/lec-18/slide25.png)
*Slide. 25.*

## <mark style='background-color: #fff5b1'> Generative models: variational autoencoders </mark>

![slide27](/assets/images/CS285/lec-18/slide27.png)
*Slide. 27.*

![slide28](/assets/images/CS285/lec-18/slide28.png)
*Slide. 28.*

![slide29](/assets/images/CS285/lec-18/slide29.png)
*Slide. 29.*

![slide30](/assets/images/CS285/lec-18/slide30.png)
*Slide. 30.*

![slide31](/assets/images/CS285/lec-18/slide31.png)
*Slide. 31.*

![slide32](/assets/images/CS285/lec-18/slide32.png)
*Slide. 32.*

![slide33](/assets/images/CS285/lec-18/slide33.png)
*Slide. 33.*

![slide34](/assets/images/CS285/lec-18/slide34.png)
*Slide. 34.*

### <mark style='background-color: #dcffe4'> asd </mark>

## <mark style='background-color: #fff5b1'> Reference </mark>

- [CS 285 at UC Berkeley : Deep Reinforcement Learning](http://rail.eecs.berkeley.edu/deeprlcourse/)

