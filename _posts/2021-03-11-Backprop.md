---
title: (미완) Error BackPropagation for Optimization
categories: MachineLearning
tag: [MachineLearning,ML]

toc: true
toc_sticky: true
---

---
< 목차 >
{: class="table-of-content"}
* TOC
{:toc}
---

## <mark style='background-color: #fff5b1'> What is Deep Learning? and How to train Neural Network? </mark>

"머신러닝, 딥러닝 알고리즘을 사용한다는 건 뭘까요?"

어떤 함수 $$f$$가 다음과 같이 주어져 있다고 합시다. 

![deep_learning1](/assets/images/backprop/deep_learning1.png)

덧셈 연산을 하는 함수인게 명확하죠. 
하지만 이 함수 $$f$$가 뭔지 알려지지 않았다고 해봅시다.

![deep_learning2](/assets/images/backprop/deep_learning2.png)

다만 입력과 정답에 대한 pair가 데이터로 존재할 뿐이라고 생각해보겠습니다. 

> 입력 3,5 / 정답 8
> 입력 4,1 / 정답 5
> 입력 50,122 / 정답 172 
> ...

머신 러닝 (Machine Learning) 이란 이 알려지지 않은 $$f$$를 데이터를 통해서 찾아내는 `Data-driven Approach` 인데요, 그 중에서도 아래와 같이 비선형성이 추가된 뉴럴 네트워크를 깊게 쌓은 것이 바로 
`딥 러닝 (Deep Learning)`이라고 하는 것 입니다.

![deep_learning3](/assets/images/backprop/deep_learning3.png)

딥러닝은 아래와 같이 `학습 (Training)` 이라는 과정을 거쳐서 점점 함수 $$f$$를 찾아내는 건데요, 

![deep_learning4](/assets/images/backprop/deep_learning4.png)

이렇게 찾아낸 `어떤 함수 f`가 그럼 맨 처음에 우리가 생각한 "덧셈 연산자 (Plus Operator)" 이냐고 누가 물어본다면 안타깝게도 그렇다고 답할수는 없습니다. 

![deep_learning5](/assets/images/backprop/deep_learning5.png)

그저 `"어떤 함수를 데이터를 통해 찾아냈을 뿐"`이죠. 


이를 확장해서 우리가 원하는 어떤 함수가 개, 고양이 등의 이미지를 입력받아 이게 무엇인지 맞추는 `이미지 분류기`라고 생각해봅시다.
입력 이미지가 $$x$$, 이에 대한 정답이 $$y$$라고 할 때 우리가 원하는 것은 어떤 알려지지 않은 이미지 $$x$$에 대해서 정답을 알려주는 `orcale function` $$y=f(x)$$일 것입니다.
머신러닝, 딥러닝 알고리즘을 통해 솔루션을 구한다는것은 바로 이 함수에 가장 근사한 함수, `approximate function` $$y=\hat{f}(x)$$을 무수히 많은 데이터를 가지고, 많이 시행 착오 (`trial and error`)를 통해, 즉 학습을 통해 구해 낸다는 것입니다.


이 근사 함수의 출력은 확률 분포로 모델링 되어있고, 이 출력 분포는 입력 데이터를 각종 수많은(많게는 175 billion 개, GPT3) 파라메터 $$\theta$$들과 `행렬 곱 연산`을 통해서 나타낼 수 있고, 맨 처음 주어진 랜덤한 파라메터들을 학습시킨다는 것은 출력 분포의 값이 최대가 되게끔 하는, 즉 `우도 (likelihood)`가 최대가 되게 하게끔 이 파라메터들의 값들을 최적의 값이 되도록 조정하는 것을 말합니다.

![forward](/assets/images/backprop/forward.gif)
*Fig. 네트워크가 입력 이미지를 받아서 출력 분포를 산출해 내는 과정. 손글씨 분류 문제는 Categorical Distribution로 모델링 된 학습 데이터들에 대한 출력 분포로 이루어진 likelihood를 최대화 하는 것과 같다.*

(출처 : [[3b1b youtube 1](https://www.youtube.com/watch?v=Ilg3gGewQ5U&t=1s)], [[3b1b youtube 2](https://www.youtube.com/watch?v=tIeHLnjs5U8)])

하지만 일반적으로 likelihood를 최대로 할 수 있는 `최적의 파라메터`를 단박에 구할 수 없는데 (즉 닫힌 해(`closed form solution`)가 존재하지 않다는 것이고), 그렇기 때문에 우리는 일반적으로 `gradient descent` 라고 하는 최적화 기법을 통해서 파라메터를 점진적으로 바꿔갑니다.


학습이 잘 된다는 가정하에 파라메터를 점진적으로 바꾸다 보면 어느 지점에 수렴하게 되고, 최적해에 도달할 수 있습니다 (물론 그렇지 않을 수도 있죠).

![optimization](/assets/images/backprop/optimization.gif)
*Fig. likelihood를 최대화 한다는 것은 negative likelihood (loss)를 최소화 한다는 것과 같다. 애니메이션에서는 어떤 랜덤한 지점에서 시작된 파라메터가 loss가 최소가 되는 지점을 향해 가는 것을 보여준다.*

"여기서 어떤 파라메터를 얼만큼 바꿔야 할까?"는 "이 만큼의 loss를 발생시킨데는 $$\theta_1$$의 값이 가장 주요했어, 그러니까 $$\theta_1$$ 크게 penalty를 받아야겠다, 크게 값을 조정해야겠어" 라고 판단하여 파라메터를 조절해야 하는데,
여기서 파라메터의 출력에 끼치는 영향력을 `편미분 (Partial Differentiation)`을 통해서 계산해 낼 수 있습니다.


하지만 딥러닝 모델이 커질수록, 층수가 깊어지고, 파라메터가 많아질수록 그 많은 파라메터와 결과값 사이의 `민감도 (Sensitivity)`를 매번 계산해 내는것은 불가능할 정도로 오래걸립니다.
바로 이를 해결하기 위한 효율적인 테크닉이 바로 `오차 역전파 (Error Back Propagation)` 입니다. 

![backward](/assets/images/backprop/backward.gif)
*Fig. likelihood를 최대화 한다는 것은 negative likelihood (loss)를 최소화 한다는 것과 같다. 애니메이션에서는 어떤 랜덤한 지점에서 시작된 파라메터가 loss가 최소가 되는 지점을 향해 가는 것을 보여준다.*

이번 글에서는 "오차역전파가 무엇인지?" 그리고 "왜 이 방법이 일반적인 미분 방법보다 효율적인지?"에 대해서 이야기  합니다.








## <mark style='background-color: #fff5b1'> Why Error Backpropagation? </mark>

앞서 말한 것 처럼 뉴럴 네트워크 (Neural Network, NN)의 파라메터를 최적화하기 위해서는 파라메터를 미분해서 업데이트 해야 하는데, 여기서 두 가지를 구분하는게 중요합니다.

- 1.`손실 함수 (Loss Function)를 통해서 정답과 추정치의 차이 값을 계산하고, 이를 파라메터에 대해서 미분한다.`
  - 바로 이 때 이 미분 값 (gradient)을 구하는 효율적인 방법이 바로 오차 역전파가 되겠고, 이를 구하는 다른 기법으로 야코비안 (Jacobian), 헤시안 (Hessian)을 이용할 수도 있습니다.
- 2.`gradient를 사용해서 파라메터를 업데이트한다.`
  - 이 때 경사 하강법 (gradient descent)를 사용하는 것이 가장 일반적인 방법이다. 

그렇다면 왜 오차 역전파를 사용해야할까요? 가장 중요한 이유는 바로 계산 효율성 때문입니다. 
즉 오차 역전파를 사용한다는 것은 손실 함수 값을 계산하고, 이 계산한 값을 가지고 미분을 한번 더 하는 일반적인 방식을 사용하지 않겠다는 겁니다.
계산 효율성에 대해서 정량적으로 비교하기 위해 예를 들어보도록 하겠습니다.


우리가 가진 어떤 네트워크의 파라메터가 $$W$$개 라고 가정하겠습니다.
우선 현재 파라메터를 평가하기 위해서 순전파 (Forward Propagation)를 하면 $$O(W)$$만큼의 시간이 걸립니다.



요약하자면 수치 미분으로 업데이트하는 것과 역전파 알고리즘으로 업데이트를 한다는 것은 아래와 같은 차이가 있습니다.

- `수치 미분을 사용할 경우`
  - 1.순전파 시행
  - 2.손실 함수 값 계산 (정답 - 추정치, $$y-\hat{y}$$)
  - 3.모든 W개의 파라메터, $$\theta$$ (weight, bias)에 대해서 미분 시행 (이 때 미분값을 계산하기 위해서 파라메터 한 개당 순전파 한번씩 시행)
  - 4.파라메터 갱신 (update)
- `오차 역전파를 사용할 경우`
  - 1.순전파 시행 (순전파 시행하면서 computational graph 저장)
  - 2.순전파를 시행해 끝에 도달했으면, 끝에서 부터 시작지점까지 연쇄 법칙 (chain rule)을 통해서 파라메터에 대한 미분 값을 점진적으로 계산하여 뒤로 전파 (역 전파). (이 때 파라메터 각각에 대해서 수치 미분을 일일히 하는 것이 아니므로 순전파를 다시 시행할 필요가 없음) 
  - 3.파라메터 갱신 (update)


### <mark style='background-color: #dcffe4'> Jacobian Matrix </mark>


### <mark style='background-color: #dcffe4'> Hessian Matrix </mark>








## <mark style='background-color: #fff5b1'> Erro Backpropagation </mark>

### <mark style='background-color: #dcffe4'> Backpropagation in CNN </mark>

### <mark style='background-color: #dcffe4'> Backpropagation in RNN </mark>

### <mark style='background-color: #dcffe4'> Backpropagation through Batch Normalization Layer </mark>






## <mark style='background-color: #fff5b1'> "Yes you should understand backprop" - Andrej Karpathy </mark>







## <mark style='background-color: #fff5b1'> References </mark>

- [link1](https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b)

- [link2](https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html)

- [link3](https://tensorflow.blog/2016/12/27/%ec%97%ad%ec%a0%84%ed%8c%8c-%ec%a7%81%ec%a0%91-%ec%a7%9c%eb%b4%90%ec%95%bc-%ed%95%98%eb%82%98%ec%9a%94/#more-20614)

- [tmp](https://bskyvision.com/718)
