---
title: (미완)Transducer
categories: Speech_Recognition
tag: [tmp]

toc: true
toc_sticky: true
---

---
< 목차 >
{: class="table-of-content"}
* TOC
{:toc}
---

Transducer 

## <mark style='background-color: #fff5b1'> Common Approaches for Deep Learning based E2E ASR Model) </mark>

![seq2seq](/assets/images/NLP_RL/seq2seq.png)
*Fig. tmp*

### <mark style='background-color: #dcffe4'> CTC-based model (2006, 2014, ...) </mark>

### <mark style='background-color: #dcffe4'> Attention-based model (2014, ...) </mark>

### <mark style='background-color: #dcffe4'> Transducer-based model (2012, 2018, ...) </mark>

## <mark style='background-color: #fff5b1'> References </mark>

- Blog
  - 1. [Sequence-to-sequence learning with Transducers from Loren Lugosch](https://lorenlugosch.github.io/posts/2020/11/transducer/)
- Paper
  - 1. [Sequence Transduction with Recurrent Neural Networks](https://arxiv.org/pdf/1211.3711)
  - 2. [A Neural Transducer](https://arxiv.org/pdf/1511.04868)
  - 3. [Exploring Neural Transducers for End-to-End Speech Recognition](https://arxiv.org/pdf/1707.07413)
  - 4. [Streaming End-to-end Speech Recognition For Mobile Devices](https://arxiv.org/pdf/1811.06621)
