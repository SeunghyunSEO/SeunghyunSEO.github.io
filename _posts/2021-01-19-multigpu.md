---
title: Multi GPU with DP and DDP
categories: gpu
tag: [gpu,multigpu,pytorch]

toc: true
toc_sticky: true
---

Data-driven approach인 딥러닝의 특성상, 일반적으로 학습 데이터가 무수히 많기 때문에, 그리고 데이터의 입력 차원이 크기 때문에 대부분의 딥러닝 네트워크는 batch 단위로 학습을 하기 마련입니다.
그리고 모델의 크기가 클 수록 일반적으로 네트워크의 성능이 좋아지기 때문에 최근 논문들에서 제안되는 네트워크들은 엄청나게 모델 사이즈가 크기 때문에 큰 batch size를 사용하기 힘듭니다.<br>
위와 같은 이유로 딥러닝 네트워크의 학습이 수렴하는데는 상당히 많은 시간이 걸리기 때문에 GPU가 넉넉하다면 누구나 여러개의 GPU를 사용해서 batch size를 늘려 학습하고 싶을 것입니다.<br><br> 

이럴 경우 pytorch 프레임워크를 예로 들면 내장 함수인 ```torch.nn.DataParallel``` 혹은 ```torch.nn.parallel.DistributedDataParallel``` 를 사용하거나 nvidia의 ```apex.parallel.DistributedDataParallel```나 ```hovorod```를 사용하는 등 다양한 방법을 사용할 수 있습니다.

이 때, 하나의 pc에서 여러개의 gpu를 사용하는경우 (예를 들어, single pc, [0,1,2,3] 총 4개 gpu), 아니면 여러개의 pc 여러개의 gpu를 사용하는 경우(예를 들어, multiple pc, 하나의 pc에 [0,1,2,3] 4개씩 총 8개 gpu)를 사용하는 경우에 따라 조금 다르게 코딩을 해줘야 하는데 이번에는 전자의 경우에 대해서만 다뤄보도록 하겠습니다. 


### torch.nn.DataParallel (DP)
앞서 말한것처럼 pytorch 에서는 굉장히 쉽게 여러개의 gpu를 사용해 학습할 수 있는데, ```torch.nn.DataParallel```(DP)를 사용해 간단히 multi-gpu를 사용하는 코드는 다음과 같습니다.<br>
  
  
{% gist SeunghyunSEO/dc8bb539c4d8655254e48010fcff1192 %}


### torch.nn.DistributedDataParallel (DDP)
이번에는 ```torch.nn.parallel.DistributedDataParallel```, 즉 DDP를 사용할 경우에 대해서 알아보겠습니다.<br>


{% gist SeunghyunSEO/2a03baf56c0d6a96d220269804521318 %}

gist 코드 테스트중<br>




