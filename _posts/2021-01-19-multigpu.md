---
title: Multi GPU with DP and DDP
categories: gpu
tag: [gpu,multigpu,pytorch]

toc: true
toc_sticky: true
---

<div style="font-size: 0.9rem; font-weight:300; line-height: 1.6rem;">
딥러닝 학습을 진행할 때, GPU를 여러 개 사용하여 학습하고 싶을 때가 있을 것입니다.<br>
Data-driven approach인 딥러닝의 특성상, 일반적으로 학습 데이터가 무수히 많기 때문에, 그리고 데이터의 입력 차원이 크기 때문에 대부분의 딥러닝 네트워크는 batch 단위로 학습을 하기 마련입니다.
그리고 모델의 크기가 클 수록 일반적으로 네트워크의 성능이 좋아지기 때문에 일반적으로 최근에 논문에서 제안되는 네트워크들은 엄청나게 커서 큰 batch size를 사용하기 힘듭니다.<br>
위와 같은 이유로 학습이 길어지는 문제 때문에 GPU가 넉넉하다면 누구나 여러개의 GPU를 사용해서 batch size를 늘려 학습하고 싶을 것입니다.<br><br> 

pytorch 프레임워크를 사용하면 굉장히 쉽게 여러개의 gpu를 사용해 학습할 수 있는데, 이는 `torch.nn.DataParallel` 를 사용하거나 `torch.nn.parallel.DistributedDataParallel` 를 사용하는 방식으로 간단하게 구현할 수 있습니다.<br>
`torch.nn.DataParallel`(DP)를 사용해 간단히 multi-gpu를 사용하는 코드는 다음과 같습니다.<br>
  
  
{% gist SeunghyunSEO/dc8bb539c4d8655254e48010fcff1192 %}

gist 코드 테스트중<br>
이번에는 `torch.nn.parallel.DistributedDataParallel`, 즉 DDP를 사용할 경우에 대해서 알아보겠습니다.<br>


{% gist SeunghyunSEO/2a03baf56c0d6a96d220269804521318 %}


</div>



