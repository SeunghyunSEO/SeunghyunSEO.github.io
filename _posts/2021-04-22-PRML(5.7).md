---
title: 5.7 Bayesian Neural Networks
categories: Brief_Review_for_PRML
tag: [PRML,MachineLearning,ML]

toc: true
toc_sticky: true

comments: true
---


---
< 목차 >
{: class="table-of-content"}
* TOC
{:toc}
---


## <mark style='background-color: #fff5b1'> PRML 5.7 </mark>

이번 장에서는 어떻게 비선형성을 가지는 뉴럴 네트워크를 사용해 Bayesian Inference를 할 수 있는가에 대해서 살펴보는 장이다.


***

- Dataset : $$D$$, (input $$x$$, and output label, $$t$$ $$\in D$$)
- Network Parameter : $$ w $$ 
- Likelihood : $$p( D \vert w) = p(t \vert f(x;w))$$
- Prior : $$p(w)$$
- Posterior : $$ p(w \vert D) = \frac{ p(D \vert w) p(w) }{ p(D) } = \frac{ p(D \vert w) p(w) }{ \int_{w'} p( D \vert w') p(w') dw' } \approx q(w \vert D) $$
- Inference : $$ p(y^{\ast} \vert x^{\ast}, D) = \int_w p(y^{\ast} \vert x^{\ast}, w) p(w \vert D) \approx \int_w p(y^{\ast} \vert x^{\ast}, w) q(w) $$
- Inference (Bayesian model Averaging) : $$p(y^{\ast} \vert D) = \mathbb{E}_{w_k \sim p(w \vert D)} p(y^{\ast} \vert w) \approx \frac{1}{K} \sum_{k=1}^K p(y^{\ast} \vert w_k)$$

***


### <mark style='background-color: #dcffe4'> 5.7.1 사후 매개변수 분포 (Posterior parameter distribution) </mark>

입력 $$x$$에 대해서 단일 타겟 변수 $$t$$를 예측하는 회귀 문제를 고려할 것입니다 ($$t$$는 연속적인 값을 가지게 됩니다).
연속적인 출력 분포를 가정하기 위해서 익숙한 `가우시안 분포`를 가정해보도록 하겠습니다.

$$
p(t \vert x,w,\beta) = N(t \vert y(x,w), \beta^{-1})
$$

분산을 나타내는 값이 $$\beta^{-1}$$이므로 $$\beta$$는 그와 반대인 정밀도를 의미하게 되겠습니다.
출력 가우시안 분포의 평균 (mean, $$\mu$$)를 추론하게 될 파라메터 $$w$$에 대한 분포, `prior` 또한 위의 likelihood와 유사한 가우시안 분포로 가정하겠습니다. 

$$
p(w \vert \alpha) = N(w \vert 0, \alpha^{-1} I)
$$

N개의 관측값 (Observations, Samples) $$x_1,x_2, \cdots, x_n$$과 이에 해당하는 표적값 (Target) $$D=\{ t_1,t_2,\cdots,x_n \}$$에 대해서 `likelihood`는 아래와 같습니다.

$$
p(D \vert w,\beta) = \prod_{n=1}^N N(t_n \vert y(x_n,w),\beta^{-1})
$$

(각 샘플들이 독립을 가정하기 때문에 개별 샘플의 확률 곱으로 최종 likelihood를 나타낼 수 있는 것)


여기에 `posterior`는 일반적으로 아래와 같은 관계식을 따르므로

$$
posterior \approx likelihood \times prior
$$

최종적으로 다음 형태의 posterior를 얻을 수 있습니다.

$$
p(w \vert D,\alpha,\beta) \approx p(D \vert w,\beta) \times p(w \vert \alpha)
$$

$$y(x,w)$$의 $$w$$에 대한 비선형성으로 인해서 위의 식은 비 가우시안 분포가 될 것입니다.


우리는 앞서 배운 `라플라스 근사법 (Laplace Approximation)` 을 사용해서 posterior의 가우시안 근사치를 구할 수 있는데, 이를 위해서는 사후 분포의 (지역적) 최대값을 찾아야 하며, (= MAP solution을 의미함) 이는 activation function이 가지는 전체 함수의 비선형성 때문에 닫힌 해 (closed-form)를 구할 수 없으므로 반복적인 최적화를 통해 구해야 합니다. 


`MAP Solution`은 간단하게 posterior에 대해서 $$log$$를 취한 뒤 최적화를 통해 구할 수 있습니다.

$$
ln p(w \vert D) = -\frac{\alpha}{2} w^T w - \frac{\beta}{2} \sum_{n=1}^N { \{ y(x_n,w) - t_n \} }^2 + const
$$

(앞서 배운 것 처럼 우리가 likelihood로 가우시안 분포를 가정했으므로 (=회귀 문제) MSE loss가 나오는 것은 당연하고, 여기에 파라메터에 대해서 또 한번 가우시안 prior를 가정했으므로 정규화 항이 딸려서 나오는 것은 당연하겠죠?)


***

### MLE vs MAP

- MLE 

![mle1](/assets/images/PRML_5.7/mle1.png)
*Additive Fig. 선형 회귀 문제에서의 MLE를 한다는 것은 MSE의 최소점을 찾는 것과 같다.*

![mle2](/assets/images/PRML_5.7/mle2.png)
*Additive Fig. 분산 (Variance)를 파라메터로 생각하지 않고 평균 (mean)에 대해서만 생각하는 경우*

- MAP

![map1](/assets/images/PRML_5.7/map1.png)

![map2](/assets/images/PRML_5.7/map2.png)

![map3](/assets/images/PRML_5.7/map3.png)
*Additive Fig. prior와 likelihood를 곱해 얻은 posterior를 최대화 하는 MAP 솔루션은 데이터 샘플 수가 많으면 MLE 솔루션과 같아진다 (점이 됨), 그리고 Posterior에서 어떤 파라메터를 샘플링 하던 거의 비슷한 값이 나올 것이다. (MAP나 Bayesian Inference나 그게 그거가 되는 것)*


***



일단 우리는 prior와 likelihood의 분산(역으로는 정밀도)를 나타내는 파라메터 $$\alpha,\beta$$는 고정된 값이라고 생각하겠습니다 (이거는 학습 매개변수가 아닌것).
오차 역전파 (Error Backpropagation)과 경사 하강법 (Gradient Descent)를 이용해서 $$w_{MAP}$$를 찾은 뒤, 음의 로그 사후 분포의 이차 미분 행렬을 바탕으로 우리는 `지역적 가우시안 근사치`를 얻을 수 있습니다.

$$
A = - \bigtriangledown \bigtriangledown ln p(w \vert D,\alpha,\beta) = \alpha I + \beta H
$$

($$H$$는 오차 함수의 $$w$$ 성분들에 대한 이차 미분값들로 이루어진 헤시안 행렬임)


우리는 앞서 4절에서 배운 것 처럼 `posterior를 근사한 분포`를 아래처럼 얻을 수 있다.

$$
q(w \vert D) = N(w \vert w_{MAP}, A^{-1} )
$$


![laplace_approx](/assets/images/PRML_5.7/laplace_approx.png)
*Additive Fig. MAP의 최적화 솔루션을 통해 찾은 값을 바탕으로 봉우리 (Mode)가 하나인 다루기 쉬운 가우시안 분포를 찾아내는 라플라스 근사법 (Laplace Approximation)*


우리가 머신러닝을 통해서 최종적으로 원하는 것은 데이터를 통해 학습한 파라메터를 가지고, 새로운 unseen 입력 데이터에 대해서 그럴싸한 추론을 하는 겁니다. 

$$
p(t \vert x,D)
$$

이러한 머신런이 방법론들 중 `베이지안 방법론`의 목적은 파라메터를 점 추정 하는것에 그치지 않고 (MLE나 MAP는 최대값인 파라메터 딱 하나만을 결과물로 취함), 모두 고려해 weight에 대한 uncertainty를 최대한 없애는 것이기 때문에 가능한 파라메터들에 대해서 모두 결과값을 구해 이를 Averaging하는 것이고, 

![nn_vs_bnn](/assets/images/PRML_5.7/nn_vs_bnn.png)
*Additive Fig. Figure의 caption에도 나와있지만, 왼쪽은 점 추정 (일반적인 MLE 솔루션)을 한 경우이며, 오른쪽은 분포 추정을 한 경우이다 (저 분포에서도 max를 찍으면 MAP가 되겠지만 분포를 그대로 살려두고 추론 시 integral을 통해  결과 값을 예측한다.)*





이를 위해 사후 분포를 주변화 (marginal) 한 수식은 아래와 같이 표현이 가능하며,

$$
p(t \vert x,D) = \int p(t \vert x,w) p(w \vert D, \alpha, \beta) dw
$$

우리는 라플라스 근사식을 통해서 $$\int$$속 복잡한 posterior를 근사 분포로 만들어 최종적으로 다음과 같은 수식을 얻을 수 있는겁니다.

$$
p(t \vert x,D) = \int p(t \vert x,w) q(w \vert D) dw
$$

이제 학습이 끝난 후 어떤 unseen 데이터 $$x$$가 들어오면 이를 위의 수식에 넣어 적분을 통해 $$t$$값을 추론해 내기만 하면 되지만, 그럼에도 이 적분식을 해석적으로(?) 계산하기는 여전히 어려운데 왜냐하면 이는 $$w$$의 함수로 주어지는 네트워크 함수 $$y(x,w)$$가 비선형이기 때문이라고 합니다. (음... 잘 와닿지 않네요 아직)


논의를 해보기 위해 변화하는 $$y(x,w)$$값 상의 $$w$$의 척도와 비교했을 때, 사후 분포의 분산이 상대적으로 작다고 가정해보도록 하겠습니다.
이 가정을 바탕으로 하면 $$w_{MAP}$$ 주변의 네트워크 함수를 테일러 전개하고 선형항만을 남길 수가 있습니다.

$$
y(x,w) \approx y(x,w_{MAP}) + g^T(w-w_{MAP})
$$

$$
g = \bigtriangledown_{w} y(x,w) \vert_{w=w_{MAP}}
$$

***

- Taylor Series

![taylor_series_animated](/assets/images/PRML_5.7/taylor_series_animated.gif)
*Additive Fig. Animated Taylor Series*

(이미지 출처 : [link](https://yasincapar.com/taylor-expansion/))

***

이 근사치를 바탕으로 $$p(w)$$와 $$p(t \vert w)$$에 대한 선형 가우시안 모델을 얻게 되었고, 이 때 $$p(t \vert w)$$의 평균값은 $$w$$에 대한 선형 함수로 나타낼 수 있습니다.

$$
p(t \vert x,w,\beta) \approx N( t \vert y(x,w_{MAP}) + g^T(w-w_{MAP}) , \beta^{-1})
$$

주변 확률 $$p(t)$$에 대한 2절에서의 식 2.115를 이용하면 다음을 구할 수 있습니다.

$$
p(t \vert x,D,\alpha,\beta) = N( t \vert y(x,w_{MAP}) , \alpha^2(x))
$$

여기서 어떠한 입력 데이터 $$x$$에 종속적인 분산은 다음으로 구할 수 있습니다.

$$
\alpha^2(x) = \beta^{-1} + g^T A^{-1} g 
$$


***

recap)

$$
g = \bigtriangledown_{w} y(x,w) \vert_{w=w_{MAP}}
$$

$$
A = - \bigtriangledown \bigtriangledown ln p(w \vert D,\alpha,\beta) = \alpha I + \beta H
$$

***

위의 수식들을 다시 한 번 살펴보자면, 예측 분포 $$p(t \vert x,D)$$는 가우시안 분포이며, 그 평균값은 매개변수들이 MAP값으로 설정된 네트워크 함수 $$y(x,w_{MAP}$$입니다. 
분산은 두 개의 항으로 이루어져 있는데, 첫 번째 항 $$\beta^{-1}$$은 타깃 변수의 `내재적인 노이즈 (Intrinsic Noise)` 로부터 기인하며, 두 번째 항은 x에 종속적인 항으로써 모델 매개변수 $$w$$의 불확실성으로부터 기인한 삽간 함수 (?)의 불확실성을 나타냅니다 (the uncertainty in the interpolant due to the uncertainty in the model parameters w).



![uncertainty1](/assets/images/PRML_5.7/uncertainty1.png){: width="60%"}
*Additive Fig. 책에는 나오지 않지만 후에 다른 연구자들이 Uncertainty를 두 가지로 규정하였는데, Epistemic Uncertainty는 우리가 예측한 파라메터가 얼마나 불확실한지를 나타내는 지표이며, Aleatoric Uncertainty는 데이터 자체에 내재되어있는 불확실성, 즉 "데이터가 실제 분포로 부터 만들어 질 때 (샘플링, 수집 될 때) 얼마나 노이즈가 많이 꼈는가?" 를 의미한다.*

![uncertainty2](/assets/images/PRML_5.7/uncertainty2.png)
*Additive Fig. 이 두 가지를 합쳐서 비로소 Uncertainty라고 할 수 있다.*

![uncertainty3](/assets/images/PRML_5.7/uncertainty3.png)
*Additive Fig. 비선형 회귀 문제를 풀었을 때의 Unceratinty, 데이터가 없는 곳에는 우리가 구한 파라메터를 기반으로 추론한 분포가 굉장히 분산이 큰 걸 알 수 있다. (그만큼 확신이 없고 확률이 여러곳으로 분산되어있다는 뜻)*













### <mark style='background-color: #dcffe4'> 5.7.2 초매개변수의 최적화 (Hyperparameter optimization) </mark>

여태까지는 likelihood와 prior의 분산을 의미하는 $$\alpha,\beta$$가 고정되어있는 경우를 가정하고 문제를 풀었는데요 (fixed variance problem), 
우리는 앞서 3절에서 논의 했던 `증거 방법론 (evidence approximation)`과 `라플라스 근사법 (laplace approximation)`을 통해 구한 사후 분포의 가우시안 근사치를 바탕으로 초매개변수 (hyperparam), $$\alpha,\beta$$를 구할 수도 있습니다. 

$$\alpha,\beta$$의 주변 가능도 (Evidence, Marginal Likelihood)는 네트워크 가중치들에 대한 적분을 통해서 구할 수 있는데요,

$$
p(D \vert \alpha, \beta) = \int p(D \vert w, \beta) p(w \vert \alpha) dw
$$

***

Recap) 

- Dataset : $$D$$, (input $$x$$, and output label, $$t$$ $$\in D$$)
- Network Parameter : $$ w $$ 
- Likelihood : $$p( D \vert w) = p(t \vert f(x;w))$$
- Prior : $$p(w)$$
- Posterior : $$ p(w \vert D) = \frac{ p(D \vert w) p(w) }{ p(D) } = \frac{ p(D \vert w) p(w) }{ \int_{w'} p( D \vert w') p(w') dw' } \approx q(w \vert D) $$
- Inference : $$ p(y^{\ast} \vert x^{\ast}, D) = \int_w p(y^{\ast} \vert x^{\ast}, w) p(w \vert D) \approx \int_w p(y^{\ast} \vert x^{\ast}, w) q(w) $$
- Inference (Bayesian model Averaging) : $$p(y^{\ast} \vert D) = \mathbb{E}_{w_k \sim p(w \vert D)} p(y^{\ast} \vert w) \approx \frac{1}{K} \sum_{k=1}^K p(y^{\ast} \vert w_k)$$

***

이는 4절에서 구한 라플라스 근사 결과치를 바탕으로 쉽게 계산할 수 있고 이에 로그를 취하면 아래와 같은 식을 얻게 됩니다.




$$
ln(D \vert \alpha, \beta) \approx -E(w_{MAP}) - \frac{1}{2} ln \vert A \vert + \frac{W}{2} ln \alpha + \frac{N}{2} ln \beta + \frac{N}{2} ln(2\pi)
$$

$$
E(w_{MAP}) = \frac{\beta}{2} \sum_{n=1}^N { \{ y(x_n,w_{MAP}) - t_n \} }^2 + \frac{\alpha}{2} w_{MAP}^T w_MAP
$$

(여기서 $$W$$는 총 매개변수 숫자에 해당합니다.)


증거 방법론에서는 $$ln p(D \vert \alpha,\beta)$$값을 최대화해서 $$\alpha,\beta$$에 대한 점 추정값을 구할 수 있습니다.

그러기 위해서 첫 번째로 $$\alpha$$에 대한 최대값을 구하기 위해서 고윳값 방적식을 다음과 같이 정의할 수 있습니다.

$$
\beta \boldsymbol{H} \boldsymbol{u_i} = \lambda_i \boldsymbol{u_i}
$$

여기서 $$\boldsymbol{H}$$는 MSE 함수의 이차 미분항들로 이루어진 헤시안 행렬로, w=w_{MAP}에 대해서 계산된 것입니다.
 
앞서 3잘에서 살펴본 바와 비슷하게

$$
\alpha = \frac{\gamma}{w_{MAP}^T w_{MAP}}
$$

$$
\gamma = \sum_{i=1}^W \frac{\lambda_i}{\alpha+\lambda_i}
$$

여기서 $$\gamma$$는 유효 매개변수의 숫자를 지칭합니다.


이와 유사하게 $$\beta$$에 대한 증거값 또한 최대화 하면 다음을 얻을 수 있다.

$$
\frac{1}{\beta} = \frac{1}{N-\gamma} \sum_{n=1}^N { \{ y(x_n,w_{MAP}) - t_n \} }^2
$$


선형 모델의 경우와 마찬가지로 비선형 모델인 뉴럴 네트워크를 사용할 경우에도 사후 분포를 업데이트 하는 과정과 $$\alpha,\beta$$를 업데이트 하는 과정을 번갈아가며 진행하면서 최적화 하면 됩니다.

뉴럴 네트워크의 경우도 선형 모델의 경우와 크게 다를 바 없이 각 매개변수들의 최대값들을 추정할 수 있었지만, 뉴럴 네트워크의 경우 사후 분포가 다봉성 (multi-modal)을 가지기 때문에 이 과정이 좀 더 복잡하며, $$w$$를 어떻게 초기화 하냐에 따라서 로그 사후 분포를 최대화 해서 찾을 수 있는 $$w_{MAP}$$가 달라진다고 합니다.



















### <mark style='background-color: #dcffe4'> 5.7.3 베이지안 뉴럴 네트워크를 통한 분류 (Bayesian neural networks for classification) </mark>

베이지안 뉴럴 네트워크를 통해서 문제를 풀어보도록 할건데요, 다중 분류 문제는 이진 분류 문제와 크게 다르지 않기 때문에 우선 간단한 이진 분류 문제를 가정해보도록 하겠습니다.


![bnn_classification2](/assets/images/PRML_5.7/bnn_classification2.png)
*Additive Fig. 우리가 실제로 원하는 것(아래). 위는 MLE로 추정한 파라메터 (점)를 그냥 결정 경계로 사용하는것, 아래는 posterior 분포를 추정한 뒤 모든 파라메터에 대해서 결정 경계면을 그려 이를 합산하는 Bayesian Approach*


![bnn_classification1](/assets/images/PRML_5.7/bnn_classification1.png)
*Additive Fig. 선형 분류기가 아닌 신경망 (Neural Network, NN)을 사용한 분류기의 경우도 마찬가지다. 우리는 학습을 통해 각각의 파라메터들에 대해서 분포를 가지고 있는 셈이고 (이는 비선형 활성화 함수를 사용한 뉴럴 네트워크이기 때문에 비선형 결정 경계면을 만들어낸다.), 가능한 파라메터의 경우를 다 고려해서 최종적으로 테스트 데이터 입력에 대한 출력 분포를 만들어 내는 것이다.*




$$
ln p(D \vert w) = \sum_{n=1}^{N} \{ t_n ln y_n + (1-t_n) ln(1-y_n) \} 
$$

여기서 분산을 나타내는 $$\beta$$가 존재하지 않는 이유는, 데이터 포인트들이 올바르게 레이블링 되어있다고 가정하기 때문입니다. 
이제 prior를 가정할것인데, 앞선 문제들과 마찬가지로 등방 가우시안 분포를 가정하도록 할겁니다.

$$
p(w \vert \alpha) = N(w \vert 0, \alpha^{-1}I)
$$

이 모델에 라플라스 방법론을 적용하는 것은 아래와 같습니다 (이전에 다 했던겁니다).

***

- 1.첫 번째로 파라메터 $$\alpha$$를 초기화한다. 
- 2.로그 사후 분포를 최대화 함으로써 매개변수 $$w$$의 값을 찾는다. (마찬가지로 이는 정규화 항이 포함된 Binary Cross Entropy (BCE) 수식을 최소화 하는 것이 될겁니다.)

$$
E(w) = -ln p(D \vert w) + \frac{\alpha}{2} w^T w
$$

- 3.MAP의 해인, $$w_{MAP}$$를 구하고 나면 음의 로그 가능도 (negative log likelihood, nll)의 이차 미분값들로 이루어진 Hessian Matrix, $$H$$를 구한다.
- 4.이를 이용해 posterior의 근사 분포를 구한다. (라플라스 근사)
- 5.(optional) prior의 분산, $$\alpha$$마저 최적화한다. 이를 위한 주변 가능도 (marginal likelihood)는 아래와 같다.

$$
lnp(D \vert \alpha) \approx -E(w_{MAP}) -\frac{1}{2} ln \vert A \vert + \frac{W}{2} ln \alpha
$$

$$
E(w_{MAP}) = - \sum_{n=1}^{N} \{ t_n ln y_n + (1-t_n) ln(1- y_n) \} + \frac{\alpha}{2} w_{MAP}^T w_{MAP}
$$

여기서 $$y_n  \equiv y(x_n, w_{MAP})$$ 이며, 이 증거 함수를 $$\alpha$$에 대해서 최대화 하면 된다.

***

이 $$\alpha$$를 결정하기 위해서 증거 방법론을 이용하는 것에 대해서는 *Fig. 5.22.*에 나와있습니다.


![Fig5.22](/assets/images/PRML_5.7/Fig5.22.png)
*Fig. 5.22. Binary Classification의 예시. 최적의 결정 경계는 녹색이며, 8개의 은닉 유닛을 가지는 2층 짜리 NN을 MLE로 추론한 결정 경계는 검은색, 빨간색 곡선은 정규화 항을 추가한 경우의 결과를 표현하고 있다.빨간색 곡선의 경우 정규화항의 $$\alpha$$ 값은 증거 방법론을 통해 최적화 되었는데, 이 때 초기값은 $$\alpha=0$$을 사용했다. 증거 방법론을 사용한 경우 과적합 현상이 현저히 줄어듬을 볼 수 있다.*

```
아마 지금은 w에 대한 MAP 솔루션을 먼저 구하고, alpha, beta (분류 문제에서는 beta가 없다고 했으니 빼고 생각)를 구하는 걸로 끝인 듯 합니다. 이렇게 구해진 걸 바탕으로 Baysian Inference를 하는건 다른 문제? 같네요.
```

마지막으로 우리는 이렇게 구한 파라메터들을 통해 unseed 데이터에 대한 예측 분포를 찾는 것을 해 볼것인데,

$$
p(t \vert x,D) = \int p(t \vert x,w) q(w \vert D) dw
$$

마찬가지로 이 적분은 네트워크 함수의 비선형성으로 인해서 계산해내기 매우 어렵다고 합니다. 
가장 단순하게 이를 근사하는 방법은 사후 분포가 매우 좁다고 가정하고 근사치를 구하는 건데, 이 때의 근사치는 아래와 같습니다.

$$
p(t \vert x, D) \approx p(t \vert x, w_{MAP})
$$

이는 또한 사후 분포의 분산을 고려함으로써 이 근사치를 개선할 수 있습니다.
하지만 이 경우 회귀 문제에서 사용했던 네트워크 출력값에 대한 선형 근사는 적합하지 않게 되는데요, 왜냐하면 로지스틱 시그모이드 출력 유닛 활성화 함수는 출력값이 $$(0,1)$$의 범위상에 존재하도록 제약하기 때문입니다. 
대신에 여기서는 출력 유닛에 대한 선형 근사치를 사용할 수 있습니다.

$$
a(x,w) \approx a_{MAP}(x) + b^T (w - w_{MAP})
$$

여기서 $$a_{MAP}(x) = a(x,w_{MAP})$$와 $$ b \equiv \bigtriangledown a(x,w_{MAP})$$는 역전파를 통해서 구할 수 있습니다.

```
여기서 말하는 바는 우리가 최종 출력 유닛 (logit)을 구한 뒤 sigmoid나 softmax 함수를 통과시키기 전까지에 대한 근사치만 생각하겠다는 겁니다.
```

$$
p(a \vert x, D) = \int \delta (a - a(x,w) ) q(w \vert D) dw
$$

$$
p(a \vert x, D) = \int \delta (a - a_{MAP}(x) - b^T (x) (w-w_{MAP}) ) q(w \vert D) dw
$$

여기서 $$q(w \vert D)$$는 당연히 사후 분포의 가우시안 근사에 해당하며, 4.5.2절에서 이 분포가 가우시안 분포이며, 평균값으로 $$a_{MAP} \equiv a(x,w_{MAP})$$를 가지고 분산으로 다음을 가진다는 것을 알 수 있습니다.

$$
\sigma_a^2(x) = b^T (x) A^{-1} b(x)
$$

마지막으로 예측 분포를 구하기 위해서는 다음 식에 따라서 $$a$$에 대한 Marginalization을 시행하면 .

$$
p(t=1 \vert x,D) = \int \sigma(a) p(a \vert x,D)da
$$

여기서 가우시안과 로지스틱 시그모이드의 Convolution을 계산하기는 매우 어렵기 때문에 식 4.153의 근사식을 바로 위의식에 적용해서 아래의 식을 구할 수 있습니다.

$$
p(t=1 \vert x,D) = \sigma ( \kappa (\sigma_{a}^2) a_{MAP})
$$

여기서 $$\kappa(\cdot)$$은 식 4.154에 정의되어 있으며, $$\sigma_a^2$$와 $$b$$는 모두 $$x$$의 함수입니다.



![Fig5.23](/assets/images/PRML_5.7/Fig5.23.png)
*Fig. 5.23. An illustration of the Laplace approximation for a Bayesian neural network having 8 hidden units with ‘tanh’ activation functions and a single logistic-sigmoid output unit. 파라메터들은 scaled conjugate gradients을 사용해서 찾았으며, 하이퍼파라메터인 $$\alpha$$ 는 evidence framework을 사용해서 찾아냈다. 왼쪽 그림은 매개변수 $$w_{MAP}$$ 에 대한 점 추정을 바탕으로 단순 근사 (simple approximation (5.185))를 적용한 결과이다. 여기서 녹색 경계선은 $$y = 0.5$$ 인 경우에 대한 결정 경계이며, 나머지 곡선들은 각각 $$y = 0.1, 0.3, 0.7, 0.9$$ 일 때의 출력 확률에 해당한다. 오른쪽 그림은 식 (5.190)을 이용한 것이다. Marginalization의 효과로 곡선이 더 넓게 퍼졌고, 그에 따라 예측치의 신뢰도가 내려갔다. 따라서 각각의 입력 데이터 포인트 $$x$$에 대해서, 사후확률이 $$0.5$$로 몰리게 되었다. 반면에 $$y = 0.5$$ 인 경계선은 왼쪽과 동일하다.*










## <mark style='background-color: #fff5b1'> Bayesian Method in Deep Learning </mark>

- Posterior is intractable
- Millions of parameters
- Large datasets
- Unclear which priors to use












### <mark style='background-color: #dcffe4'> Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning </mark>

![net](/assets/images/PRML_5.7/net.jpeg){: width="40%"}
*Additive Fig.*


![net](/assets/images/PRML_5.7/gp_net.jpeg){: width="40%"}
*Additive Fig.*


![net](/assets/images/PRML_5.7/do_net.jpeg){: width="40%"}
*Additive Fig.*







### <mark style='background-color: #dcffe4'> Uncertainty in Deep Learning </mark>



![mcmc_bnn](/assets/images/PRML_5.7/mcmc_bnn.png)
*Additive Fig.*









## <mark style='background-color: #fff5b1'> How Can We Do Approximate Bayesian Inference? </mark>

- Laplace Approximation
- Variational Inference 
- Markov Chain Monte Carlo (MCMC)
- Geometrically Inspired Methods



### <mark style='background-color: #dcffe4'> BNN using Variational Inference </mark>

$$
w^{MLE} = arg max_w log P(D \vert w)
$$

$$
= arg max_w \sum_i log p(y_i \vert x_i, w)
$$

$$
w^{MAP} = arg max_w log P(w \vert D)
$$

$$
= arg max_w log P(D \vert w) + log P(w)
$$

만약 w에 대한 prior분포가 가우시안분포라면 L2 regularisation이, Laplace prior라면 L1 regularisation이 도출됩니다.


원래의 Bayesian Inference라면

$$
P(\hat{y} \vert \hat{x}) = \mathbb{E}_{p(w \vert D)} [ P(\hat{y} \vert \hat{x},w) ]
$$

우리는 마찬가지로 $$p(w \vert D)$$를 근사한 $$q(w \vert \theta)$$를 원하는데, 

$$
\theta^{\ast} = arg min_{\theta} KL [ q(w \vert \theta) \parallel P(w \vert D)]
$$

$$
= arg min_{\theta} \int q(w \vert \theta) log \frac{ q(w \vert \theta) }{ P(w) P(D \vert w) } dw
$$

$$
= arg min_{\theta} \int q(w \vert \theta) log \frac{ q(w \vert \theta) }{ p( w \vert X,Y ) } dw
$$


$$
= arg min_{\theta} KL [q(w \vert \theta) \parallel P(w) ] - \mathbb{E}_{q(w \vert \theta)} [ log P(D \vert w) ]
$$

최종 Cost Function 

$$
F(D,\theta) = KL [q(w \vert \theta) \parallel P(w)] - \mathbb{E}_{q(w \vert \theta)} [ log P(D \vert w) ]
$$

Monte Carlo Sample from Variational Posterior $$q(w^{(i)} \vert \theta)$$

$$
F(D,\theta) \approx \sum_{i=1}^n log q(w^{(i)} \vert \theta) - log P(w^{(i)}) - log P(D \vert w^{(i)})
$$




***

- ELBO Derivation

$$
\begin{aligned}

& \text{log evidence} = log (p( Y \vert X )) = log ( \int p(Y \vert X, w) p(w) dw ) \geq \int log ( p(Y \vert X, w) ) p(w) dw &\\

& = log ( \int p(Y \vert X, w) \frac{p(w)}{q(w \vert \theta) } q(w \vert \theta) dw ) \geq \int log ( p(Y \vert X ) \frac{ p(w) }{ q(w \vert \theta) } ) q(w \vert \theta) dw & \\

& = \int log (p(Y \vert X,w)) q(w \vert \theta) dw - \int log (\frac{q(w \vert \theta)}{p(w)} ) q(w \vert \theta) dw & \\

& \geq  \mathbb{E}_{q(w \vert \theta)} [ log(p(Y \vert X, w))] - KL(q(w \vert \theta) \parallel p(w)) &

\end{aligned}
$$

- ELBO Derivation 2

$$
\begin{aligned}

& \text{log evidence} = log (p( Y \vert X )) = log ( \int p(Y \vert X, w) p(w) dw ) & \\

& = log \int p( Y \vert X, w) p(w) \frac{q(w \vert \theta)}{q(w \vert \theta)} & \\

& = log \mathbb{E}_{w \sim q(w \ vert \theta)} [ p( Y \vert X, w) p(w) \frac{1}{q(w \vert \theta)} ] & \\

&& \\


\end{aligned}
$$

Jensen's Inequality 

$$
\begin{aligned}

& log\mathbb{E}[y] \geq \mathbb{E}[logy] & 

\end{aligned}
$$

$$
\begin{aligned}

& log p(y \vert x) = log \mathbb{E}_{w \sim q(w \vert \theta)} [ \frac{p(y \vert x,w) p(w) }{ q(w \vert \theta) } ]  & \\

& \geq  & log \mathbb{E}_{w \sim q(w \vert \theta)} [ \frac{p(y \vert x,w) p(w) }{ q(w \vert \theta) } ] = \mathbb{E}_{w \sim q(w \vert \theta)} [log p(y \vert x,w) + log p(w)] - \mathbb{E}_{w \sim q(w \vert \theta)} [log q(w \vert \theta) ] &  \\

& \geq \mathbb{E}_{w \sim q(w \vert \theta)} [log p(y \vert x,w) + log p(w)] + H(q(w \vert \theta)) & \\ 


& L = \mathbb{E}_{w \sim q(w \vert \theta)} [log p(y \vert x,w) + log p(w)] + H(q(w \vert \theta)) &

\end{aligned}
$$

how tight this bound?

$$
\begin{aligned}

& D_{KL} (q(w \vert \theta) \parallel p(w \vert D)) = \mathbb{E}_{q \sim q(w \vert \theta)} log \frac{ q(w \vert \theta)  }{ p(w \vert D) } & \\

& = \mathbb{E}_{q \sim q(w \vert \theta)} log \frac{ q(w \vert \theta) p(D) }{ p(w,D) }  & \\

& = - \mathbb{E}_{q \sim q(w \vert \theta)} [ log p(w,D) ]  + \mathbb{E}_{q \sim q(w \vert \theta)} [log q(w \vert \theta) ] + \mathbb{E}_{q \sim q(w \vert \theta)} [log p(D)] & \\

& = - \mathbb{E}_{q \sim q(w \vert \theta)} [ log p(D \vert w) + log p(w) ]  + \mathbb{E}_{q \sim q(w \vert \theta)} [log q(w \vert \theta) ] + \mathbb{E}_{q \sim q(w \vert \theta)} [log p(D)] & \\


& = - \mathbb{E}_{q \sim q(w \vert \theta)} [ log p(D \vert w) + log p(w) ]  - H( q(w \vert D)) + \mathbb{E}_{q \sim q(w \vert \theta)} [log p(D)] & \\

& = - L + log p(D) & \\

\end{aligned}
$$

`KLD + Lower bound = evidence`, so we need to push up bound and lower KLD 

$$
\begin{aligned}

& L = \mathbb{E}_{w \sim q(w \vert \theta)} [log p(y \vert x,w) + log p(w)] + H(q(w \vert \theta)) & \\

& = \mathbb{E}_{w \sim q(w \vert \theta)} [log p(y \vert x,w)] + \mathbb{E}_{w \sim q(w \vert \theta)} [ log p(w)] + H(q(w \vert \theta)) & \\

& = \mathbb{E}_{w \sim q(w \vert \theta)} [log p(y \vert x,w)] - D_{KL} ( q(w \vert \theta) \parallel p(w) )  & \\

\end{aligned}
$$

***





## <mark style='background-color: #fff5b1'> References </mark>

1. [Gal, Yarin, and Zoubin Ghahramani. "Dropout as a bayesian approximation: Representing model uncertainty in deep learning." In international conference on machine learning, pp. 1050-1059. PMLR, 2016.](http://proceedings.mlr.press/v48/gal16.pdf)

2. [(Yarin Gal)THESIS: UNCERTAINTY IN DEEP LEARNINGLink to this paper](https://www.cs.ox.ac.uk/people/yarin.gal/website/thesis/thesis.pdf)

3. [Weight Uncertainty in Neural Networks](https://arxiv.org/pdf/1505.05424)

4. [NYU Bayesian Deep Learning : Tutorials](https://wjmaddox.github.io/assets/BNN_tutorial_CILVR.pdf)

5. [Yarin Gal's Blog](http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html)

6. [Bayesian Deep Learning NIPS Workshop](http://bayesiandeeplearning.org/)

7. [Variational inference in Bayesian neural networks](http://krasserm.github.io/2019/03/14/bayesian-neural-networks/)
