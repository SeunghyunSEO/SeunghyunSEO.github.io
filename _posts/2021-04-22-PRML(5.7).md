---
title: 5.7 Bayesian Neural Networks
categories: Brief_Review_for_PRML
tag: [PRML,MachineLearning,ML]

toc: true
toc_sticky: true

comments: true
---


---
< 목차 >
{: class="table-of-content"}
* TOC
{:toc}
---


## <mark style='background-color: #fff5b1'> PRML 5.7 </mark>

### <mark style='background-color: #dcffe4'> 5.7.1 사후 매개변수 분포 (Posterior parameter distribution) </mark>

입력 $$x$$에 대해서 단일 타겟 변수 $$t$$를 예측하는 회귀 문제를 고려할 것입니다 ($$t$$는 연속적인 값을 가지게 됩니다).
연속적인 출력 분포를 가정하기 위해서 익숙한 `가우시안 분포`를 가정해보도록 하겠습니다.

$$
p(t \vert x,w,\beta) = N(t \vert y(x,w), \beta^{-1})
$$

분산을 나타내는 값이 $$\beta^{-1}$$이므로 $$\beta$$는 그와 반대인 정밀도를 의미하게 되겠습니다.
출력 가우시안 분포의 평균 (mean, $$\mu$$)를 추론하게 될 파라메터 $$w$$에 대한 분포, `prior` 또한 위의 likelihood와 유사한 가우시안 분포로 가정하겠습니다. 

$$
p(w \vert \alpha) = N(w \vert 0, \alpha^{-1} I)
$$

N개의 관측값 (Observations, Samples) $$x_1,x_2, \cdots, x_n$$과 이에 해당하는 표적값 (Target) $$D=\{ t_1,t_2,\cdots,x_n \}$$에 대해서 `likelihood`는 아래와 같습니다.

$$
p(D \vert w,\beta) = \prod_{n=1}^N N(t_n \vert y(x_n,w),\beta^{-1})
$$

(각 샘플들이 독립을 가정하기 때문에 개별 샘플의 확률 곱으로 최종 likelihood를 나타낼 수 있는 것)


여기에 `posterior`는 일반적으로 아래와 같은 관계식을 따르므로

$$
posterior \approx likelihood \times prior
$$

최종적으로 다음 형태의 posterior를 얻을 수 있습니다.

$$
p(w \vert D,\alpha,\beta) \approx p(D \vert w,\beta) \times p(w \vert \alpha)
$$

$$y(x,w)$$의 $$w$$에 대한 비선형성으로 인해서 위의 식은 비 가우시안 분포가 될 것입니다.


우리는 앞서 배운 `라플라스 근사법 (Laplace Approximation)` 을 사용해서 posterior의 가우시안 근사치를 구할 수 있는데, 이를 위해서는 사후 분포의 (지역적) 최대값을 찾아야 하며, (= MAP solution을 의미함) 이는 activation function이 가지는 전체 함수의 비선형성 때문에 닫힌 해 (closed-form)를 구할 수 없으므로 반복적인 최적화를 통해 구해야 합니다. 


`MAP Solution`은 간단하게 posterior에 대해서 $$log$$를 취한 뒤 최적화를 통해 구할 수 있습니다.

$$
ln p(w \vert D) = -\frac{\alpha}{2} w^T w - \frac{\beta}{2} \sum_{n=1}^N { \{ y(x_n,w) - t_n \} }^2 + const
$$

(앞서 배운 것 처럼 우리가 likelihood로 가우시안 분포를 가정했으므로 (=회귀 문제) MSE loss가 나오는 것은 당연하고, 여기에 파라메터에 대해서 또 한번 가우시안 prior를 가정했으므로 정규화 항이 딸려서 나오는 것은 당연하겠죠?)


일단 우리는 prior와 likelihood의 분산(역으로는 정밀도)를 나타내는 파라메터 $$\alpha,\beta$$는 고정된 값이라고 생각하겠습니다 (이거는 학습 매개변수가 아닌것).
오차 역전파 (Error Backpropagation)과 경사 하강법 (Gradient Descent)를 이용해서 $$w_{MAP}$$를 찾은 뒤, 음의 로그 사후 분포의 이차 미분 행렬을 바탕으로 우리는 `지역적 가우시안 근사치`를 얻을 수 있습니다.

$$
A = - \bigtriangledown \bigtriangledown ln p(w \vert D,\alpha,\beta) = \alpha I + \beta H
$$

($$H$$는 오차 함수의 $$w$$ 성분들에 대한 이차 미분값들로 이루어진 헤시안 행렬임)


우리는 앞서 4절에서 배운 것 처럼 `posterior를 근사한 분포`를 아래처럼 얻을 수 있다.

$$
q(w \vert D) = N(w \vert w_{MAP}, A^{-1} )
$$


우리가 머신러닝을 통해서 최종적으로 원하는 것은 데이터를 통해 학습한 파라메터를 가지고, 새로운 unseen 입력 데이터에 대해서 그럴싸한 추론을 하는 겁니다. 

$$
p(t \vert x,D)
$$

이러한 머신런이 방법론들 중 `베이지안 방법론`의 목적은 파라메터를 점 추정 하는것에 그치지 않고 (MLE나 MAP는 최대값인 파라메터 딱 하나만을 결과물로 취함), 모두 고려해 weight에 대한 uncertainty를 최대한 없애는 것이기 때문에, 가능한 파라메터들에 대해서 모두 결과값을 구해 이를 Averaging하는 것이고, 이를 위해 사후 분포를 주변화 (marginal) 한 수식은 아래와 같이 표현이 가능하며,

$$
p(t \vert x,D) = \int p(t \vert x,w) p(w \vert D, \alpha, \beta) dw
$$

우리는 라플라스 근사식을 통해서 $$\int$$속 복잡한 posterior를 근사 분포로 만들어 최종적으로 다음과 같은 수식을 얻을 수 있는겁니다.

$$
p(t \vert x,D) = \int p(t \vert x,w) q(w \vert D) dw
$$

이제 학습이 끝난 후 어떤 unseen 데이터 $$x$$가 들어오면 이를 위의 수식에 넣어 적분을 통해 $$t$$값을 추론해 내기만 하면 되지만, 그럼에도 이 적분식을 해석적으로(?) 계산하기는 여전히 어려운데 왜냐하면 이는 $$w$$의 함수로 주어지는 네트워크 함수 $$y(x,w)$$가 비선형이기 때문이라고 합니다. (음... 잘 와닿지 않네요 아직)







### <mark style='background-color: #dcffe4'> 5.7.2 초매개변수의 최적화 (Hyperparameter optimization) </mark>

여태까지는 likelihood와 prior의 분산을 의미하는 $$\alpha,\beta$$가 고정되어있는 경우를 가정하고 문제를 풀었는데요 (fixed variance problem), 
우리는 앞서 3절에서 논의 했던 `증거 방법론 (evidence approximation)`과 `라플라스 근사법 (laplace approximation)`을 통해 구한 사후 분포의 가우시안 근사치를 바탕으로 초매개변수 (hyperparam), $$\alpha,\beta$$를 구할 수도 있습니다. 



$$\alpha,\beta$$의 주변 가능도 (Evidence, Marginal Likelihood)는 네트워크 가중치들에 대한 적분을 통해서 구할 수 있는데요,

$$
p(D \vert \alpha, \beta) = \int p(D \vert w, \beta) p(w \vert \alpha) dw
$$

이는 4절에서 구한 라플라스 근사 결과치를 바탕으로 쉽게 계산할 수 있고 이에 로그를 취하면 아래와 같은 식을 얻게 됩니다.

$$
ln(D \vert \alpha, \beta) \approx -E(w_{MAP}) - \frac{1}{2} ln \vert A \vert + \frac{W}{2} ln \alpha + \frac{N}{2} ln \beta + \frac{N}{2} ln(2\pi)
$$

$$
E(w_{MAP}) = \frac{\beta}{2} \sum_{n=1}^N { \{ y(x_n,w_{MAP}) - t_n \} }^2 + \frac{\alpha}{2} w_{MAP}^T w_MAP
$$

(여기서 $$W$$는 총 매개변수 숫자에 해당합니다.)


증거 방법론에서는 $$ln p(D \vert \alpha,\beta)$$값을 최대화해서 $$\alpha,\beta$$에 대한 점 추정값을 구할 수 있습니다.


선형 모델의 경우와 마찬가지로 비선형 모델인 뉴럴 네트워크를 사용할 경우에도 사후 분포를 업데이트 하는 과정과 $$\alpha,\beta$$를 업데이트 하는 과정을 번갈아가며 진행하면서 최적화 하면 됩니다.






### <mark style='background-color: #dcffe4'> 5.7.3 베이지안 뉴럴 네트워크를 통한 분류 (Bayesian neural networks for classification) </mark>

베이지안 뉴럴 네트워크를 통해서 문제를 풀어보도록 할건데요, 다중 분류 문제는 이진 분류 문제와 크게 다르지 않기 때문에 우선 간단한 이진 분류 문제를 가정해보도록 하겠습니다.

$$
ln p(D \vert w) = \sum_{n=1}^{N} \{ t_n ln y_n + (1-t_n) ln(1-y_n) \} 
$$

여기서 분산을 나타내는 $$\beta$$가 존재하지 않는 이유는, 데이터 포인트들이 올바르게 레이블링 되어있다고 가정하기 때문입니다. 
이제 prior를 가정할것인데, 앞선 문제들과 마찬가지로 등방 가우시안 분포를 가정하도록 할겁니다.

$$
p(w \vert \alpha) = N(w \vert 0, \alpha^{-1}I)
$$

이 모델에 라플라스 방법론을 적용하는 것은 아래와 같습니다.

- 1.첫 번째로 파라메터 $$\alpha$$를 초기화한다. 
- 2.로그 사후 분포를 최대화 함으로써 매개변수 $$w$$의 값을 찾는다. (마찬가지로 이는 정규화 항이 포함된 Binary Cross Entropy (BCE) 수식을 최소화 하는 것이 될겁니다.)

$$
E(w) = -ln p(D \vert w) + \frac{\alpha}{2} w^T w
$$

- 3.MAP의 해인, $$w_{MAP}$$를 구하고 나면 음의 로그 가능도 (negative log likelihood, nll)의 이차 미분값들로 이루어진 Hessian Matrix, $$H$$를 구한다.
- 4.이를 이용해 posterior의 근사 분포를 구한다. (라플라스 근사)
- 5.(optional) prior의 분산, $$\alpha$$마저 최적화한다. 이를 위한 주변 가능도 (marginal likelihood)는 아래와 같다.

$$
lnp(D \vert \alpha) \approx -E(w_{MAP}) -\frac{1}{2} ln \vert A \vert + \frac{W}{2} ln \alpha
$$

$$
E(w_{MAP}) = - \sum_{n=1}^{N} \{ t_n ln y_n + (1-t_n) ln(1- y_n) \} + \frac{\alpha}{2} w_{MAP}^T w_{MAP}
$$


![Fig5.22](/assets/images/PRML_5.7/Fig5.22.png)
*Fig. 5.22 Binary Classification의 예시. 최적의 결정 경계는 녹색이며, 8개의 은닉 유닛을 가지는 2층 짜리 NN을 MLE로 추론한 결정 경계는 검은색, 빨간색 곡선은 정규화 항을 추가한 경우의 결과를 표현하고 있다.빨간색 곡선의 경우 정규화항의 $$\alpha$$ 값은 증거 방법론을 통해 최적화 되었는데, 이 때 초기값은 $$\alpha=0$$을 사용했다. 증거 방법론을 사용한 경우 과적합 현상이 현저히 줄어듬을 볼 수 있다.*






![Fig5.23](/assets/images/PRML_5.7/Fig5.23.png)
*Fig. 5.23*





## <mark style='background-color: #fff5b1'> Bayesian Deep Learning </mark>

- Posterior is intractable
- Millions of parameters
- Large datasets
- Unclear which priors to use


## <mark style='background-color: #fff5b1'> How Can We Dd Approximate Bayesian Inference? </mark>

- Laplace Approximation
- Variational Inference 
- Markov Chain Monte Carlo (MCMC)
- Geometrically Inspired Methods

## <mark style='background-color: #fff5b1'> References </mark>

1. [Gal, Yarin, and Zoubin Ghahramani. "Dropout as a bayesian approximation: Representing model uncertainty in deep learning." In international conference on machine learning, pp. 1050-1059. PMLR, 2016.](http://proceedings.mlr.press/v48/gal16.pdf)

2. [(Yarin Gal)THESIS: UNCERTAINTY IN DEEP LEARNINGLink to this paper](https://www.cs.ox.ac.uk/people/yarin.gal/website/thesis/thesis.pdf)

3. [Weight Uncertainty in Neural Networks](https://arxiv.org/pdf/1505.05424)

4. [NYU Bayesian Deep Learning : Tutorials](https://wjmaddox.github.io/assets/BNN_tutorial_CILVR.pdf)

5. [Yarin Gal's Blog](http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html)

6. [Bayesian Deep Learning NIPS Workshop](http://bayesiandeeplearning.org/)
