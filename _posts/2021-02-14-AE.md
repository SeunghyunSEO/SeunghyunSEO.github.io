---
title: From AutoEncoder(AE) to Variational AutoEncoder(VAE)
categories: MachineLearning
tag: [MachineLearning,ML]

toc: true
toc_sticky: true
---

본 포스트는 [lillog의 'from AutoEncoder to beta VAE' 블로그 post](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)와 [이활석(전 Clova leader)님의 '오토 인코더의 모든 것 (1~3)'](https://www.youtube.com/watch?v=o_peo6U7IRM) [+(presentation slide)](https://www.slideshare.net/NaverEngineering/ss-96581209) 등의 자료들을 참고하여 만들었습니다.

- <mark style='background-color: #fff5b1'> Dimensionality Reduction </mark>

오토인코더(AutoEncoder, AE)는 비지도 학습(Unsupervised Learning)을 통해서 어떻게하면 큰 차원의 입력 데이터를 작은 차원의 데이터로 줄일까? 근데 또 막무가내로 줄이는건 아니고 의미있는 정보는 최대한 가지면서(혹은 더 대단한 성분(more efficient and compressed representation)을 추출하면서) 줄일 수 있을까? 라는 생각에서 디자인된 뉴럴 네트워크(Neural Network, NN) 입니다.  

물론 차원 축소(Dimensionality Reduction) 알고리즘에는 오토인코더만 있는게 아니고, non-parametric한 방법인 주성분 분석(Principal Components Analysis)이나 선형 판별 분석(Linear Discriminant Analysis, LDA) 등 다양한 방법이 존재합니다. 

|Dimensionality Reduction|
|---|
|1.	Principal component analysis (PCA)|
|2.	Non-negative matrix factorization (NMF)|
|3.	Kernel PCA|
|4.	Graph-based kernel PCA|
|5.	Linear discriminant analysis (LDA)|
|6.	Generalized discriminant analysis (GDA)|
|7.	Autoencoder|
|8.	t-SNE|
|9.	UMAP|
|...|

*출처 : [Wikipidea 문서](https://en.wikipedia.org/wiki/Dimensionality_reduction), 물론 위키에 있는 방법이 전부가 아니며, 다른 방법들도 많이 있습니다.*

![pcavslda](https://user-images.githubusercontent.com/48202736/107734574-122a5c80-6d41-11eb-85fe-aa05b23df9f4.png)
{: style="width: 70%;" class="center"}
*Fig. 차원 축소 알고리즘의 대표적인 예인 PCA, LDA 출처 : [lecture slide from Haesun Park](https://project.inria.fr/siamsummerschool/files/2019/06/Lec2LRA.pdf)*

하지만 이번 글에서는 이 많은 것들을 전부 다룰 수는 없고, 딥러닝의 AE만 다루게 될 것입니다.


{: class="table-of-content"}
* TOC
{:toc}

## <mark style='background-color: #fff5b1'> AutoEncoder (AE) </mark>

오토 인코더는 아래와 같이 생겼습니다. 

우리가 앞서 말했던 것 처럼 오토 인코더라는 차원을 축소하는 것이 목적입니다. (물론 그렇게 줄어든 차원 속에 더욱 중요하고 효율적인 정보가 담겨있다는 믿음도 있습니다.)
사실 우리가 정말 원하는 것은 오토 인코더의 `인코더(Encoder)` 부분 그러니까 고차원의 입력 데이터를 저차원으로, 정보를 압축(Encoding)하는 부분입니다.

입력 데이터 x를 네트워크에 통과시켜 다시 x를 만들어내게끔 하는 비지도 학습 방법으로 학습 시키기 위해서 다시 저차원의 압축된 정보를 원래의 차원으로 복원시켜줄 `디코더(Decoder)`를 덧붙혀서 학습 시키는 겁니다.

<img width="850" alt="ae1" src="https://user-images.githubusercontent.com/48202736/107733559-a7782180-6d3e-11eb-8cfc-35be14f7d4eb.png">
*Fig. 오토인코더 (AutoEncoder, AE) 모델 아키텍쳐, 이미지 출처 : [lilian's blog](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)*

그래서 오토인코더는 위와같이 네트워크가 좁아졌다가 다시 넓어지는 형태로 생겼습니다. 가운데 차원이 확 좁아지는 곳은 물병의 목 같다고 해서 `Bottle Neck` 이라고 합니다.   

이제 수식적인 term들을 추가해서 글을 전개하기 위해 Notation을 아래와 같이 정의하고 이야기하도록 하겠습니다.  

### Notation

{: class="info"}
| Symbol | Mean(Kor) | Mean(Eng) |
| ---------- | ---------- ||
| $$\mathcal{D}$$ | 데이터 셋 집합, 크기는 n | The dataset, $$\mathcal{D} = \{ \mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \dots, \mathbf{x}^{(n)} \}$$, contains $$n$$ data samples; $$\vert\mathcal{D}\vert =n $$. |
| $$\mathbf{x}^{(i)}$$ | 각 데이터 포인트는 d차원으로 이루어져 있음. | Each data point is a vector of $$d$$ dimensions, $$\mathbf{x}^{(i)} = [x^{(i)}_1, x^{(i)}_2, \dots, x^{(i)}_d]$$. |
| $$\mathbf{x}$$ | 데이터 셋 집합으로 부터 샘플링한 데이터 1개 | One data sample from the dataset, $$\mathbf{x} \in \mathcal{D}$$. |
| $$\mathbf{x}’$$| 축소했다가 디코더로부터 복원된 데이터 x | The reconstructed version of $$\mathbf{x}$$. |
| $$\tilde{\mathbf{x}}$$ | 노이즈가 섞인 데이터 x | The corrupted version of $$\mathbf{x}$$. |
| $$\mathbf{z}$$ | 인코더가 뱉은 표현 벡터 | The compressed code learned in the bottleneck layer. |
| $$a_j^{(l)}$$ | l번째 레이어의 j번째 뉴런의 활성 함수  | The activation function for the $$j$$-th neuron in the $$l$$-th hidden layer. |
| $$g_{\phi}(.)$$ | $$\phi$$로 매개변수 화 되어있는 인코더 (*What we want!*) | The **encoding** function parameterized by $$\phi$$. |
| $$f_{\theta}(.)$$ | $$\theta$$로 매개변수 화 되어있는 디코더 | The **decoding** function parameterized by $$\theta$$. |
| $$q_{\phi}(\mathbf{z}\vert\mathbf{x})$$ | 사후 확률 분포를 뱉는 '확률적' 인코더 (위의 인코더와 다름) |Estimated posterior probability function, also known as **probabilistic encoder**.  |
| $$p_{\theta}(\mathbf{x}\vert\mathbf{z})$$ | 마찬가지로 인코더가 예측한 확률 분포에서 샘플링을 통해 추출한 잠재 변수를 입력으로 하는 '확률적' 디코더 | Likelihood of generating true data sample given the latent code, also known as **probabilistic decoder**. |
| ---------- | ---------- |

수식을 포함해서 다기 얘기하자면,
기본적인 오토인코더 모델은 (추후에 기술할 예정인 VAE는 조금 다릅니다) 파라메터 $$\phi$$로 모델링 된 인코더 함수 $$g(.)$$와 파라메터 $$\theta$$로 모델링 된 디코더 $$f(.)$$로 이루어져있습니다.
병목 층(bottle neck layer)에서 학습이 된 representation은 $$\mathbf{z} = g_\phi(\mathbf{x})$$ 이며, 이를 입력받아 디코더를 통해 얻은 복원된 데이터는 $$\mathbf{x}' = f_\theta(g_\phi(\mathbf{x}))$$ 라고 합니다.

인코더와 디코더의 파라메터인 $$(\theta, \phi)$$는 각각 따로 학습되는것이 아니라 $$x$$를 넣어서 원래 입력값인 $$\mathbf{x} \approx f_\theta(g_\phi(\mathbf{x}))$$를 복원하는 과정에서 함께 학습이 됩니다.

이렇게 학습을 시키는 것은 `Cross Entropy Loss`를 사용하는 등 다양한 방법이 있지만, 일반적으로 간단하게 `Mean Squared Error Loss`를 사용해서 학습하게 됩니다.

$$
L_\text{AE}(\theta, \phi) = \frac{1}{n}\sum_{i=1}^n (\mathbf{x}^{(i)} - f_\theta(g_\phi(\mathbf{x}^{(i)})))^2
$$

### <mark style='background-color: #dcffe4'> Principal Components Analysis (PCA) vs AE </mark>

![pca3](https://user-images.githubusercontent.com/48202736/107734572-10f92f80-6d41-11eb-857e-18388f3dbe9c.png)
*Fig. 선형 차원 축소 알고리즘인 PCA (Kernel PCA아님) vs 비선형 차원 축소 알고리즘인 AE, 이미지 출처 : [link](https://www.researchgate.net/figure/Comparison-between-PCA-and-Autoencoder-15_fig1_340049776)*


![pca1](https://user-images.githubusercontent.com/48202736/107734566-0fc80280-6d41-11eb-9fd5-f461f94fc255.png)
![pca2](https://user-images.githubusercontent.com/48202736/107734571-10609900-6d41-11eb-91c7-c533d738b9a5.png)
*Fig. PCA vs AE 의 embedding space representation, 이미지 출처 : [link](https://stats.stackexchange.com/questions/190148/building-an-autoencoder-in-tensorflow-to-surpass-pca)*


### <mark style='background-color: #dcffe4'> Restricted Boltzman Machine (RBM) vs AE </mark>

### <mark style='background-color: #dcffe4'> Denoising AutoEncoder (DAE) </mark>

<img width="1035" alt="dae1" src="https://user-images.githubusercontent.com/48202736/107733564-aa731200-6d3e-11eb-9c43-5af450a2c0fb.png">

### <mark style='background-color: #dcffe4'> Contractive AutoEncoder (CAE) </mark>





## <mark style='background-color: #fff5b1'> Variational AutoEncoder (VAE) </mark>

<img width="961" alt="vae1" src="https://user-images.githubusercontent.com/48202736/107733571-ac3cd580-6d3e-11eb-99b9-92cd42df5d65.png">

### <mark style='background-color: #dcffe4'> AE vs VAE </mark>

<img width="850" alt="ae1" src="https://user-images.githubusercontent.com/48202736/107733559-a7782180-6d3e-11eb-8cfc-35be14f7d4eb.png">

<img width="1183" alt="vae2" src="https://user-images.githubusercontent.com/48202736/107733574-acd56c00-6d3e-11eb-8f4a-2c65d331c84d.png">


### <mark style='background-color: #dcffe4'> Objective Function of VAE : ELBO </mark>

### <mark style='background-color: #dcffe4'> Reparamaterization Trick </mark>

![reparam1](https://user-images.githubusercontent.com/48202736/107733569-aba43f00-6d3e-11eb-8f4d-4994745f83eb.png)






### <mark style='background-color: #dcffe4'> Conditional Variational AutoEncoder (CVAE) </mark>

### <mark style='background-color: #dcffe4'> Vector Quantized - Variational AutoEncoder (VQ-VAE) </mark>

<img width="1617" alt="vq-vae" src="https://user-images.githubusercontent.com/48202736/107733581-ae9f2f80-6d3e-11eb-94cf-f5b9e70f1812.png">







### <mark style='background-color: #dcffe4'> + Generative Adversarial Networks (GAN) </mark>





<br><br>

## <mark style='background-color: #fff5b1'> References </mark>

1. ['from AutoEncoder to beta VAE' form lillog](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)
2. ['오토 인코더의 모든 것 (1~3)' from Hwalseok Lee](https://www.youtube.com/watch?v=o_peo6U7IRM) 
3. ['On manifolds and autoencoders' from Pascal Vincent](http://videolectures.net/deeplearning2015_vincent_autoencoders/?q=vincent%20autoencoder)
