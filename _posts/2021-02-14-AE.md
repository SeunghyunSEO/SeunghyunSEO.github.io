---
title: (미완)From AutoEncoder(AE) to Variational AutoEncoder(VAE)
categories: DeepLearning
tag: [DeepLearning]

toc: true
toc_sticky: true
---

본 포스트는 [lillog의 'from AutoEncoder to beta VAE' 블로그 post](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)와 [이활석(전 Clova leader)님의 '오토 인코더의 모든 것 (1~3)'](https://www.youtube.com/watch?v=o_peo6U7IRM) [+(presentation slide)](https://www.slideshare.net/NaverEngineering/ss-96581209) 등의 자료들을 참고하여 만들었습니다.

---
< 목차 >
{: class="table-of-content"}
* TOC
{:toc}
---

## <mark style='background-color: #fff5b1'> Dimensionality Reduction </mark>

`오토인코더(AutoEncoder, AE)`는 비지도 학습(Unsupervised Learning)을 통해서 "어떻게하면 큰 차원의 입력 데이터를 작은 차원의 데이터로 줄일까? 근데 또 막무가내로 줄이는건 아니고 의미있는 정보는 최대한 가지면서(혹은 더 대단한 성분(more efficient and compressed representation)을 추출하면서) 줄일 수 있을까?" 라는 생각에서 디자인된 뉴럴 네트워크(Neural Network, NN) 입니다.  

물론 `차원 축소(Dimensionality Reduction)` 알고리즘에는 오토인코더만 있는게 아니고, non-parametric한 방법인 주성분 분석(Principal Components Analysis)이나 선형 판별 분석(Linear Discriminant Analysis, LDA) 등 다양한 방법이 존재합니다. 

|Dimensionality Reduction|
|---|
|1.	Principal component analysis (PCA)|
|2.	Non-negative matrix factorization (NMF)|
|3.	Kernel PCA|
|4.	Graph-based kernel PCA|
|5.	Linear discriminant analysis (LDA)|
|6.	Generalized discriminant analysis (GDA)|
|7.	Autoencoder|
|8.	t-SNE|
|9.	UMAP|
|...|

*출처 : [Wikipidea 문서](https://en.wikipedia.org/wiki/Dimensionality_reduction), 물론 위키에 있는 방법이 전부가 아니며, 다른 방법들도 많이 있습니다.*

![lda](/assets/images/ae_to_vae/pca_vs_lda.png)
*Fig. 차원 축소 알고리즘의 대표적인 예인 PCA, LDA 출처 : [lecture slide from Haesun Park](https://project.inria.fr/siamsummerschool/files/2019/06/Lec2LRA.pdf)*

하지만 이번 글에서는 AE에 대해서만 알아볼 것이고, 더 나아가 다양한 목적을 위한 AE의 Variation들에 대해서도 알아보도록 하겠습니다.





## <mark style='background-color: #fff5b1'> AutoEncoder (AE) </mark>

오토 인코더는 아래와 같이 생겼습니다. 

우리가 앞서 말했던 것 처럼 오토 인코더라는 차원을 축소하는 것이 목적입니다. (물론 그렇게 줄어든 차원 속에 더욱 중요하고 효율적인 정보가 담겨있다는 믿음도 있습니다.)
사실 우리가 정말 원하는 것은 오토 인코더의 `인코더(Encoder)` 부분 그러니까 고차원의 입력 데이터를 저차원으로, 정보를 압축(Encoding)하는 부분입니다.

입력 데이터 x를 네트워크에 통과시켜 다시 x를 만들어내게끔 하는 비지도 학습 방법으로 학습 시키기 위해서 다시 저차원의 압축된 정보를 원래의 차원으로 복원시켜줄 `디코더(Decoder)`를 덧붙혀서 학습 시키는 겁니다.


![ae](/assets/images/ae_to_vae/ae.png)
*Fig. 오토인코더 (AutoEncoder, AE) 모델 아키텍쳐, 이미지 출처 : [lilian's blog](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)*

그래서 오토인코더는 위와같이 네트워크가 좁아졌다가 다시 넓어지는 형태로 생겼습니다. 가운데 차원이 확 좁아지는 곳은 물병의 목 같다고 해서 `Bottle Neck` 이라고 합니다.   

이제 수식적인 term들을 추가해서 글을 전개하기 위해 Notation을 아래와 같이 정의하고 이야기하도록 하겠습니다.  





### Notation

{: class="info"}
| Symbol | Mean(Kor) | Mean(Eng) |
| ---------- | ---------- ||
| $$\mathcal{D}$$ | 데이터 셋 집합, 크기는 n | The dataset, $$\mathcal{D} = \{ \mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \dots, \mathbf{x}^{(n)} \}$$, contains $$n$$ data samples; $$\vert\mathcal{D}\vert =n $$. |
| $$\mathbf{x}^{(i)}$$ | 각 데이터 포인트는 d차원으로 이루어져 있음. | Each data point is a vector of $$d$$ dimensions, $$\mathbf{x}^{(i)} = [x^{(i)}_1, x^{(i)}_2, \dots, x^{(i)}_d]$$. |
| $$\mathbf{x}$$ | 데이터 셋 집합으로 부터 샘플링한 데이터 1개 | One data sample from the dataset, $$\mathbf{x} \in \mathcal{D}$$. |
| $$\mathbf{x}’$$| 축소했다가 디코더로부터 복원된 데이터 x | The reconstructed version of $$\mathbf{x}$$. |
| $$\tilde{\mathbf{x}}$$ | 노이즈가 섞인 데이터 x | The corrupted version of $$\mathbf{x}$$. |
| $$\mathbf{z}$$ | 인코더가 뱉은 표현 벡터 | The compressed code learned in the bottleneck layer. |
| $$a_j^{(l)}$$ | l번째 레이어의 j번째 뉴런의 활성 함수  | The activation function for the $$j$$-th neuron in the $$l$$-th hidden layer. |
| $$g_{\phi}(.)$$ | $$\phi$$로 매개변수 화 되어있는 인코더 (*What AE want!*) | The **encoding** function parameterized by $$\phi$$. |
| $$f_{\theta}(.)$$ | $$\theta$$로 매개변수 화 되어있는 디코더 | The **decoding** function parameterized by $$\theta$$. |
| $$q_{\phi}(\mathbf{z}\vert\mathbf{x})$$ | 사후 확률 분포를 뱉는 '확률적' 인코더 (위의 인코더와 다름) |Estimated posterior probability function, also known as **probabilistic encoder**.  |
| $$p_{\theta}(\mathbf{x}\vert\mathbf{z})$$ | 마찬가지로 인코더가 예측한 확률 분포에서 샘플링을 통해 추출한 잠재 변수를 입력으로 하는 '확률적' 디코더 (*What VAE want!*) | Likelihood of generating true data sample given the latent code, also known as **probabilistic decoder**. |
| ---------- | ---------- |

수식을 포함해서 다시 얘기하자면,
기본적인 오토인코더 모델은 (추후에 기술할 예정인 VAE는 조금 다릅니다) 파라메터 $$\phi$$로 모델링 된 인코더 함수 $$g(.)$$와 파라메터 $$\theta$$로 모델링 된 디코더 $$f(.)$$로 이루어져있습니다.
병목 층(bottle neck layer)에서 학습이 된 representation은 $$\mathbf{z} = g_\phi(\mathbf{x})$$ 이며, 이를 입력받아 디코더를 통해 얻은 복원된 데이터는 $$\mathbf{x}' = f_\theta(g_\phi(\mathbf{x}))$$ 라고 합니다.

인코더와 디코더의 파라메터인 $$(\theta, \phi)$$는 각각 따로 학습되는것이 아니라 $$x$$를 넣어서 원래 입력값인 $$\mathbf{x} \approx f_\theta(g_\phi(\mathbf{x}))$$를 복원하는 과정에서 함께 학습이 됩니다.

이렇게 학습을 시키는 것은 `Cross Entropy Loss`를 사용하는 등 다양한 방법이 있지만, 일반적으로 간단하게 `Mean Squared Error Loss`를 사용해서 학습하게 됩니다.

$$
L_\text{AE}(\theta, \phi) = \frac{1}{n}\sum_{i=1}^n (\mathbf{x}^{(i)} - f_\theta(g_\phi(\mathbf{x}^{(i)})))^2
$$








### <mark style='background-color: #dcffe4'> Principal Components Analysis (PCA) vs AE </mark>

사실 차원 축소 방법론에는 PCA와 같은 방법론도 있는데요, AE가 비선형 활성함수들을 사용한 신경망 (Neural Network, NN)이 아니라, 선형적인 특성만 이용한다면 이는 PCA와 크게 다르지 않은 결과를 만들어 냅니다.


(증명은 하지 않겠습니다.)


![pca_vs_ae](/assets/images/ae_to_vae/pca_vs_ae.png){: width="70%"}
*Fig. 선형 차원 축소 알고리즘인 PCA (Kernel PCA아님) vs 비선형 차원 축소 알고리즘인 AE, 이미지 출처 : [link](https://www.researchgate.net/figure/Comparison-between-PCA-and-Autoencoder-15_fig1_340049776)*

위의 그림에서는 원 데이터들이 일반적인 AE를 사용할 경우 `비선형 매니폴드 (Non-linear Manifold)`에 매핑된 것을 볼 수 있고, PCA를 사용할 경우 `선형 매니폴드 (Linear Manifold)`에 매핑된 것을 볼 수 있습니다.


또한 각각의 차원 축소 방법론을 사용해 (인코더를 사용해) MNIST 분류를 하는 경우 아래처럼 얼마나 같은 Class의 숫자끼리 뭉치는지 차이가 많이 나는 것을 확인할 수 있습니다.

![pca_vs_ae_embedding](/assets/images/ae_to_vae/pca_vs_ae_embedding.png)

![pca_vs_ae_embedding2](/assets/images/ae_to_vae/pca_vs_ae_embedding2.png)
*Fig. PCA vs AE 의 embedding space representation, 이미지 출처 : [link](https://stats.stackexchange.com/questions/190148/building-an-autoencoder-in-tensorflow-to-surpass-pca)*










### <mark style='background-color: #dcffe4'> Denoising AutoEncoder (DAE) </mark>

AE는 $$x$$를 given으로 다시 $$x$$를 예측하는 방법론으로, 오버피팅을 하게 되는 문제가 필연적으로 발생하는데,
`디노이징 오토인코더 (Denoisig Autoencoder, DAE)`는 이를 해결하기 위해 제안되었습니다.

의도적으로 입력 데이터에 노이즈 (Noise) 를 섞어서 (corrupt) 이를 다시 없애는 말 그대로 "De-Noise"하게 끔 인코더를 학습시키는 겁니다.
가장 간단하게는 단순히 입력값의 벡터 요소들을 "0" 으로 마스킹한다고 생각할 수 있습니다.
이렇게 함으로써 데이터를 증강 (Augmentation) 시키는 효과를 본다고 할 수도 있겠죠.

![dae](/assets/images/ae_to_vae/dae.png)

DAE는 수식적으로 아래처럼 간단히 나타낼 수 있습니다.

$$
\tilde{\mathbf{x}}^{(i)} &\sim \mathcal{M}_\mathcal{D}(\tilde{\mathbf{x}}^{(i)} \vert \mathbf{x}^{(i)})\\
L_\text{DAE}(\theta, \phi) &= \frac{1}{n} \sum_{i=1}^n (\mathbf{x}^{(i)} - f_\theta(g_\phi(\tilde{\mathbf{x}}^{(i)})))^2
$$

여기서 $$\tilde{\mathbf{x}}^{(i)} &\sim \mathcal{M}_\mathcal{D}(\tilde{\mathbf{x}}^{(i)} \vert \mathbf{x}^{(i)})$$ 가 의미하는 바는, 확률적인 분포로부터 특정 입력값을 마스킹하겠다는 뜻입니다.


이러한 `Denoising Auto-Encoding` 방법론은 간단하지만 현대의 강력한 딥러닝 모델들에서도 계속해서 쓰이는 방법론인데요,
그 대표적인 예로 `BERT`를 들 수 있습니다. 

![jay_bert](/assets/images/ae_to_vae/jay_bert.png)
*Fig. [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805)의 모식도. 버트는 DAE와 마찬가지로 sequence의 토큰 일부를 랜덤하게 마스크 토큰으로 바꾼 뒤, 해당 부분을 예측하는 비지도 학습 방식으로 학습한다.*

(이미지 출처 : [The Illustrated BERT, ELMo, and co. from Jay Alammar](http://jalammar.github.io/illustrated-bert/))


![xlnet_bert](/assets/images/ae_to_vae/xlnet_bert.png)
*Fig. [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/pdf/1906.08237)에서 언급된 버트. 버트는 Denoising Auto-Encoding 방법론의 일종이다.*











## <mark style='background-color: #fff5b1'> Variational AutoEncoder (VAE) </mark>

`Variational AutoEncoder (VAE)`는 Kingma라는 연구자에 의해서 2014년에 처음 제안되었습니다. [Kingma, Diederik P., and Max Welling. "Auto-encoding variational bayes."](https://arxiv.org/pdf/1312.6114)

사실 보기에는 이름 자체가 (Variational) `AutoEncoder`이기 때문에 오토인코더와 다른점이 거의 없어 보이지만, 그렇지 않습니다.

VAE는 논문에서도 저자들이 이야기하듯, variational bayesian 방법과 graphical model과 관련이 있는 모델이며, 
목적 자체도 오토인코더와 같이 차원축소를 목적으로 '저차원의 유의미한 representation을 추출한다' 가 아니라, `'데이터로부터 진짜 잠재 분포(latent distribution)를 찾아내고, 이로부터 샘플링을 통해 데이터셋에 없는 그럴싸한 새로운 데이터를 만들어내는 생성 모델(generative model)을 만든다'` 입니다.

$$x$$를 넣어서 원래 입력값인 $$\mathbf{x} \approx f_\theta(g_\phi(\mathbf{x}))$$를 복원해내는 비지도 학습 방식으로 학습되는 것은 똑같습니다.
하지만, 일반적인 오토인코더는 인코더를 앞서 말한 방식과 같이 학습하기 위해서 디코더를 붙힐 수 밖에 없었던 것이고, VAE는 디코더를 학습하기 위해서 인코더를 붙힌것으로 목적 자체가 다릅니다.

(+ `Variational` AutoEncoder의 'Variational'이란 앞서 말한 posterior라고 할 수 있는 latent distribution $$z$$를 direct로 학습할 수 없기 때문에 사용하는 근사방법인, 변분 추론(Variational Inference)에서 따온 이름입니다.)  

<br>

자, 이제 그림을 보면서 얘기를 하도록 하겠습니다. VAE는 아래와 같이 생겼습니다.

![vae1](/assets/images/ae_to_vae/vae1.png)
*Fig. Variational AutoEncoder의 모식도*


이전에 봤던 그림처럼 다시 구성하면 아래와 같습니다.

![ae](/assets/images/ae_to_vae/ae.png)
*Fig. 일반적인 AutoEncoder의 모식도*

![vae2](/assets/images/ae_to_vae/vae2.png)
*Fig. Variational AutoEncoder의 모식도 2, 여기서는 우리가 추정하고자 하는 latent distribution z가 가우시안 분포라고 생각했기 때문에 mean, variance를 찾게 됩니다.*








### <mark style='background-color: #dcffe4'> Objective Function of VAE : ELBO </mark>



### <mark style='background-color: #dcffe4'> Reparamaterization Trick </mark>

![repram](/assets/images/ae_to_vae/repram.png)












### <mark style='background-color: #dcffe4'> Conditional Variational AutoEncoder (CVAE) </mark>











### <mark style='background-color: #dcffe4'> Beta - Variational AutoEncoder (Beta-VAE) </mark>












### <mark style='background-color: #dcffe4'> Vector Quantized - Variational AutoEncoder (VQ-VAE) </mark>

![vq_vae](/assets/images/ae_to_vae/vq_vae.png)










### <mark style='background-color: #dcffe4'> Temporal Difference - Variational AutoEncoder (TD-VAE) </mark>











### <mark style='background-color: #dcffe4'> + Generative Adversarial Networks (GAN) </mark>














## <mark style='background-color: #fff5b1'> References </mark>

1. ['from AutoEncoder to beta VAE' form lillog](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)
2. ['오토 인코더의 모든 것 (1~3)' from Hwalseok Lee](https://www.youtube.com/watch?v=o_peo6U7IRM) 
3. ['On manifolds and autoencoders' from Pascal Vincent](http://videolectures.net/deeplearning2015_vincent_autoencoders/?q=vincent%20autoencoder)
