---
title: (미완) A Long Way to Deep Generative Models - From AutoEncoder (AE) to Variational AutoEncoders (VAEs)
categories: DeepLearning
tag: [DeepLearning]

toc: true
toc_sticky: true
---

본 포스트는 [CS W182 / 282A at UC Berkeley - Designing, Visualizing and Understanding Deep Neural Networks](https://cs182sp21.github.io/)강의, [lillog의 'from AutoEncoder to beta VAE'](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html) 블로그 포스트 그리고 [이활석님의 '오토 인코더의 모든 것 (1~3)'](https://www.youtube.com/watch?v=o_peo6U7IRM) 강의 [+(presentation slide)](https://www.slideshare.net/NaverEngineering/ss-96581209) 등의 자료들을 참고하여 만들어 졌습니다.




---
< 목차 >
{: class="table-of-content"}
* TOC
{:toc}
---



이번 글에서는 `심층 생성 모델 (Deep Generative Models)`의 대표적인 예인 `Variational AutoEncoder (VAE)`와 이의 다양한 Variation인 VQ-VAE 등에 대해서 알아볼 것이며, 이를 위해 AutoEncoder (AE)란 무엇인지? 변분 추론 (Variational Inference)란 무엇인지? 등에 대해서도 깊게 알아볼 것입니다.  



## <mark style='background-color: #fff5b1'> AutoEncoder (AE) </mark>


`오토인코더(AutoEncoder, AE)`는 "어떻게하면 큰 차원의 입력 데이터를 작은 차원의 데이터로 줄일까? 근데 또 막무가내로 줄이는건 아니고 의미있는 정보는 최대한 가지면서(혹은 더 대단한 성분(more efficient and compressed representation)을 추출하면서) 줄일 수 있을까?" 라는 생각에서 디자인된 뉴럴 네트워크(Neural Network, NN) 입니다.  

![cs285_lec17_ae1](/assets/images/ae_to_vae/cs285_lec17_ae1.png)
*Fig. 오토인코더 (AutoEncoder, AE) 모델 아키텍쳐*

AE는 위와 같이 구성되어 있고, `비지도 학습(Unsupervised Learning)` 방법으로 학습이 됩니다.
사실 우리가 위의 그림에서 정말 원하는 것은 `인코더(Encoder)` 부분인데요,
그러니까 고차원의 입력 데이터를 저차원으로, 정보를 압축(Encoding)하는 부분을 원한다는 겁니다.

그렇기 때문에, 우리는 원래는 디코더가 필요 없었으나, 입력 데이터 x를 네트워크에 통과시켜 다시 x를 만들어내게끔 하는 `비지도 학습 방법으로 인코더 네트워크를 학습`하기 위해서 다시 저차원의 압축된 정보를 원래의 차원으로 복원시켜줄 디코더(Decoder)를 추가적으로 덧붙힌 겁니다.


![cs285_lec17_ae2](/assets/images/ae_to_vae/cs285_lec17_ae2.png)
*Fig. AE가 원하는 것은 입력 데이터보다 상대적으로 저 차원 인 잠재 벡터 (hidden vector)를 출력해주는 Encoder를 학습하는 것이다. (여기서는 인코더를 통해 128차원의 벡터를 얻을 수 있는데, MNIST가 768차원인 것에 비하면 많이 줄었다는 것을 알 수 있다)*

오토인코더는 위와같이 네트워크가 좁아졌다가 다시 넓어지는 형태로 생겼기 때문에, 가운데 차원이 확 좁아지는 곳은 물병의 목 같다고 해서 `Bottle Neck` 이라고 합니다. 


오토인코더는 위와 같이 충분히 학습을 한 후에 인코더가 의미있는 저차원 벡터를 추출할 수 있게 되면, 디코더를 떼어버리고 그 뒤에 다른 네트워크를 덧붙혀 다른 task를 학습합니다.
(지금도 많이 쓰이는 `사전 학습 (Pre-tarining)`이나 `전이 학습 (Transfer Learning)`이라고 할 수 있겠네요.)





### <mark style='background-color: #dcffe4'> Dimensionality Reduction </mark>

물론 `차원 축소(Dimensionality Reduction)` 목적으로 개발된 알고리즘에는 오토인코더만 있는게 아니고, non-parametric한 방법인 주성분 분석(Principal Components Analysis)이나 선형 판별 분석(Linear Discriminant Analysis, LDA) 등 다양한 방법이 존재하지만 이번 글에서는 AE만 다룰 것입니다. 

![lda](/assets/images/ae_to_vae/pca_vs_lda.png)
*Fig. 차원 축소 알고리즘의 대표적인 예인 PCA, LDA 출처 : [lecture slide from Haesun Park](https://project.inria.fr/siamsummerschool/files/2019/06/Lec2LRA.pdf)*

 


### <mark style='background-color: #dcffe4'> Manifold </mark>

한편, 그렇다면 AE가 차원을 축소한다는게 무슨 의미일지 궁금하실 텐데요, AE를 통해서 우리는 `매니폴드 (Manifold)`라는 원본 데이터와는 다른 조금 세계인 저차원 `임베딩 공간 (Embedding Space)`을 배우게 됩니다. ( [Maifold in Wikipedia](https://en.wikipedia.org/wiki/Manifold) 참조)

![ae_manifold](/assets/images/ae_to_vae/ae_manifold.png)
*Fig. AE를 학습한다는 것은 의미 있는 매니폴드를 학습을 통해 알아낸다는 것이다.*

위의 그림에서 보면 원본 데이터들이 있던 원래 공간에서 인코딩을 하면 좁은 공간으로 줄어들었다가 디코딩을 하면 다시 원래의 공간으로 돌아오는 걸 알 수 있는데요,
원래 데이터 공간에서 넓게 퍼져있던 (sparse) 데이터들이 작은 공간안에 오밀조밀하게 응축된 것을 볼 수 있습니다.
이렇게 저차원으로 축소시킨 벡터를 사용한다는 것은 이후 인코더 뒤에 네트워크를 덧붙혀 학습하는 경우 `연산량을 줄여줌`과 동시에, `더욱 의미있는 벡터`들을 활용하기 때문에 학습을 더 잘하게 만들 수 있다는 의미를 가집니다.

![ae_manifold1](/assets/images/ae_to_vae/ae_manifold1.png)
*Fig. 원본, 764차원 손글씨 이미지를 non-parametric 알고리즘을 사용해 단순히 2차원으로 매핑한 결과(좌)와 parametric 방법론인 AE를 학습한 뒤 이를 사용해서 2차원으로 매핑한 결과(우). 오른쪽이 같은 숫자끼리 잘 뭉쳤다는 걸 알 수 있다.*

근데 첫 번째 계산량을 줄여준다는 특성은 그렇다 치고 왜 이 줄어든 벡터들이 `더욱 의미있는 벡터`라고 할 수 있는 걸까요?
그 의미는 바로 저차원에 데이터들을 밀집시킴으로써, 데이터 포인트들간 상관관계를 더욱 잘 파악할 수 있는 차원에 데이터들이 매핑 됐기 때문인데요,

![ae_manifold2](/assets/images/ae_to_vae/ae_manifold2.png)
*Fig. 원래 데이터 차원에서의 데이터 간 거리가 가깝다고 해서 실제 의미가 비슷한 것은 아니다.*

위의 사진을 보면 원본 데이터의 공간에서 거리가 가까워 보이는 것이 실제 학습된 AE의 매니폴드에서는 가깝지 않다는 것 (데이터의 유클리디안 거리만 가깝지 의미적으로는 멈)을 알 수 있으며, AE의 학습된 매니폴드에서는 인근 거리에 있는 데이터들이 실제로 의미적으로 가깝다는 걸 쉽게 알 수 있습니다.

![ae_manifold3](/assets/images/ae_to_vae/ae_manifold3.png)
*Fig. 실제로 원본 데이터 공간에서 어떤 두 데이터를 interpolation해서 중간 지점을 찾아내면 미스매치가 있는 걸 알 수 있는데, 이는 실제 매니폴드 (진짜 의미가 내재되어 있는 공간)상에서는 중간 지점이 아니기 때문이다.*


### <mark style='background-color: #dcffe4'> Principal Components Analysis (PCA) vs AE </mark>

사실 차원 축소 방법론에는 PCA와 같은 방법론도 있는데요, AE가 비선형 활성함수들을 사용한 신경망 (Neural Network, NN)이 아니라, 선형적인 특성만 이용한다면 이는 PCA와 이론적으로 같은 매니폴드 공간을 만들어 냅니다.

(증명은 하지 않겠습니다.)


![pca_vs_ae](/assets/images/ae_to_vae/pca_vs_ae.png){: width="50%"}
*Fig. 선형 차원 축소 알고리즘인 PCA (Kernel PCA아님) vs 비선형 차원 축소 알고리즘인 AE, 이미지 출처 : [link](https://www.researchgate.net/figure/Comparison-between-PCA-and-Autoencoder-15_fig1_340049776)*

위의 그림에서는 원 데이터들이 일반적인 AE를 사용할 경우 `비선형 매니폴드 (Non-linear Manifold)`에 매핑된 것을 볼 수 있고, PCA를 사용할 경우 `선형 매니폴드 (Linear Manifold)`에 매핑된 것을 볼 수 있습니다.


또한 각각의 차원 축소 방법론을 사용해 인코딩 할 경우 매니폴드 상에서 얼마나 같은 Class의 숫자 이미지끼리 뭉치는지 차이가 많이 나는 것을 확인할 수 있습니다.

![pca_vs_ae_embedding](/assets/images/ae_to_vae/pca_vs_ae_embedding.png)

![pca_vs_ae_embedding2](/assets/images/ae_to_vae/pca_vs_ae_embedding2.png)
*Fig. PCA vs AE 의 embedding space representation, 이미지 출처 : [link](https://stats.stackexchange.com/questions/190148/building-an-autoencoder-in-tensorflow-to-surpass-pca)*




### Notation

이제 본격적으로 수식을 가지고 AE와 VAE에 대해서 논하기 위해 몇 가지 Notation을 아래와 정의하고 이야기하도록 하겠습니다.  

{: class="info"}
| Symbol | Mean(Kor) | Mean(Eng) |
| ---------- | ---------- ||
| $$\mathcal{D}$$ | 데이터 셋 집합, 크기는 n | The dataset, $$\mathcal{D} = \{ \mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \dots, \mathbf{x}^{(n)} \}$$, contains $$n$$ data samples; $$\vert\mathcal{D}\vert =n $$. |
| $$\mathbf{x}^{(i)}$$ | 각 데이터 포인트는 d차원으로 이루어져 있음. | Each data point is a vector of $$d$$ dimensions, $$\mathbf{x}^{(i)} = [x^{(i)}_1, x^{(i)}_2, \dots, x^{(i)}_d]$$. |
| $$\mathbf{x}$$ | 데이터 셋 집합으로 부터 샘플링한 데이터 1개 | One data sample from the dataset, $$\mathbf{x} \in \mathcal{D}$$. |
| $$\mathbf{x}’$$| 축소했다가 디코더로부터 복원된 데이터 x | The reconstructed version of $$\mathbf{x}$$. |
| $$\tilde{\mathbf{x}}$$ | 노이즈가 섞인 데이터 x | The corrupted version of $$\mathbf{x}$$. |
| $$\mathbf{z}$$ | 인코더가 뱉은 표현 벡터 | The compressed code learned in the bottleneck layer. |
| $$g_{\phi}(.)$$ | - | The **encoding** function parameterized by $$\phi$$. |
| $$f_{\theta}(.)$$ | - | The **decoding** function parameterized by $$\theta$$. |
| $$q_{\phi}(\mathbf{z}\vert\mathbf{x})$$ | 확률적 인코더 (VAE에서 사용하므로 후술할 것임) |Estimated posterior probability function, also known as **probabilistic encoder**.  |
| $$p_{\theta}(\mathbf{x}\vert\mathbf{z})$$ | 확률적 인코더 (VAE에서 사용하므로 후술할 것임) | Likelihood of generating true data sample given the latent code, also known as **probabilistic decoder**. |
| ---------- | ---------- |

수식을 포함해서 다시 얘기하자면,
기본적인 오토인코더 모델은 (추후에 기술할 예정인 VAE는 조금 다릅니다) 파라메터 $$\phi$$로 모델링 된 인코더 함수 $$g(.)$$와 파라메터 $$\theta$$로 모델링 된 디코더 $$f(.)$$로 이루어져있습니다.
병목 층(bottle neck layer)에서 학습이 된 representation은 $$\mathbf{z} = g_\phi(\mathbf{x})$$ 이며, 이를 입력받아 디코더를 통해 얻은 복원된 데이터는 $$\mathbf{x}' = f_\theta(g_\phi(\mathbf{x}))$$ 라고 합니다.

인코더와 디코더의 파라메터인 $$(\theta, \phi)$$는 각각 따로 학습되는것이 아니라 $$x$$를 넣어서 원래 입력값인 $$\mathbf{x} \approx f_\theta(g_\phi(\mathbf{x}))$$를 복원하는 과정에서 함께 학습이 됩니다.



![ae](/assets/images/ae_to_vae/ae.png)
*Fig. 일반적인 AutoEncoder의 모식도*

이렇게 학습을 시키는 것은 `Cross Entropy Loss`를 사용하는 등 다양한 방법이 있지만, 일반적으로 간단하게 `Mean Squared Error Loss`를 사용해서 학습하게 됩니다.

$$
L_\text{AE}(\theta, \phi) = \frac{1}{n}\sum_{i=1}^n (\mathbf{x}^{(i)} - f_\theta(g_\phi(\mathbf{x}^{(i)})))^2
$$







### <mark style='background-color: #dcffe4'> Denoising AutoEncoder (DAE) </mark>

AE는 $$x$$를 given으로 다시 $$x$$를 예측하는 방법론으로, 오버피팅을 하게 되는 문제가 필연적으로 발생하는데,
`디노이징 오토인코더 (Denoisig Autoencoder, DAE)`는 이를 해결하기 위해 제안되었습니다.

의도적으로 입력 데이터에 노이즈 (Noise) 를 섞어서 (corrupt) 이를 다시 없애는 말 그대로 "De-Noise"하게 끔 인코더를 학습시키는 겁니다.
가장 간단하게는 단순히 입력값의 벡터 요소들을 "0" 으로 마스킹한다고 생각할 수 있습니다.
이렇게 함으로써 데이터를 증강 (Augmentation) 시키는 효과를 본다고 할 수도 있겠죠.

![cs285_lec17_dae1](/assets/images/ae_to_vae/cs285_lec17_dae1.png)
*Fig. Denoising AutoEncoder (DAE)는 더럽힌 이미지를 원본으로 복원시키는 방식으로 학습해 AE보다 더욱 강건한 (robust) Encoder를 얻는게 목적이다.*

DAE는 수식적으로 아래처럼 간단히 나타낼 수 있습니다.

$$
\begin{aligned}
\tilde{\mathbf{x}}^{(i)} &\sim \mathcal{M}_\mathcal{D}(\tilde{\mathbf{x}}^{(i)} \vert \mathbf{x}^{(i)})\\
L_\text{DAE}(\theta, \phi) &= \frac{1}{n} \sum_{i=1}^n (\mathbf{x}^{(i)} - f_\theta(g_\phi(\tilde{\mathbf{x}}^{(i)})))^2
\end{aligned}
$$

여기서 원본 이미지를 마스킹 하는 것은 확률적인 분포로부터 샘플링 하여 진행합니다.



이러한 `Denoising Auto-Encoding` 방법론은 간단하지만 현대의 강력한 딥러닝 모델들에서도 계속해서 쓰이는 방법론인데요,
그 대표적인 예로 `BERT`를 들 수 있습니다. 

![jay_bert](/assets/images/ae_to_vae/jay_bert.png)
*Fig. [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805)의 모식도. 버트는 DAE와 마찬가지로 sequence의 토큰 일부를 랜덤하게 마스크 토큰으로 바꾼 뒤, 해당 부분을 예측하는 비지도 학습 방식으로 학습한다.*

(이미지 출처 : [The Illustrated BERT, ELMo, and co. from Jay Alammar](http://jalammar.github.io/illustrated-bert/))




BERT가 DAE와 유사하다는 것은 논문에 기술된 방법론을 봐도 그렇지만 이의 후속 논문이라고 할 수 있는 XLNet 논문에서의 묘사로 더 확실히 알 수 있습니다.

![xlnet_bert](/assets/images/ae_to_vae/xlnet_bert.png)
*Fig. [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/pdf/1906.08237)에서 언급된 버트. 버트는 Denoising Auto-Encoding 방법론의 일종이다.*




이 밖에도 목적에 맞는 다양한 AE의 Variation이 존재하지만 그것들은 생략하고, 우리는 앞으로 AE와 비슷하게 생겼으나, 목적은 전혀 다른 (생성 모델을 만드는게 목적임) `Variational AutoEncoder (VAE)`에 대해서 알아보도록 할 것입니다.










## <mark style='background-color: #fff5b1'> Variational AutoEncoder (VAE) </mark>

`Variational AutoEncoder (VAE)`는 Kingma라는 연구자에 의해서 2014년에 처음 제안되었습니다. [Kingma, Diederik P., and Max Welling. "Auto-encoding variational bayes."](https://arxiv.org/pdf/1312.6114)

사실 보기에는 이름 자체가 (Variational) `AutoEncoder`이기 때문에 오토인코더와 다른점이 거의 없어 보이지만, 그렇지 않습니다.

VAE는 논문에서도 저자들이 이야기하듯, variational bayesian 방법과 graphical model과 관련이 있는 모델이며, 
목적 자체도 오토인코더와 같이 차원축소를 목적으로 '저차원의 유의미한 representation을 추출한다' 가 아니라, `'데이터로부터 단순히 고정된 벡터 (fixed vector)가 아닌 잠재 분포(latent distribution)를 찾아내고, 이로부터 샘플링을 통해 데이터셋에 없는 새로운 데이터를 만들어내는 생성 모델(generative model)을 만들자'` 입니다. (VAE는 생성모델)


물론 $$x$$를 넣어서 원래 입력값인 $$\mathbf{x} \approx f_\theta(g_\phi(\mathbf{x}))$$를 복원해내는 비지도 학습 방식으로 학습되는 것은 AE와 똑같습니다, 하지만 학습을 위한 목적 함수도 다르고, 학습이 된 후 네트워크의 어떤 부분을 쓰느냐도 다릅니다.

![lee_ae1](/assets/images/ae_to_vae/lee_ae1.png){: width="80%"}
*Fig. AutoEncoder는 유의미한 공간으로의 차원 축소를 해줄 Encoder를 학습하는게 목적이며, 이를 비지도 학습 방법론으로 학습하기 위해 Decoder를 붙힌 것이다.*

일반적인 오토인코더는 인코더를 앞서 말한 방식과 같이 학습하기 위해서 디코더를 붙힐 수 밖에 없었던 것이고, VAE는 디코더를 학습하기 위해서 인코더를 붙힌것으로 목적 자체가 다릅니다.

![lee_vae1](/assets/images/ae_to_vae/lee_vae1.png){: width="60%"}
*Fig. Variational AutoEncoder는 우리가 어떠한 유의미한 데이터 분포를 알고 있을 때, 이를 입력으로 유의미한 데이터를 만들어내기 위한 (i.e. 이미지) Decoder를 학습하는것이 목적이며, 이를 AE와 마찬가지로 비지도 학습 방법론으로 달성하기 위해서 Encoder를 붙힌 것이다.*

![lee_vae2](/assets/images/ae_to_vae/lee_vae2.png){: width="100%"}
*Fig. Encoder를 붙힌 VAE의 모습은 AE와 유사하다. Sample을 한다는 것의 의미는 후술하기로 한다.*

(+ `Variational` AutoEncoder의 'Variational'이란 앞서 말한 posterior라고 할 수 있는 latent distribution $$z$$를 direct로 학습할 수 없기 때문에 사용하는 근사방법인, 변분 추론(Variational Inference)에서 따온 이름입니다.)  


이제 VAE에 대해서 차분히 알아보도록 할건데, 그 전에 우리는 `잠재 변수 모델 (Latent Variable Model)`이 무엇이며 어떤 의미를 가지는지에 대해 알 필요가 있기 때문에 이에 대해 먼저 알아보도록 하겠습니다.














### <mark style='background-color: #dcffe4'> What is Latent Variable Model ? </mark>

잠재 변수 모델은 과연 뭘까요?


머신러닝은 일반적으로 $$p(x)$$이나 $$p(y \vert x)$$에 대한 분포를 모델링하고 (연속적이거나 이산적인 분포 i.e. 가우시안, 카테고리컬 분포) 이 분포를 통해 구한 데이터 셋 전체에 대한 likelihood를 최대화 하는 분포에 대한 파라메터를 찾는것이 목적입니다.

![jd_likelihood](/assets/images/ae_to_vae/jd_likelihood.png)
*Fig. likelihood를 최대화 한다는 것은 주어진 데이터를 가장 잘 표현하는 분포를 찾는다는 것과 같다.*

여기서 $$p(x)$$는 일반적으로 `확률적 생성 모델 (Probabilistic Generative Model)`, $$p(y \vert x)$$는 `확률적 판별 모델 (Probabilistic Discriminative Model)`이라고 합니다.

![cs285_lec17_generative](/assets/images/ae_to_vae/cs285_lec17_generative.png){: width="40%"}
*Fig. 확률적 생성 모델, $$ p(x) $$*

![cs285_lec17_discriminative](/assets/images/ae_to_vae/cs285_lec17_discriminative.png){: width="80%"}
*Fig. 확률적 판별 모델, $$ p(y \vert x) $$*

하지만 확률적이라고 해도 이러한 모델들에서 랜덤 변수 (random varialbes)라고 할 만한 것들은 데이터의 입출력 $$x,y$$ 밖에 없는데요, 
이러한 확률적 분포 모델 $$p(x)$$, $$p(y \vert x)$$에 랜덤 변수 $$z$$를 추가해서 모델링 하는 것이 바로 잠재 변수 모델이며, 이 때 $$z$$를 잠재 변수라고 합니다.

직관적으로 이해하기 위해 예를 들어 보도록 하겠습니다.
우리가 다음과 같이 복잡한 분포로 부터 샘플링 된 데이터를 가지고 있다고 해보도록 하겠습니다. (당연히 실제 분포는 몰라야 정상이지만 안다고 하겠습니다.)

![cs285_lec17_px](/assets/images/ae_to_vae/cs285_lec17_px.png){: width="60%"}
*Fig. 복잡한 분포를 가지는 $$p(x)$$*

우리가 원하는건 당연히 데이터를 잘 표현하는 분포 $$p(x)$$를 찾는거죠. 
하지만 우리가 일반적으로 가정하는 봉우리가 하나뿐인 `단봉 가우시안 분포 (Unimodal Univariate Gaussian Distribution)`으로는 표현하는 데 한계가 있습니다.
그래서 우리는 `다봉 가우시안 분포 (Multimodal Univariate Gaussian Distribution)` 같이 좀 더 복잡한 분포로 이를 표현하고 싶은데,
이를 위해서는 아래처럼 단순히 단봉 분포를 여러 개 weighted sum할 수도 있습니다.

![jd_gmm6](/assets/images/ae_to_vae/jd_gmm6.png){: width="50%"}
*Fig. 우리가 원하는 것은 복잡한 $$p(x)$$이다. 이를 위해 단봉 가우시안 분포 여러갤르 합치면 어떨까?*

하지만 이보다 더 복잡하고 표현력이 좋은 방법이 있는데요, 이것이 바로 잠재 변수를 활용한 `잠재 변수 모델 (latent variable model)`입니다.

잠재 변수 모델은 앞서 말한 것 처럼 원 데이터에는 존재하지 않았던 변수를 데이터 속으로 부터 분리하는 `주변화 (Marginalization)` 테크닉을 통해 정의하는데요,
즉 이를 통해서 전에 없던 결합 분포를 만들어 낸다는 겁니다.

![jd_gmm1](/assets/images/ae_to_vae/jd_gmm1.png){: width="50%"}
*Fig. 잠재 변수 (여기서는 $$h$$라는 노테이션으로 쓰임)와 원본 데이터 $$x$$와의 결합 분포, $$h$$의 분포는 그림에서는 연속적인 분포다 (i.e.가우시안)*

$$
p(x) = \int p(x,h) dh 
$$

만약에 잠재 변수가 이산적인 분포를 갖는 경우를 가정하면 이는 아래와 같은 그림으로 표현할 수 있게 되는데요,

![jd_gmm7](/assets/images/ae_to_vae/jd_gmm7.png){: width="60%"}
*Fig. 만약 잠재 변수 $$h$$의 분포가 이산적인, 예를 들어 3개의 클래스를 가지는 카테고리컬 분포라면, 위의 그림처럼 된다.*

그림에서 볼 수 있듯, 같은 데이터 포인트 $$x$$라도 $$h=1,2,3$$일 때 각각 리턴하는 확률 값이 다르다는 것을 알 수 있습니다. 
즉 x좌표상 왼쪽 부근에 있는 데이터들은 $$h=1$$에 속할 확률이 높겠네요.


이런식으로 우리는 실제로는 주어진 정보가 $$x$$밖에 없지만 존재하지 않던 $$h$$라는 내재되어있는 변수를 도입하고, 
이를 학습을 통해서 fitting하면서, 실제로는 각 데이터 포인트에 대해서 어느 클래스에 속한다는 정답은 없었지만, 
$$h=1,2,\cdots$$ 같은 `가짜 정답 (Fake Label)`에 대한 분포를 만들고 알아서 학습하게 되는거죠.

![jd_gmm3](/assets/images/ae_to_vae/jd_gmm3.png){: width="60%"}
![jd_gmm4](/assets/images/ae_to_vae/jd_gmm4.png){: width="60%"}
*Fig. 학습을 통해 알아서 데이터의 분포를 더욱 잘 설명하는 복잡한 분포를 찾아내는 것을 알 수 있다.*

```
이 때 중요한 점은 이렇게 만들어진 정보 (i.e x라는 데이터는 h=1일 확률이 가장 높다.)가 맞다고 가정하고 진행한다는 겁니다.
```

이를 2차원이나 고차원으로 확장시켜도 당연히 문제가 없으며,

![cs285_lec17_latent1](/assets/images/ae_to_vae/cs285_lec17_latent1.png){: width="40%"}
*Fig. 당연히 여기서 색을 입힌건 편의를 위해서지 정답이 주어진게 아니며, 검은색 원 또한 잠재 변수 모델로 얻어낸 다변량 다봉 정규 분포 (Multi-modal Multivariate Gaussian Distribution)를 나타내는 것이지, 실제로 우리가 알고 있는 것은 데이터 $$x$$ 정보 밖에 없습니다.*

이러한 잠재 변수 모델은 전통적인 머신러닝 기법인 `EM Algorithm`을 통해서 학습하곤 합니다.


![jd_gmm5](/assets/images/ae_to_vae/jd_gmm5.png){: width="70%"}
*Fig. $$h$$라는 잠재 변수가 어떻게 돼야 한다고 강제한건 아니지만, 학습되는 과정에서 알아서 데이터 분포를 잘 설명하기 위해서 군집끼리 묶는다.*


잠재 변수 모델을 수식적으로 생각해보자면, 우리는 잠재 변수를 표현하기 위해서 원래 우리가 추정하고자 하는 분포 $$p(x)$$를 Marginalization (혹은 integrated out)해서 아래처럼 표현하고, 

$$
p(x) \rightarrow p(x) = \sum_z p(x,z)
$$

간단한 확률 테크닉을 통해 아래처럼 나타낼 수 있습니다.

$$
p(x) = \sum_z p(x \vert z) p(z)
$$

이는 마찬가지로 아래와 같은 판별 모델에도 적용할 수 있습니다.

$$
p(y \vert x) \rightarrow p(y \vert x) = \sum_z p(y \vert x,z) p(z)
$$

이제 이를 더 확장해서 생각해보도록 하겠습니다 (generalization).


우리가 가지는 데이터에 대한 분포 $$p(x)$$가 연속적이며, 굉장히 복잡한 분포라고 가정해보도록 하겠습니다.
단순히 3개의 가우시안 분포를 합쳐서 표현할 정도가 아니라 굉장히 복잡한 (complicated monstrous) 분포입니다.

![cs285_lec17_px](/assets/images/ae_to_vae/cs285_lec17_px.png){: width="60%"}
*Fig.*

여기에 위에서 한 것 처럼 잠재 변수를 도입할건데요, 이 때 $$p(z)$$는 매우 다루기 쉬운 연속적인 분포인 가우시안 분포라고 해보도록 하겠습니다. 

![cs285_lec17_pz](/assets/images/ae_to_vae/cs285_lec17_pz.png){: width="60%"}
*Fig.*

우리가 필요한 것은 어떤 데이터 포인트 $$x$$가 주어졌을 때 이 데이터에 대한 알려지지 않은 "Fake Label" $$z$$에 대한 정보 $$p(x \vert z)$$ 입니다.
$$p(x \vert z)$$ 또한 굉장히 다루기 쉬운 가우시안 분포라고 가정 해 보도록 하겠습니다.

![cs285_lec17_pxz1](/assets/images/ae_to_vae/cs285_lec17_pxz1.png){: width="70%"}
*Fig.*

우리는 이미 잠재 변수를 도입할 때 아래의 식이 성립한다는 것을 알고 있죠.

$$
p(x) = \int p(x \vert z) p(z) dz
$$

(여기서 우변이 아까와 다르게 $$\sum$$이 아닌 $$\int$$인 이유는 $$p(z)$$가 이번에는 연속적인 분포이기 때문입니다.)


$$\int p(x \vert z) p(z) dz$$의 의미는 z 분포의 가능한 모든 value에 대해 생각을 한다는 겁니다.


우리가 이로부터 알 수 있는 중요한 사실은 바로, 원래는 표현하기 복잡하며 어떻게 표현해야 할 지도 감이 안 왔던 $$p(x)$$를 배우는 것을, 매우 간단한 분포인 가우시안 분포 두개를 배우는 것으로 바꿔서 생각할 수 있게 됐다는 겁니다.

여기서 $$p(z)$$는 고정된 분포이며 (i.e. zero mean, unit variance $$N(0,I)$$), 가우시안 분포 $$p(x \vert z)$$의 평균 (mean, $$\mu$$), 분산 (variance, $$\sigma$$)는 뉴럴 네트워크의 출력이며, 이 뉴럴 네트워크를 학습하는것도 사실 그리 쉬운 일은 아니지만 적어도 $$p(x \vert z)$$는 deterministic하며, 이러한 방법으로 학습하는게 $$p(x)$$를 학습하는 것보다는 낫습니다.


자 이제 우리가 어떻게 잠재 변수 모델을 학습하는지에 대해서만 생각해보고, VAE로 넘어가도록 하겠습니다.
이를 설명하기 위해 우선 다음을 정의하도록 하겠습니다.

- The model : $$p_{\theta} (x)$$
- The data : $$D = \{ x_1,x_2, \cdots, x_N \}$$
- Maximum likelihood fit : $$ \theta \leftarrow argmax_{\theta} \frac{1}{N} \sum_i log p_{\theta} (x_i) $$

우리가 잠재 변수 모델을 정의하기 위해 $$p(x)$$를 Marginalization 했으니 아래와 같이 표현할 수 있겠습니다.

$$ 
\theta \leftarrow argmax_{\theta} \frac{1}{N} \sum_i log p_{\theta} (x_i)  \\ 
\theta \leftarrow argmax_{\theta} \frac{1}{N} \sum_i log ( \int p_{\theta}(x_i \vert z) p(z) dz ) \\
$$

적분식이 가지는 의미는 우리가 연속적인 분포 $$p(z)$$의 가능한 모든 변수들을 고려하겠 다는 것인데, 이는 불가능 하기 때문에 적분식을 계산하는 것은 intractable합니다. (즉 no closed-form solution). 


(여기서 우리는 $$p(z)$$를 prior라고 부르며 (학습이 되는게 아님, 정해진 분포 그대로), $$p(x \vert z)$$는 mapping function으로 우리가 학습을 통해 배우게 될 것입니다 (즉 mean, variance가 학습을 통해 변함).)


하지만 적분식을 계산할 수 없다고 학습을 할 수 없는건 아닙니다. 
바로 아래의 `Expected log-likelihood` 식을 정의하고 이를 최대화 하는 방향으로 학습을 하면 $$p(x \vert z)$$를 fit할 수 있게 되는데요,

$$
\theta \leftarrow argmax_{\theta} \frac{1}{N} \sum_i \mathbb{E}_{z \sim p(z \vert x_i)} [log p_{\theta} (x_i, z)] 
$$

이는 전체 적분을 계산하지 않고, 우리가 가지는 학습 데이터 $$x_1, \cdots, x_N$$에 대해서 각각에 대해 가장 그럴듯한 정답 $$z_1, \cdots, z_N$$이 존재하며, 이게 맞다고 가정하고 두 $$(x_i,z_i)$$의 결합 분포 (joint distribution)을 최대화 하겠다는 겁니다. 
적분은 없어졌지만 여전히 기대값이 취해져 있기 때문에 i번째 데이터에 대해서 $$z~p(z \vert x_i)$$의 모든 확률들에 대해서 평균을 내기는 합니다.
하지만 practical하게는 우리는 1번 혹은 몇 번의 샘플링을 통해서 얻은 z 몇개에 대해서만 계산할 것이기 때문에 부담이 확 줄어들었습니다. 

***

![jd_prob1](/assets/images/ae_to_vae/jd_prob1.png){: width="40%"}
![jd_prob2](/assets/images/ae_to_vae/jd_prob2.png){: width="70%"}
*Fig. Recap. 결합 분포와 조건부 분포의 관계, 우리는 한 데이터 $$x_i$$당 전체 $$z$$ (그림에서는 $$y$$)에 대한 probability를 계산하는 것이 아닌 몇 개의 $$z$$ 샘플에 대해서만 probability를 계산하면 된다.*


***

```
다시한번,

Intuition : "guess" most likely z given x_i, and pretend it's the right one
...but there are many possible values of z, so use distribution p(z|x_i) and sample a few z from it

```


이제 "과연 $$p(x_i \vert z)$$ 분포는 무엇인지, 그리고 이는 어떻게 계산할 것인지?" 가 관건입니다.
이를 해결하기는 과정은 `확률적 추론 (Probabilistic Inference)`이라고 불리는데, 추론이라고 불리는 이유는 각각의 입력, $$x_i$$ (i.e. 이미지)에 대해서 어떤 $$z$$가 동반되어야 하는지를 `추론 (infer)`하기 때문입니다. 


즉, 우리가 정말로 원하는 것은 $$p(z)$$로 부터 샘플링한 벡터를 이용해서 새로운 $$x_i' \approx x_i$$를 만드는, $$p(x_i \vert z)$$라는 mapping function을 학습하는 것이지만,

![lee_vae1](/assets/images/ae_to_vae/lee_vae1.png){: width="60%"}

![cs285_lec17_pxz1](/assets/images/ae_to_vae/cs285_lec17_pxz1.png){: width="70%"}
*Fig. $$p(x \vert z)$$*


이를 위해서 역으로 $$p(z \vert x_i)$$ 라는 주어진 입력으로 부터 주어지는 $$z$$는 과연 어떤 분포일까?를 나타내는 $$p(z \vert x_i)$$도 추론해야 한다는 거죠.   

![cs285_lec17_pxz2](/assets/images/ae_to_vae/cs285_lec17_pxz2.png){: width="60%"}
*Fig. $$p(z \vert x)$$*

만약에 이 분포가 학습이 잘된다면, 우리는 예를 들어, 강아지 사진이 어떤 분포 $$p(z \vert x)$$로 부터 기인했는지를 알 수 있게 되고 (물론 이 분포는 복잡합니다), 이 분포에서 다른 데이터 포인트를 샘플링해서 $$z \sim p(z \vert x)$$ 디코더에 넣어주면 $$p(x \vert z)$$ 우리가 학습한 강아지 사진과 비슷하지만, 다른 모양의 강아지 (털 색이 다르다던가)를 만들어 낼 수 있게 됩니다.
그래서 이 모델이 `심층 생성 모델 (Deep Generative Model)`이라고 불릴 수 있는 것이죠.



하지만 이 추론을 하는 과정 자체가 엄청나게 어려운데요, 그렇기 때문에 우리는 `근사 추론 (approximate inference)` 방법을 사용해서 학습을 하게 되고, 
이 때 자주 쓰이는 방법이 바로 지금 우리가 논하려고 하는 VAE에서도 쓰는 방법인 `변분 근사 (variational approximation)` 혹은 `변분 추론 (variational Inference)`이 됩니다.













### <mark style='background-color: #dcffe4'> Variational Inference (Variational Approximation) </mark>

변분 추론의 핵심 아이디어는 계산하기 복잡한 $$p(z \vert x)$$ 대신에, 이와 유사하지만 간단한 분포 (i.e. 가우시안 분포)를 사용하자는 겁니다.

$$
p(z \vert x_i) \rightarrow q_i(z) = N(\mu_i, \sigma_i)
$$

수식에서도 알 수 있듯이, 이는 각각의 학습 데이터셋의 데이터 포인트인 $$x_i$$마다 서로 다른 $$\mu_i,\sigma_i$$를 가지고 있을 겁니다.

![elbo](/assets/images/ae_to_vae/elbo.png){: width="70%"}
*Fig. Variational Approximation*





(말씀을 드리지 않았는데, 여기서 $$p(z \vert x)$$를 `진짜 사후 분포 (real posterior distribution)` 라고 표현합니다. 이는 단순한 가우시안 분포가 아니라 굉장히 복잡하게 생겨 모델링 하기도 힘들며, 실제로 우리가 알지 못하는 분포입니다.)


- $$p(x_i)$$ : real data distribution
- $$p(z \vert x_i)$$ : real posterior
- $$p(z)$$ : prior
- $$q_i(z)$$ : approximate posterior


여기서 어떤 $$q_i(z)$$를 설정하던지, 우리는 $$logp(x_i)$$에 대한 `하계 (Lower Bound)`를 설정할 수가 있는데요,
이는 아래의 수식을 통해서 정의할 수 있습니다.

$$
\begin{aligned}

& log p(x_i) = log \int_z p(x_i \vert z) p(z) & \\
& = log \int_z p(x_i \vert z) p(z) \frac{q_i(z)}{q_i(z)} & \\
& = log \mathbb{E}_{z \sim q_i(z)} [p(x_i \vert z) p(z) \frac{1}{q_i(z)}] & \\
& = log \mathbb{E}_{z \sim q_i(z)} [ \frac{p(x_i \vert z) p(z) }{q_i(z)} ] & 

\end{aligned}
$$

위에서 사용된 테크닉은 $$\frac{q_i(z)}{q_i(z)} = 1 $$을 추가하고, 기대값의 정의를 사용한 것 밖에 없습니다.
여기서 추가적으로 `변분 추론의 핵심`이 되는 아래와 같은 특성을 이용하면,

$$
log \mathbb{E} [y] \geq \mathbb [log y]
$$


![jensen](/assets/images/ae_to_vae/jensen.png)
*Fig. [Jensen's Inequality](https://en.wikipedia.org/wiki/Janson_inequality)*


우리는 비로소 아래와 같은 수식을 얻을 수 있게 됩니다.

$$
\begin{aligned}

& log p(x_i) = log \mathbb{E}_{z \sim q_i(z)} [ \frac{p(x_i \vert z) p(z) }{q_i(z)} ] & \\
& \geq \mathbb{E}_{z \sim q_i(z)} [ log \frac{p(x_i \vert z) p(z) }{q_i(z)} ] = \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] - \mathbb{E}_{z \sim q_i(z)} [log q_i(z)] &

\end{aligned}
$$


생성 모델 이란 결국 모든 데이터 포인트들에 대한 log-likelihood, $$log p(x_i)$$의 합인 $$log p(x) = \sum_i log p(x_i) $$를 최대화 하는 문제인데, $$\mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] - \mathbb{E}_{z \sim q_i(z)} [log q_i(z)]$$ 라는 term이 lower bound이기 때문에 이를 최대화 하는 것이 곧 $$log p(x)$$ 를 최대화 하는 문제를 푸는 것과 다름 없게 됩니다.


여기서 우리가 최대화 하고자 하는 lower bound수식의 두번째 term은 사실 `음의 엔트로피 (negative Entropy)`와 동일한 수식인데요,

$$
\begin{aligned}
& log p(x_i) \geq \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] - \mathbb{E}_{z \sim q_i(z)} [log q_i(z)] & \\
& log p(x_i) \geq \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] + H(q_i) &
\end{aligned}
$$

그렇기 때문에 우리는 수식이 갖는 의미를 조금 더 해석적으로 이야기할 수 있습니다.









#### < Entropy >

먼저 `엔트로피 (Entropy)`가 의미하는 것은 뭘까요?

$$
H(p) = - \mathbb{E}_{x~p(x)} [log p(x)] = -\int_x p(x) log p(x) dx
$$

엔트로피가 의미하는 바는 직관적으로 다음과 같습니다.

- 얼마나 확률 분포가 랜덤한가? (how random is the random variable?)
- 주어진 확률 분포 하에서 log 확률값에 대한 기대값이 얼마나 큰가? (how large is the log probability in expectation under itself?)

![entropy](/assets/images/ae_to_vae/entropy.png)
*Fig. 마찬가지로 더욱 랜덤한 오른쪽 분포가 더 엔트로피가 높다.*

![entropy_ber](/assets/images/ae_to_vae/entropy_ber.png){: width="40%"}
*Fig. 베르누이 분포 하에서의 Entropy, 나올 수 있는 경우 2가지가 모두 0.5일 때, 가장 헷갈리는 상황으로 엔트로피가 가장 높다.*

즉 엔트로피는 얼마나 확률 분포가 랜덤한가? 인데, 우리가 최대화 하려고 하는 수식이 바로 $$q_i(z)$$ 의 엔트로피를 포함하고 있기 때문에, 
아래의 수식을 최대화 하는 것은

$$
\mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] + H(q_i)
$$

$$q_i(z)$$ 분포를 평평하게 (랜덤하게) 만들면서, 이로부터 샘플링한 z라는 랜덤 변수 (random variable)을 가지고 만들어낸 이미지가 $$log p(x_i \vert z)$$ 원본 이미지 $$x_i$$가 되게끔 하는 것을 의미하게 된다는 겁니다.

![cs285_lec18_entropy](/assets/images/ae_to_vae/cs285_lec18_entropy.png)
*Fig. 우리가 최대화 하려는 수식의 첫 번째 term과 두 번째 term이 가지는 의미*







#### < KL-Divergence (KLD) >

이 수식을 해석하는 또 다른 방법은 바로 `쿨백 라이블러 발산 (KL-Divergence, KLD)`을 이용하는 건데요,
KLD는 서로 다른 두 분포에 대해서 다음의 수식을 만족합니다.

$$
\begin{aligned}

& D_{KL} (q \parallel p) = \mathbb{E}_{x \sim q(x)} [log \frac{q(x)}{p(x)}] & \\
& = \mathbb{E}_{x \sim q(x)} [log q(x)] - \mathbb{E}_{x \sim q(x)} [log p(x)] & \\
& = - \mathbb{E}_{x \sim q(x)} [log p(x)] - H(q) &

\end{aligned}
$$

KL-Divergence에 대해서도 할말이 굉장히 많지만, 정말 간단하게 얘기해서 KL-Divergence는 `'두 분포가 얼마나 다른가'` 혹은 `'두 분포간의 거리'`를 의미하며, 수식의 결과값이 작을수록 두 분포가 유사하다는 뜻을 나타내며, 두 분포가 완전히 같다면 이 값은 $$0$$이 됩니다. ($$0$$이 되는지는 수식의 기대값에 같은 분포를 넣어서 계산하면 쉽게 확인할 수 있습니다.)

![kld](/assets/images/ae_to_vae/kld.png){: width="80%"}
*Fig. [Wikipedia](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)에 묘사되어 있는 KLD.*


물론 널리 알려져 있는 것처럼, 이 `거리`는 우리가 흔히 말하는 좌표상의 유클리디안 거리 (Euclidean Distance)가 아니며, $$D_{KL}(p \parallel q)$$와 $$D_{KL}(q \parallel p)$$의 결과값은 서로 같지 않습니다.
그리고 KLD의 특성중 하나는 리턴하는 값이 언제나 양수라는 겁니다. 



어쨌든, 우리가 KLD를 갑자기 가져온 이유가 있습니다.
그건 바로 `우리가 Jensen's Inequality로 유도한 수식이 사실은 KLD를 나타낸다.`라는 사실 때문입니다.

$$
\begin{aligned}

& D_{KL} (q \parallel p) = - \mathbb{E}_{x \sim q(x)} [log p(x)] - H(q) & \\
& log p(x_i) \geq \mathbb{z \sim q_i (z)} [ log p(x_i \vert z) + log p(z)] + H(q_i) &

\end{aligned}
$$

한편, 어떤 $$q_i(z)$$가 좋은 근사 분포일까요? 
이는 유도했던 수식의 bound가 `'얼마나 tight한가'`? 다시 풀어서 말하면, `'얼마나 우변과 좌변이 유사한가?'`를 재보면 알 수 있습니다.
$$q_i(z)$$는 $$p(z \vert x_i)$$ 와 유사하지만 다루기가 쉬운 분포여야 하며, 이를 잘 반영했을 때가 좌변과 우변이 차이가 가장 적어지고, 그런 $$q$$가 좋은 $$q$$가 된다는 겁니다. 
그렇다면 이를 잴 수 있는 도구는 뭘까요? $$q_i(z)$$는 $$p(z \vert x_i)$$ 사이의 KLD가 될겁니다.
두 분포 사이의 KLD를 재보도록 하겠습니다.

$$
\begin{aligned}

& D_{KL} (q_i(z) \parallel p(z \vert x_i)) = \mathbb{E}_{z \sim q_i(z)} [log \frac{q_i(z)}{p(z \vert x_i)}] & \\
& = \mathbb{E}_{z \sim q_i(z)} [log \frac{ q_i(z) p(x_i) }{ p(x_i,z) }] & 

\end{aligned}
$$

우리는 위와 같은 수식을 얻을 수 있고, 이 수식을 아래와 같이 잘 전개하면 우리는 놀라운 결과를 얻을 수 있는데요,

$$
\begin{aligned}
& D_{KL} (q_i(z) \parallel p(z \vert x_i)) = \mathbb{E}_{z \sim q_i(z)} [log \frac{q_i(z)}{p(z \vert x_i)}] = \mathbb{E}_{z \sim q_i(z)} [log \frac{ q_i(z) p(x_i) }{ p(x_i,z) }] & \\
& = -\mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] + \mathbb{E}_{z \sim q_i(z)} [log q_i(z)] + \mathbb{E}_{z \sim q_i(z)} [log p(x_i)] & \\
& = - \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] - H(q_i) + log p(x_i) & \\
& = - L_i (p,q_i) + log p(x_i) &
\end{aligned}
$$

$$log p(x_i)$$가 아까 정의한 `Lower Bound`인 $$L_i(p,q_i)$$와 $$D_{KL} (q_i(z) \parallel p(z \vert x_i))$$의 합이라는 겁니다.

***

+ log p(x)를 일반적으로 증거 값 (Evidence)이라고 부르는데요, 이 값은 정확하게 $$L_i$$와 KLD값의 합이며 이 KLD는 언제나 양수값이기 때문에 $$L_i$$는 언제나 Evidence보다 조금 아래에 놓이게 되는 하계 (Lower Bound)가 됩니다. 그렇기 때문에 일반적으로 $$L_i(p,q_i)$$를 `Evidence Lower Bound (ELBO)` 라고 합니다.

***


$$
log p(x_i) = D_{KL} (q_i(z) \parallel p(z \vert x_i)) + L_i (p,q_i) 
$$

이 수식이 시사하는 바는 큰데요, 이는 $$L_i(p,q_i)$$를 유도하는 또 다른 방법이기도 하며, $$log p(x_i)$$와 `ELBO` $$L_i$$간의 괴리 (error)가 얼마나 크고 작은지를 알 수 있기 때문입니다.


만약 두 진짜 분포와 근사 분포간의 KLD가 작다고 생각하면, $$L_i$$가 $$log p(x_i)$$를 굉장히 잘 근사 (bound가 굉장히 tight해짐) 한다는 걸 알수 있겠죠? (극단적으로 0이면, 둘은 동일함)
이러한 특성은 매우 매우 중요한 특성인데요, 만일 우리가 KLD를 최소화 하면서, 동시에 $$L_i$$를 최대화 하면 우리는 정말 효과적으로 $$p(x_i)$$를 극대화 할 수 있을겁니다.

$$
\begin{aligned}

& log p(x_i) = D_{KL} (q_i(z) \parallel p(z \vert x_i)) + L_i (p,q_i) & \\
& log p(x_i) \geq L_i(p,q_i) &

\end{aligned}
$$


그리고 우리는 KLD가 언제나 양수이며, KLD와 $$L_i$$의 합이 $$logp(x)$$라는 사실로 부터,
즉 우리는 $$L_i$$를 $$q_i$$에 대해서 최대화 하는 것이 즉 KLD를 최소화 한다는걸 알 수 있습니다. 

$$
\begin{aligned}

& D_{KL} (q_i(z) \parallel p(z \vert x_i)) = - \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] - H(q_i) + log p(x_i) & \\
& = - L_i (p, q_i) + log p(x_i) &

\end{aligned}
$$

(여기서 $$logp(x_i)$$ 는 $$q_i$$와 관련이 없기 때문에 (독립임) 고정되어있을 겁니다.)

![elbo_kld](/assets/images/ae_to_vae/elbo_kld.png){: width="50%"}
*Fig. $$L_i$$를 최대화 하는 것은, 실제 분포와 근사 분포의 KLD를 최소화 하는 것이다. (Notation이 다른 이유는 후에 다시 서술하도록 하겠습니다.)*



결론적으로 우리는 `ELBO`를 $$p$$와 $$q$$ 모두에 대해서 최대화 하는 것이 결국 `생성 모델이 원하는 진짜 목적 함수 (Objective Function)`, $$log p(x)$$를 최대화 하게 되는 겁니다.

- ELBO를 $$q$$에 대해서 최대화 : $$p,q$$ 사이의 KLD가 줄어든다 - `bound가 tight해진다`
- ELBO를 $$p$$에 대해서 최대화 : $$log p(x_i) \geq L_i$$의 $$L_i$$이 커지면서 $$log p(x_i)$$, 즉 `Evidence도 덩달아 커진다`.

이렇게 우리는 `잠재 변수 모델 (Latent Variable Model)`을 학습할 수 있는 tractable한 방법을 얻게 되었습니다!





즉, 이제 우리는 아래의 수식이 아니라 

$$
\theta \leftarrow arg max_{\theta} \frac{1}{N} \sum_i log p_{\theta} (x_i) 
$$

`ELBO`를 최대화 함으로써 생성 모델을  학습할 수 있게 된겁니다.

$$
\begin{aligned}

& \theta \leftarrow arg max_{\theta} \frac{1}{N} \sum_i L_i(p,q_i) & \\
& \theta \leftarrow arg max_{\theta} \frac{1}{N} \sum_i \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] + H(q_i) &

\end{aligned}
$$

조금 더 디테일하게는 아래의 `학습 절차 (training procedure)` 따르면 되겠습니다.

***

$$
\begin{aligned}

& \text{for each } x_i (\text{or mini-batch}): &  \scriptstyle{\text{; for every data x_i in our dataset}} \\
& \quad \text{calculate } \bigtriangledown_{\theta} L_i(p,q_i): & \scriptstyle{\text{; calculate gradient of ELBO with respect to model param}} \\
& \quad \quad \text{sample } z \sim q_i(z) & \scriptstyle{\text{; 1. sample z because we have Expectation}}  \\
& \quad \quad \bigtriangledown_{\theta} L_i(p,q_i) \approx \bigtriangledown_{\theta} log p_{\theta} (x_i \vert z) &  \scriptstyle{\text{; 2. calculate gradient for one sample (can use multiple sample). p(z) has no parameter}}  \\
& \quad \theta \leftarrow \theta + \alpha \bigtriangledown_{\theta} L_i(p,q_i) &  \scriptstyle{\text{; 3. update param on } \theta} \\
& \quad \text{update } q_i \text{ to maximize }  L_i(p,q_i) &  \scriptstyle{\text{; 4. also maximize } q_i \text{how? -> will talk bout this later}}

\end{aligned}
$$

***

우리가 힘겹게 목적 함수도 정의 했으며, 어떻게 파라메터를 업데이트 하는지 까지 알아보긴 했지만, 여기서 문제가 하나 있습니다.
예를 들어, 우리가 $$q_i$$를 간단한 분포, 즉 아래와 같은 세팅의 가우시안 분포라고 가정해보도록 하겠습니다.

- $$ q_i(z) = N(\mu_i, \sigma_i) $$

여기서 주의해야 할 점은 $$p(z)$$와 $$q_i(z)$$는 다르다는 겁니다.
$$p(z)$$는 파라메터가 없는 $$N(0,I)$$ 이고, $$q_i$$는 데이터 포인트 $$x_i$$에 대한 파라메터화 된, 즉 학습을 통해 우리가 추정해야 하는 분포인거죠.
우리는 각 데이터 포인트 $$x_i$$마다 평균, $$\mu_i$$ 와 분산, $$\sigma_i$$이 필요합니다.


즉 이는 데이터 포인트가 하나의 이미지라면, `모든 이미지 마다 가짜 정답 (fake label)을 달아주는 것 (annotate)`이 되는 겁니다.
그러니까 우리는 $$L_i$$를 $$q_i$$에 대해 업데이트 하려면 아래와 같이 모든 이미지 마다, 두 파라메터를 전부 다 업데이트 해야 하는 겁니다. 
(한 데이터 포인트마다 샘플링을 여러번 하면 이 과정은 더 오래걸리겠죠?)

- use gradient $$ \bigtriangledown_{\mu_i} L_i(p,q_i) $$ and $$ \bigtriangledown_{\sigma_i} L_i(p,q_i) $$
- gradient ascent on $$\mu_i,\sigma_i$$

우리가 지금까지 정의하고 사용하려는 방법론이 클래식한 변분법이며 분명히 작용하는 알고리즘이겠지만, 이는 업데이트해야 할 파라메터가 너무 많다는 단점이 있습니다.

- How many parameters are there? $$\vert \theta \vert + ( \vert \mu_i \vert + \vert \sigma_i \vert ) \times N $$

$$p_\theta(x_i \vert z)$$를 모델링한 신경망의 모델 파라메터 $$\theta$$개수에 각 데이터 포인트 마다 평균, 분산 2개의 파라메터가 추가적으로 있는거죠.  
이는 데이터가 많으면 많을수록 더 다루기 힘들어 질 것입니다.


그렇다면 이를 해결하기 위해서는 어떻게 해야할까요? 
네 맞습니다, $$x_i$$마다 $$q_i$$를 정하지 말고, 이 둘 사이 관계를 매핑해주는 신경망을 하나 더 두는 것이죠.

- intuition : $$q_i(z)$$ should approximate $$p(z \vert x_i)$$ then what if learn network $$q_i (z) = q(z \vert x_i) \approx p(z \vert x_i)$$? 

바로 두 가지 네트워크를 둬서 approximate하는 것이 변분법을 사용하는 생성 모델, VAE의 핵심입니다.

$$q_i (z) = q(z \vert x_i) \approx p(z \vert x_i)$$

![cs285_lec18_variational](/assets/images/ae_to_vae/cs285_lec18_variational.png)
*Fig. $$x \rightarrow z$$로 매핑해주는 Encoder Network, $$z \rightarrow x'$$, 즉 생성을 담당하는 Decoder Network 두 가지를 학습하면 된다.*









### <mark style='background-color: #dcffe4'> Amortized Variational Inference </mark>

이제 우리는 두 가지 네트워크를 가지게 되었죠.

![cs285_lec18_variational](/assets/images/ae_to_vae/cs285_lec18_variational.png)

그렇기 때문에 `ELBO` 수식도 조금 변경해야할 필요가 있습니다.

$$
log p(x_i) \geq \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] + H(q_i)
$$

모든 데이터 포인트 마다 근사 분포를 가지고 있던 일반적인 변분 추론 (Regular Variational Inference)를 $$q_{\phi}$$라는 네트워크 하나로 바꾸면

$$
\begin{aligned}
& log p(x_i) \geq \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] + H(q_i) & \\
& \geq \mathbb{E}_{z \sim q_{\phi}(z \vert x_i)} [log p(x_i \vert z) + log p(z)] + H(q_{\phi}(z \vert x_i)) &
\end{aligned}
$$

위와 같은 일반화된 수식을 얻을 수 있습니다. 

(주의해야 할 점은 $$p(z)$$는 prior로 (일반적으로 머신러닝 사용되는 prior 개념 맞습니다.) 변하지 않는 분포입니다. 즉 파라메터가 없습니다. 바뀐건 $$q_i$$ 입니다.) 


이로써 `ELBO`가 아래와 같이 새로 정의됐습니다.

$$
L(p_{\theta}(x_i \vert z), q_{\phi}(z \vert x_i)) = \mathbb{E}_{z \sim q_{\phi}(z \vert x_i)} [log p(x_i \vert z) + log p(z)] + H(q_{\phi}(z \vert x_i))
$$

목적 함수가 바뀌었으니 업데이트 하는 training procedure도 바뀌었겠죠?

***

$$
\begin{aligned}

& \text{for each } x_i (\text{ or mini-batch}): & \\
& \quad \text{calculate } \bigtriangledown_{\theta} L(p_{\theta}(x_i \vert z), q_{\phi}(z \vert x_i)): & \\
& \quad \quad \text{sample } z \sim q_{\phi}(z \vert x_i) & \\
& \quad \quad \bigtriangledown_{\theta} L \approx \bigtriangledown_{\theta} log p_{\theta} (x_i \vert z) & \\
& \quad \theta \leftarrow \theta + \alpha \bigtriangledown_{\theta} L & \\
& \quad \phi \leftarrow \phi + \alpha \bigtriangledown_{\phi} L &
 
\end{aligned}
$$

***

(크게 다를 바 없으니 천천히 음미해 보시면 될 것 같습니다.)


자, 이제는 정말 거의 다 왔습니다. 
마지막 문제점 하나만 해결하면 잠재 변수 모델을 학습시킬 수 있는데요,
그것은 바로 어떻게 $$q_{\phi}$$ 네트워크의 미분을 계산할까? 입니다.

- how $$ \phi \leftarrow \phi + \alpha \bigtriangledown_{\phi} L $$ ???








### <mark style='background-color: #dcffe4'> Re-Parameterization Trick </mark>

`ELBO`에서 $$\phi$$는 두 곳에서 사용됩니다.

$$
L(p_{\theta}(x_i \vert z), q_{\phi}(z \vert x_i)) = \mathbb{E}_{z \sim q_{\phi}(z \vert x_i)} [log p(x_i \vert z) + log p(z)] + H(q_{\phi}(z \vert x_i))
$$

하나는 기대 값을 계산할 때 샘플링을 하는 분포이며, 다른 하나는 두번째 term인 엔트로피를 계산할 때 입니다.
여기서 두 번째 엔트로피를 계산하는 term은 쉽게 계산할 수 있습니다. (tensorflow나 pytorch 같은 딥러닝 프레임워크를 사용하면 간단하게 자동으로 미분해줍니다.)


하지만 문제는 기대 값을 계산하는 부분에서 발생합니다.
기대 값 안의 수식은 $$\phi$$와 관련이 없지만 바로 샘플링 (sampling)을 하는데 $$z \sim q_{\phi}$$ 부분에서 문제가 발생하는 건데요,
왜냐하면 이러한 샘플링을 하는 과정은 `미분 불가능 (non-differentiable)` 하기 때문에 gradient를 끝에서 끝까지 전파할 수 없기 때문입니다.


이에 대해서 조금 더 논하기 위해서 수식을 아래와 같이 조금 바꾸도록 하겠습니다.

$$
\begin{aligned}

& J(\phi) = \mathbb{E}_{z \sim q_{\phi} (z \vert x_i)} [log p(x_i \vert z) + log p(z)] & \\
& J(\phi) = \mathbb{E}_{z \sim q_{\phi} (z \vert x_i)} [r(x_i,z)] &

\end{aligned}
$$

기대 값 내부의 수식이 $$r(x_i,z)$$로 바뀌었습니다.

사실 다른 알파벳을 사용할 수도 있었지만 $$r$$로 표현한 이유가 있습니다.
그것은 바로 이 기대 값이 나타내는 바가 어떠한 분포에서 행동과 상태를 샘플링을 하고, 이를 이용해 보상값을 계산해서 평균내는 `강화 학습의 기본 목적함수`와 닮았기 때문입니다.
그래서 보상을 의미하는 reward의 이니셜 r을 따온 것이며, 또한 강화 학습의 `정책 경사 (Policy Gradient)`알고리즘인 `REINFORCE`알고리즘이 미분 불가능한 알고리즘을 다루기 좋은 방법론이기 때문에, 겸사겸사 원 수식을 강화 학습처럼 나타낸 것입니다.  


REINFORCE를 사용한 Objective Function, ELBO의 미분형태는 아래와 같은데요, 

$$
\begin{aligned}
& J(\phi) = \mathbb{E}_{z \sim q_{\phi} (z \vert x_i)} [r(x_i,z)] & \\
& \bigtriangledown J(\phi) = \frac{1}{M} \sum_j \bigtriangledown_{\phi} log q_{\phi} (z_j \vert x_i) r(x_i, z_j) &
\end{aligned}
$$

우리가 강화학습을 다루는 게 아니기 때문에 여기까지만 하고 미분 불가능한 함수를 다루는 다른 방법론에 대해서 알아보긴 할 것이지만,
조금만 설명을 보태자면 바로 위의 수식은 `크로스 엔트로피 (Cross Entropy, CE) 손실함수`의 각 클래스 마다 보상 (reward) 이라는 값을 곱해준, 즉 `weight sum`한 수식이라고 할 수 있습니다.


그리고 정책 경사 알고리즘은 일반적으로 variance가 크다는 문제점 등이 있는데, 물론 잠재 변수 $$z$$를 여러번 샘플링 하는 방법으로 이를 줄일 수 있지만, 이보다 더 빠르고 실용적이며 범용적인데다가, 강화 학습 알고리즘과는 다르게 $$r$$의 미분값을 직접적으로 계산할 수 있는 방법이 있으니, 바로 앞으로 설명 할 `Re-Parameterization Trick` 입니다.



우리가 추론하고 싶은 분포는 $$\phi$$로 파라메터화 된 가우시안 분포이죠.
여기서 `샘플링을 하는 연산 (Sampling Operation)`을 바로 아래와 같이 수정할 수 있는데요,


$$
\begin{aligned}
& q_{\phi} (z \vert x) = N(\mu_{\phi}(x), \sigma_{\phi} (x) ) &\\
& z = \mu_{\phi} (x) + \epsilon \sigma_{\phi} (x) &
\end{aligned}
$$

바로 $$\phi$$와 관련없는 다른 $$N(0,1)$$에서 랜덤 샘플링을 한 뒤 ($$\epsilon \sim N(0,1)$$) $$\mu_{\phi}$$에 더해주는 겁니다.
이렇게 되면 $$z$$ 자체를 평균과 분산에 대한 `deterministic function`으로 나타낼 수 있고, $$\epsilon$$만 `stochastic`합니다.

![cs285_lec18_reparam](/assets/images/ae_to_vae/cs285_lec18_reparam.png)
*Fig. Reparametarization Trick*


이렇게 할 경우 분포로부터 샘플링 하는 `stochastic`함을 유지하면서도, 직접적으로 샘플링을 하는게 아니며 $$\epsilon$$은 네트워크와 관련이 없는 랜덤 변수이기 때문에 $$\phi$$에 미분을 전파하는데 전혀 문제가 없습니다.

![repram](/assets/images/ae_to_vae/repram.png)
*Fig. Error Backpropagation of Re-Parameterization Trick. $$\epsilon$$을 샘플링 하는 것은 $$\phi$$와 별개이기 때문에 문제가 되지 않는다.*

이제 우리의 `ELBO`의 첫 번째 term인 기대 값 수식은 아래와 같이 수정할 수 있습니다. 

$$
\begin{aligned}

& J(\phi) = \mathbb{E}_{z \sim q_{\phi} (z \vert x_i)} [r(x_i,z)] & \\
& = \mathbb{E}_{\epsilon \sim N(0,1)} [r(x_i,\mu_{\phi} (x_i) + \epsilon \sigma_{\phi} (x_i))] &

\end{aligned}
$$

이름 그대로 원래의 분포 $$z \sim q_{\phi}(z \vert x_i)$$ 를 `재 매개변수화 (Re-Parameterization)` 한 것이 되는겁니다!


이제 이를 이용해서 training procedure에서 `ELBO`를 $$\phi$$에 대해서 미분하는 $$\bigtriangledown_{phi} J(\phi)$$를 아래와 같이 수정할 수 있습니다.

***

$$
\begin{aligned}

& \text{estimating } \bigtriangledown_{\phi} J(\phi) : & \\
& \quad \text{sample } \epsilon_1,\cdots,\epsilon_M \space from \space N(0,1) & \\
& \quad \bigtriangledown_{\phi} J(\phi) \approx \frac{1}{M} \sum_j \bigtriangledown_{\phi} r(x_i,\mu_{\phi} (x_i) + \epsilon_j \sigma_{\phi} (x_i)) & 

\end{aligned}
$$

***

마지막으로 우리는 `ELBO`를 지금까지 배운 `Entorpy`와 `KLD`의 연관성과 `Re-Parameterization`등을 사용해서 최종적으로 아래와 같이 전개해서 표현할 수 있는데요,

$$
\begin{aligned}

& L_i = \mathbb{E}_{z \sim q_{\phi}(z \vert x_i)} [log p_{\theta} (x_i \vert z) + log p(z)] + H( q_{\phi}(z \vert x_i) ) &  \\

& = \mathbb{E}_{z \sim q_{\phi}(z \vert x_i)} [log p_{\theta} (x_i \vert z)] + \mathbb{E}_{z \sim q_{\phi}(z \vert x_i)} [log p_(z)] + H( q_{\phi}(z \vert x_i) ) &  \\

& = \mathbb{E}_{z \sim q_{\phi}(z \vert x_i)} [log p_{\theta} (x_i \vert z)] - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) & \\

& = \mathbb{E}_{\epsilon \sim N(0,1)} [log p_{\theta} (x_i \vert \mu_{\phi} (x_i) + \epsilon \sigma_{\phi} (x_i) )] - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) & \\

& \approx log p_{\theta} (x_i \vert \mu_{\phi} (x_i) + \epsilon \sigma_{\phi} (x_i) ) - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) & 

\end{aligned}
$$

우변의 두 항 중 첫 번째 항이 더 어렵고 두 번째의 KLD는 쉽게 계산할 수 있습니다.
그리고 첫 번째 항은 $$\theta$$와 $$\phi$$두 가지 모두 관여되어 있으며, 두 번째 항은 $$\phi$$만 관여되어 있습니다.


이 수식을 두 파라메터 모두에 대해서 최대화 하게 되면

![elbo_kld](/assets/images/ae_to_vae/elbo_kld.png){: width="50%"}
*Fig. ELBO를 최대화 한다는 것의 의미*

우리는 bound를 tight하게 만들면서 진짜 Objective Function을 최대화할 수 있습니다.


***

VAE 학습하는 방법은 다음과 같다.

1. ELBO를 설정한다 (코딩한다).
2. ELBO는 $$log p_{\theta}(x_i \vert z)$$ 와 $$D_{KL} (q_{\phi} (z \vert x_i) \parallel p(z))$$ 두 가지로 이루어져있다.
3. Tensorflow나 Pytorch같은 자동 미분 패키지로 오차 역전파 (Error Backpropagation)을 통해 파라메터, $$\theta,\phi$$를 학습한다. (ELBO를 올려야 하기 때문에 경사 상승법 (gradient ascent)을 쓰면 되는데 -ELBO라면 경사 하강법을 쓸 수도 있다.)

***





먼 길을 달려왔지만 다시 한 번, 이 네트워크가 Variational AutoEncoder (VAE)인 이유는 아래 보이는 바와 같이 AE와 닮았기 때문입니다.

![ae](/assets/images/ae_to_vae/ae.png)
*Fig. 일반적인 AutoEncoder (AE) 의 모식도*

![vae2](/assets/images/ae_to_vae/vae2.png)
*Fig. Variational AutoEncoder (VAE)의 모식도*

(DAE와 비교해서 생각해보면 VAE는 입력 단계에서 노이즈가 들어가는 DAE와 다르게, 잠재 변수 단계에서 노이즈가 들어간다.)



```
Re-Parameterization Trick이 간편하고 계산하기 쉽지만 연속적인 분포에 대해서만 사용 가능하다는 단점이 있으며,
반대로 짧게 소개해드렸던 정책 경사 기반의 방법론은 variance가 크지만 연속, 이산적인 분포 모두에 사용 가능하다는 장점이 있습니다.
```








### <mark style='background-color: #dcffe4'> VAE </mark>

자 이제 모든게 준비됐으니 `Variational AutoEncdoer (VAE)`에 대해서 다시 한 번 처음부터 끝까지 살펴보도록 하겠습니다.


VAE는 가우시안 사전 분포 $$p(z)$$를 사용하는 잠재 변수 모델 (latent variable models)의 일종 입니다.

![cs285_lec18_vae1](/assets/images/ae_to_vae/cs285_lec18_vae1.png)
*Fig. VAE*

VAE를 요약하면 아래와 같습니다.

{: class="info"}
|NN| Symbol | Input | Output | param | 목적 |
|---| ---- | ---- | ---- | -- | ----------|
|Encoder| $$q_{\phi}(\mathbf{z}\vert\mathbf{x})$$ | x (i.e. 이미지) | $$\mu_{\phi}$$,$$\sigma_{\phi}$$ (가우시안으로 가정했기 때문) | $$\phi$$ |  x를 입력으로 분포를 추론 (Inference) | 
|-| $$p(z)$$ | - | - | - | 사전 분포 (Prior). $$q_{\phi}(z \vert x)$$는 이 분포를 닮아야 함. |
|Decoder| $$p_{\theta}(\mathbf{x}\vert\mathbf{z})$$ | z ($$q_{\phi}(z \vert x)$$에서 샘플링한 벡터) | x (i.e. 생성된 이미지) | $$\theta$$ | 이미지 생성 (Generation), 이 때 모든 픽셀에 대해서 $$\mu_{\theta}$$,$$\sigma_{\theta}$$ 를 독립적으로 만들어 냄. 즉, 회귀 (Regression) 문제를 푼다고 보면 됨. |
|---| ---- | ---- | ---- | -- | ----------|


Encoder가 만들어낸 $$q_{\phi}(\mathbf{z}\vert\mathbf{x})$$가 지금은 `봉우리가 한 개인 다변량 가우시안 분포 (Unimodal Multivariate Gaussian Distribution)`이기 때문에 아래와 같은 분포에서 샘플링을 한다고 생각하면 됩니다.


![cs285_lec18_vae3](/assets/images/ae_to_vae/cs285_lec18_vae3.png){: width="60%"}
*Fig. Unimodal Multivariate Gaussian Distribution으로 부터 샘플링한 벡터를 given으로 이미지를 생성한다.*

(물론 Unimodal Multivariate Gaussian Distribution가 아니라 봉우리가 한 10개정도 되는 `Density Network`를 사용해도 됩니다.)


DAE나 AE는 인코더가 차원이 축소된 히든 벡터 (Representation)를 배울 수는 있어도 이 히든 벡터를 컨트롤 해서 그럴싸한 샘플들을 (학습에 사용된 샘플을 복원하는 것 말고) 추가적으로 만들어낼 수 없으나 VAE는 가능합니다. 왜냐하면 애초에 고정된 벡터 (fixed vector)를 추출하는 AE와 다르게 (목적 자체가 고정된 벡터만 뽑으면 됐죠, 차원 축소니까), VAE는 잠재 변수의 분포를 학습했고 그 분포는 그냥 만들어 진 것이 아니라 원 데이터들이 샘플링 됐을 법한 실제 분포를 닮도록 학습이 됐기 때문입니다. 


VAE는 아래와 같은 목적 함수를 최대화 하면 되는데, (이미 수차례 정의했죠)

$$
\begin{aligned}
& L_{VAE} = - ELBO & \\
& = - \sum_{i=1}^{N} [ log p_{\theta} (x_i \vert \mu_{\phi} (x_i) + \epsilon \sigma_{\phi} (x_i) ) - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] & \\
& \hat{\theta},\hat{\phi} = arg min_{\theta,\phi} ( - \sum_{i=1}^{N} [ log p_{\theta} (x_i \vert \mu_{\phi} (x_i) + \epsilon \sigma_{\phi} (x_i) ) - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] )  &
\end{aligned}
$$

이를 그림으로 디테일하게 나타내면 아래와 같이 됩니다.

![Tutorial on Variational Autoencoders_fig3](/assets/images/ae_to_vae/Tutorial on Variational Autoencoders_fig3.png)
*Fig. VAE in Training Time*

그리고 학습이 끝난 후에는 아래처럼 가우시안 분포에서 샘플링해서 전에 없던 데이터를 만들어내면 됩니다.
(이 잠재 변수가 해석이 가능한가? 어떻게 컨트롤 해야 하는가?는 다음에 알아보도록 하겠습니다.)

![Tutorial on Variational Autoencoders_fig4](/assets/images/ae_to_vae/Tutorial on Variational Autoencoders_fig4.png){: width="40%"}
*Fig. VAE in Test Time*

Test time 에서 인코더는 사용되지 않습니다.


$$
\begin{aligned}

& \hat{\theta},\hat{\phi} = arg max_{\theta,\phi} ( \sum_{i=1}^{N} [ log p_{\theta} (x_i \vert \mu_{\phi} (x_i) + \epsilon \sigma_{\phi} (x_i) ) - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] ) & \\

& \hat{\theta},\hat{\phi} = arg min_{\theta,\phi} ( - \sum_{i=1}^{N} [ log p_{\theta} (x_i \vert \mu_{\phi} (x_i) + \epsilon \sigma_{\phi} (x_i) ) - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] ) &

\end{aligned}
$$

이 수식에서 첫 번째 term은 '이미지를 잘 만들도록 학습해라' 라는 의미를 가지기 때문에 `Reconstruction Error term`이라고 하며, 두 번째 term은 inference네트워크가 뱉는 분포가 prior $$p(z)$$ 분포와 비슷해야 한다는 제약을 담고 있기 때문에 `Regularization term` 혹은 `Penalty term` 이라고 부릅니다. 


***

여담이지만 ELBO를 $$\theta,\phi$$에 대해서 최대화 하는 방향으로 학습하는 것, 즉 번갈아가면서 인코더, 디코더를 maximize 하는 것은 EM Algorithm으로 잠재 변수 모델을 학습하는 것과 닮았습니다.

![elbo_vs_em1](/assets/images/ae_to_vae/elbo_vs_em1.png)
*Fig. ELBO vs EM Algorithm*

![elbo_vs_em2](/assets/images/ae_to_vae/elbo_vs_em2.png)
*Fig. ELBO vs EM Algorithm*

글이 너무 길어질 것 같아 자세한 이론은 생략하도록 하겠습니다. 더 궁금하신 분들은 구글링을 해보시면 좋을 것 같습니다. 

***



### <mark style='background-color: #dcffe4'> VAEs with various type of decoder </mark>

VAE에서 사용되는 뉴럴 네트워크들은 분포를 출력하는 확률적인 인코더와 디코더 인데요, 그렇기 때문에 VAE의 디코더의 출력이 어떠한 확률 분포를 출력해도 상관이 없습니다.
즉 출력 분포를 베르누이 분포로 가정할 수도 있고, 가우시안 분포로 가정할 수도 있다는 거죠.


이를 MNIST 손글씨 이미지 데이터셋을 가지고 비교해서 알아보도록 하겠습니다.

![mnist](/assets/images/ae_to_vae/mnist.png)
*Fig. MNIST Dataset*



#### < VAE with Gaussian Decoder >

우리가 출력 픽셀들에 대한 분포를 `가우시안 분포`로 가정해보도록 하겠습니다.

![lee_gaussian_decoder_vae1](/assets/images/ae_to_vae/lee_gaussian_decoder_vae1.png)
*Fig. VAE with Gaussian Decoder*

가우시안 분포로 가정을 했다는 것은 즉 회귀 문제를 풀겠다는 것이며 likelihood loss로 `평균 제곱 오차 (Mean Squared Error, MSE)`가 도출된다는 것을 의미합니다.


이는 `ELBO`에 출력 분포를 실제로 대입하면 쉽게 유도할 수 있는데요, 입출력 이미지 차원이 $$D = 28 \times 28 = 768$$차원이고, 학습 이미지 데이터의 수가 $$N$$개라고 하며, 각 학습 데이터당 $$K$$차원의 $$z$$를 딱 한번씩만 샘플링 한다고 하면, 

$$
\begin{aligned}
& L_{VAE} = - ELBO & \\
& = - \sum_{i=1}^{N} [ log p_{\theta} (x_i \vert z ) - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] & \\
& = - \sum_{i=1}^{N} [ log ( N(x_i ; \mu_i,\sigma^2_i I) ) - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] & \\
& = - \sum_{i=1}^{N} [  \sum_{j=1}^D  ( -\frac{log(2\pi)}{2}-\frac{log(\sigma_{i,j}^2)}{2} - \frac{(x_{i,j} - \mu_{i,j})^2}{2 \sigma^2_{i,j}}  )  - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] & \\
& \approx - \sum_{i=1}^{N} [  \sum_{j=1}^D  ( - (x_{i,j} - \mu_{i,j})^2  )  - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] & \\
& \approx \sum_{i=1}^{N} [  \sum_{j=1}^D  ( (x_{i,j} - \mu_{i,j})^2  )  + D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] & \\
\end{aligned}
$$

여기서 가우시안 분포 두 개로 구성된 Regularization loss, KLD 마저 전개하면


$$
\begin{aligned}

& L_{VAE} = - ELBO & \\
& \approx \sum_{i=1}^{N} [  \sum_{j=1}^D  ( (x_{i,j} - \mu_{i,j})^2  )  + D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] & \\
& \approx \sum_{i=1}^{N} [  \sum_{j=1}^D  ( (x_{i,j} - \mu_{i,j})^2  )  + \frac{1}{2} ( tr(\sigma_i^2 I) + \mu_i^T \mu_i - K + ln \frac{1}{\prod_{k=1}^K \sigma_{i,k}^2 }) ] & \\
& \approx \sum_{i=1}^{N} [  \sum_{j=1}^D  ( (x_{i,j} - \mu_{i,j})^2  )  + \frac{1}{2} ( \sum_{k=1}^K \sigma_{i,k}^2 + \sum_{k=1}^{K} \mu_{i,k}^2 - K + \sum_{k=1}^K ln(\sigma_{i,k}^2) ) ] & \\
& \approx \sum_{i=1}^{N} [  \sum_{j=1}^D  ( (x_{i,j} - \mu_{i,j})^2  )  + \frac{1}{2} ( \sum_{k=1}^K  \mu_{i,k}^2 + \sigma_{i,k}^2 - ln (\sigma_{i,k}^2) -1) ] & \\

\end{aligned}
$$

이 되며, 우리는 이 Objective를 $$\phi,\theta$$에 대해서 최소화 하면 (ELBO에 음수를 취했기 때문에) 됩니다.

(KLD를 직접 전개해서 closed-form으로 나타낼 때 우리가 encoder의 출력을 왜 가우시안 분포처럼 모델링 해야 하는지를 알 수 있는데요, 가우시안 분포가 아니라면 이 KLD를 이렇게 간단하게 전개하기가 힘들기 때문입니다.)


#### < VAE with Bernoulli Decoder >

그렇다면 출력 픽셀들의 분포가 베르누이 분포라면 어떨까요?
출력 분포를 베르누이 분포로 하겠다는 것은 $$0 \sim 1$$ 사이의 값을 뱉는 $$p$$와 $$1-p$$로 픽셀 값을 모델링 하겠다는 겁니다.

이게 가능한 이유는 MNIST데이터셋이 $$0 \sim 1$$ 사이의 값을 가지는 흑백 손글씨 이미지이기 때문입니다.

![lee_bernoulli_decoder_vae1](/assets/images/ae_to_vae/lee_bernoulli_decoder_vae1.png)
*Fig. VAE with Bernoulli Decoder*

이를 마찬가지로 $$D$$차원 입력 이미지에 대해서 전개해보면 아래와 같이 됩니다.

$$
\begin{aligned}
& L_{VAE} = - ELBO & \\
& = - \sum_{i=1}^{N} [ log p_{\theta} (x_i \vert z ) - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] & \\
& = - \sum_{i=1}^{N} [  \sum_{j=1}^D  ( log p_{i,j}^{x_{i,j}} (1-p_{i,j})^{1-x_{i,j}} )  - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] & \\
& = - \sum_{i=1}^{N} [  \sum_{j=1}^D  ( x_{i,j} log p(i,j) + (1-x_{i,j}) log (1-p_{i,j}) )  - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] & \\
& = \sum_{i=1}^{N} [  - (\sum_{j=1}^D  ( x_{i,j} log p(i,j) + (1-x_{i,j}) log (1-p_{i,j}) ) ) + D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] & \\
& = \sum_{i=1}^{N} [  - (\sum_{j=1}^D  ( x_{i,j} log p(i,j) + (1-x_{i,j}) log (1-p_{i,j}) ) ) + \frac{1}{2} ( \sum_{k=1}^K  \mu_{i,k}^2 + \sigma_{i,k}^2 - ln (\sigma_{i,k}^2) -1) ] & \\
\end{aligned}
$$

여기서 출력 분포가 베르누이 분포라면 일반적으로 likelihood term이 우리가 아는 `Binary Cross Entropy (BCE)`가 되는데, 여기서 일반적으로 분류 모델에 사용되는 BCE와 차이점이 있다면, 정답 픽셀이 $$x \in \{ 0,1 \}$$ 이 아니라 $$x \in ( 0,1 )$$라는 겁니다. 
즉 모아니면 도, 검은색 아니면 흰색이 정답은 아니라는 거죠. 


이렇게 출력 분포에 따라서 디코더를 모델링 할 수 있는데, 어떤 확률 분포를 가정하는 것이 더 좋다라고 하기는 어렵습니다.

![bernoulli_vs_gaussian](/assets/images/ae_to_vae/bernoulli_vs_gaussian.png)
*Fig. The comparison of VAES with Bernoulli Decoder and Gaussian Decoder*

위에 그림에서 아래의 두 베르누이,가우시안 분포의 디코더를 사용한 VAE에는 `생성된 이미지가 흐릿한 (blurry) 문제`가 있다는 걸 알 수 있는데요,
이는 VAE의 일반적인 특성이지만 이를 해결하기 위한 방법들도 많이 제안이 되었으니 관심있으신 분들은 관련된 논문들을 찾아보시면 좋을 것 같습니다.









### <mark style='background-color: #dcffe4'> Why does VAE work? (Learned Manifold and Results) </mark>

VAE가 왜 work할까요? 그 이유는 직관적으로 수식의 바로 두 번째 텀인 KLD의 존재 덕분에, 우리는 $$q_{\phi}(z \vert x_i)$$을 강제로 아주 쉬운 분포인 가우시안 분포, $$p(z)$$를 닮게끔 제약하고 (penalty or regularization), 디코더 또한 이로부터 샘플링된 z를 기반으로 이미지를 생성하는 것이 훈련되어 있기 때문입니다. 

![Tutorial on Variational Autoencoders_fig1](/assets/images/ae_to_vae/Tutorial on Variational Autoencoders_fig1.png)
*Fig. 이변량 정규 분포 (Bivariate Gasussian Distribution)에서 (좌) 샘플링 한 랜덤 변수를 입력으로 디코더는 전혀 다른 분포의 랜덤 변수를 만들게 된다(우).*

실제로 VAE를 통해 만들어진 $$q_{\phi}(z \vert x)$$ 분포는 아래의 모양처럼 가우시안 분포를 닮았으며,

![lee_learned_manifold1](/assets/images/ae_to_vae/lee_learned_manifold1.png)
*Fig. 고차원 이미지를 2차원으로 인코딩 했을 때 AE와 VAE의 차이. VAE는 2차원 정규 분포, $$N(0,I)$$로 매핑하는 강제성이 있기 때문에 평균인 0 중앙에 매핑된 벡터들이 모여있으며, 이렇게 좁은 범위 안에 뭉쳐놓는 것이 이미지를 생성하는 입장에서는 다루기가 .*

이를 조금 확대해 보면, MNIST 데이터셋의 서로 다른 숫자 이미지가 가우시안 분포 내에서 어떻게 형성되었는지를 알 수 있습니다.

![lee_learned_manifold2](/assets/images/ae_to_vae/lee_learned_manifold2.png)
*Fig. 고차원의 원본 이미지가 2차원 space에 어떻게 매핑 되었는지 알 수 있다. 이렇게 우리가 원하는 대로 가우시안 분포로 매핑되었기 때문에, test time에서 가우시안 분포로부터 샘플링한 2차원 벡터를 given으로 이미지를 생성하면 그럴싸한 이미지가 생성되는 것이다.*

만약 KLD 텀이 없다고 생각해 볼까요?

![kld_term1](/assets/images/ae_to_vae/kld_term1.png)
*Fig. Regularization term의 존재 유무에 따른 매니폴드의 차이*

그렇다면 위의 사진처럼 학습된 매니폴드 상에서 의미대로 이미지가 잘 나눠지지 않는다는 걸 알 수 있습니다.

![kld_term2](/assets/images/ae_to_vae/kld_term2.png)
*Fig. Regularization term이 중요한 이유*











## <mark style='background-color: #fff5b1'> Various version of VAEs  </mark>

마지막으로 VAE의 다양한 변이 네트워크 들에 대해서 간단하게 알아보고 글을 마치도록 하겠습니다.

### <mark style='background-color: #dcffe4'> Conditional Variational AutoEncoder (CVAE) </mark>

이번에는 `Conditional VAE (CVAE)`에 대해 알압도록 하겠습니다.
CVAE는 VAE의 아이디어와 크게 다르지 않습니다. 가장 큰 차이는 $$p(x)$$ 를 모델링 하는 것에서 $$p(x \vert y,z)$$로 바뀌었다는 건데요,
마찬가지로 $$p(x \vert y)$$ 자체는 굉장히 복잡한 분포이겠지만, $$p(x \vert y,z)$$와 $$p(z)$$는 그렇지 않을 것이며 VAE가 그랬던 것 처럼 이 두개의 다루기 쉬운 분포의 곱으로 $$p(x \vert y)$$를 나타낼 수 있을 겁니다.


***

- CVAE
  - What we want : $$p(y \vert x) = \int p(y \vert x,z) p(z) dz$$
  - Encoder : $$q_{\phi}(z \vert x_i,y_i)$$
  - Decoder : $$p_{\theta}(x_i \vert y_i,z)$$
  - ELBO : $$L_i = \mathbb{E}_{z \sim q_{\phi}(z \vert x_i,y_i)} [log p_{\theta}(x_i \vert y_i,z) + log p(z)] + H( (q_{\phi} (z \vert x_i,y_i) ) )$$
  - Final Objective : $$ \hat{\theta},\hat{\phi} = arg max_{\theta,\phi} ( \sum_{i=1}^{N} [ log p_{\theta} (y_i \vert (\mu_{\phi} (x_i,y_i) + \epsilon \sigma_{\phi} (x_i,y_i)), y_i ) - D_{KL} ( q_{\phi} (z \vert x_i,y_i ) \parallel p(z) ) ] ) $$
- VAE
  - What we want : $$p(x) = \int p(y \vert z) p(z) dz$$
  - Encoder : $$q_{\phi}(z \vert x_i)$$
  - Decoder : $$p_{\theta}(x_i \vert z)$$
  - ELBO : $$ L(p_{\theta}(x_i \vert z), q_{\phi}(z \vert x_i)) = \mathbb{E}_{z \sim q_{\phi}(z \vert x_i)} [log p(x_i \vert z) + log p(z)] + H(q_{\phi}(z \vert x_i)) $$
  - Final Objective : $$ \hat{\theta},\hat{\phi} = arg max_{\theta,\phi} ( \sum_{i=1}^{N} [ log p_{\theta} (x_i \vert \mu_{\phi} (x_i) + \epsilon \sigma_{\phi} (x_i) ) - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] ) $$


여기서 CVAE의 경우 아래 처럼 $$x_i$$를 컨디션한 prior를 구성해도 되고

$$L_i = \mathbb{E}_{z \sim q_{\phi}(z \vert x_i,y_i)} [log p_{\theta}(y_i \vert x_i,z) + log p(z \vert y_i)] + H( (q_{\phi} (z \vert x_i,y_i) ) )$$

아니어도 됩니다.

$$L_i = \mathbb{E}_{z \sim q_{\phi}(z \vert x_i,y_i)} [log p_{\theta}(y_i \vert x_i,z) + log p(z)] + H( (q_{\phi} (z \vert x_i,y_i) ) )$$

***

![lee_cvae1](/assets/images/ae_to_vae/lee_cvae1.png)
*Fig. VAE vs CVAE*


추가적으로, 데이터의 일부에 대해서만 정답을 알고있는 경우 위의 Objective처럼 `Supervised`가 아니라 `Semi-Supervised`로 문제를 풀어야 하는데 이런 경우도 크게 위에서 유도한 ELBO와 식이 다르지 않으니, 더 관심이 있으신 분들은 원본 논문 ([Learning Structured Output Representation using Deep Conditional Generative Models](https://papers.nips.cc/paper/2015/file/8d55a249e6baa5c06772297520da2051-Paper.pdf))을 참조하시면 좋을 것 같습니다.

![lee_cvae2](/assets/images/ae_to_vae/lee_cvae2.png)
*Fig. Semi-Supervised CVAE. Label이 존재하는 데이터의 경우 그대로 CVAE를 쓰되, 모를 경우 정답을 추정하는 네트워크를 별도로 추가해서 문제를 푼다. M3는 M2와 유사하지만 더욱 간단한 방법론이다.*

어쨌든, 그림을 보시면 아시겠지만 $$x$$가 VAE에서와 마찬가지로 이미지가 되겠고, $$y$$가 이미지에 대한 label같은 정보라면 (i.e. 숫자 4,5 ...), 이런식으로 Auto-Encoding 학습이 된 네트워크는 근사 분포로부터 $$z$$를 뽑은 후 이미지에 대한 클래스 정보 $$y$$정보를 같이 condition해주면 우리가 원하는 이미지를 만들어 낼 수 있습니다.


이렇게 레이블 정보를 추가적으로 넣어서 학습한 CVAE는 VAE에 비해서 더욱 선명한 이미지를 만들어 내며, 네트워크의 수렴 속도도 훨씬 빠르다.

![cvae1](/assets/images/ae_to_vae/cvae1.png)
*Fig. Latent Vector의 차원이 2일 때 VAE보다 더욱 선명한 이미지를 만들어내는 CVAE.*

이는 노이즈를 엄청 섞은 이미지에 대해서도 VAE보다 훨씬 잘 됩니다.

![cvae2](/assets/images/ae_to_vae/cvae2.png)
*Fig. 같은 에폭일 때 De-noising을 훨씬 잘한다.*

학습 데이터로 주어지지 않은 새로운 이미지를 샘플링 하는 테스트 타임에서 CVAE의 진가가 드러나는데요, 
레이블 정보를 주고 재생하는 방식으로 학습을 했기 때문에, $$z$$를 샘플링 한 뒤, 우리가 원하는 레이블 정보, $$y$$를 같이 주기만 하면 우리는 원하는 숫자 이미지를 새로 뽑을 수 있게 되는 겁니다. 

![cvae3](/assets/images/ae_to_vae/cvae3.png)
*Fig. VAE에서와 다르게 z가 숫자의 회전, 기울기, 굵기 등의 공통된 feature를 담고 있는 변수가 되고, y가 숫자를 바꿀 수 있는 query가 된다.*

이는 당연하면서도 꽤나 흥미로 결과인데요,
우리가 VAE를 그냥 학습할 때는 $$z$$ 분포 안에, 스타일 정보(굵기, 회전 정도, 기울기)와 숫자 label 정보가 다 같이 들어있었는데,
CVAE는 이 숫자 label 정보를 $$y$$로 따로 분리한게 되는겁니다.

그래서 VAE가 아래의 그림처럼 제대로 스타일을 컨트롤하기 힘든데 반해서 CVAE는 `똑같은 z를 가지고 y만 바꾼다거나` 아니면 `똑같은 y를 가지고 z만 바꾼다거나`하는 식으로 우리가 원하는 결과를 도출해 낼 수 있다는 겁니다. 

![lee_learned_manifold2](/assets/images/ae_to_vae/lee_learned_manifold2.png)
*Fig. z안에 모든 정보가 다 들어있는 VAE*

![cvae3](/assets/images/ae_to_vae/cvae3.png)
*Fig. CVAE의 경우는 VAE와 다르게 z는 스타일 정보만, y는 숫자 label정보만 가진다. 똑같은 y를 가지고 z만 컨트롤 하면 똑같은 숫자를 다양한 스타일로 얻을 수 있다.*

![cvae4](/assets/images/ae_to_vae/cvae4.png){: width="60%"}
*Fig. 반대로 똑같은 z를 가지고 y만 컨트롤 하면 굵기, 기울기 등 스타일은 동일하지만 다른 숫자를 얻을 수 있다.*

VAE, CVAE 각 네트워크가 배우는 manifold도 아래와 같이 차이가 납니다.  

![vae_vs_cvae_manifold](/assets/images/ae_to_vae/vae_vs_cvae_manifold.png)
*Fig. VAE와 CVAE가 배우는 manifold의 차이*

CVAE의 manifold가 굉장히 얽혀 있어 (entangled) 보이지만 사실 condition을 하나씩만 해서 뿌려보면 굉장히 잘 배운 manifold임을 알 수 있습니다.










### <mark style='background-color: #dcffe4'> Beta - Variational AutoEncoder (Beta-VAE) </mark>

이번에 알아볼 변이체는 $$\beta$$-VAE입니다. 

VAE는 일반적으로 아래와 같은 두 가지 문제점을 가집니다.

- 네트워크가 latent code를 잘 사용하지 않는 (무시한)다 ($$p_{\theta}(x \vert z) \rightarrow p(x)$$). 그 결과 재생한 이미지는 굉장히 흐릿 (blurry) 하다.
- latent code가 압축이 잘 되지 않는다 ($$q_{\phi}(z \vert x)$$ very far from $$p(z)$$). 그 결과 네트워크 자체가 identity function처럼 되어 학습시 재생한 이미지는 굉장히 선명하나, 실제로 z로부터 샘플링 해서 디코딩을 할 경우 아무것도 아닌 쓰레기 이미지를 얻게 된다.

이 경우 모두 ELBO의 KLD 텀이 문제인데요, 

$$
D_{KL} = (q_{\phi}(z \vert x) \parallel p(z))
$$

전자의 경우 KLD가 너무 작기 때문이고, 후자의 경우 KLD가 너무 크기 때문입니다.
전자의 경우에는 $$q_{phi}(z \vert x)$$에서 x정보를 아예 쓰지 않아 분포 자체가 평균이 0이고 분산이 1인 $$p(z)$$와 같아지게 되고, 따라서 `z가 정보를 하나도 가지고 있지 않다`는 뜻이며, 그 결과 디코딩을 할 때도 z정보를 하나도 안 쓰게 되는 겁니다.
후자의 경우는 '사전 분포인 평균이 0이고 분산인 1인 가우시안 분포를 닮아라'는 정규화 텀 잘 작용하지 않아 `z가 너무 많은 정보를 가지고 있다` 가 된 것이며, z가 정보가 너무 많기 때문에 원본 이미지를 너무 잘 만들어 내는 것입니다. 그래서 실제로 테스트 타임에서 prior에서 샘플링을 해 condition한 뒤 이미지를 생성하면 디코더가 어쩔 줄 모르게 되는 것이죠.


즉 우리는 이런 VAE의 흔한 문제들을 해결하기 위해서 KLD 텀을 굉장히 신중하게 컨트롤 해야 하는데요, 이를 위해 제안된 것이 바로 `beta-VAE` 입니다.
beta-VAE의 Objective는 VAE와 별로 차이가 없는데요,

$$
\begin{aligned}
& L_{VAE} = - ( \sum_{i=1}^{N} [ log p_{\theta} (x_i \vert \mu_{\phi} (x_i) + \epsilon \sigma_{\phi} (x_i) ) - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] ) & \\

& L_{\beta-VAE} = - ( \sum_{i=1}^{N} [ log p_{\theta} (x_i \vert \mu_{\phi} (x_i) + \epsilon \sigma_{\phi} (x_i) ) - \beta D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] ) &
\end{aligned}
$$

여기서 $$\beta$$는 하이퍼 파라메터로, 문제에 따라서 변경해주면 됩니다. 
첫 번쨰 문제가 발생하면 KL을 높혀야 하기 떄문에 $$\beta$$를 작은 값을 곱해주면 되고, 두 번째 문제를 마주치면 반대로 하면 됩니다 (강하게 제약을 거는거죠). 
일반적으로 학습 초기에 VAE가 $$z$$에 집중해서 이미지를 reconstruct 하는게 중요하기 때문에 $$beta$$를 학습 초기엔 작은 값으로 하다가 후기에는 큰 값으로 해주는 `hyperparameter scheduling`을 해주면 됩니다. 










### <mark style='background-color: #dcffe4'> Vector Quantized - Variational AutoEncoder (VQ-VAE) </mark>

사실 `CVAE`와 `beta-VAE`도 VAE에 간단한 아이디어를 추가해서 꽤 흥미롭고 중요한 결과를 냈던 모델들인데요, 
양자화 (Vector Quantisation)를 이용한 `VQ-VAE`가 시사하는 바는 후에 제안되는 다양한 모델들에 지대한 영향력을 끼쳤기 때문에 (생성모델 뿐 아니라 자가 지도 학습 (Self-Supervised Learning, SSL)에도 앞선 모델들보다 더욱 중요한 모델이라고 할 수 있습니다.

![vq_vae](/assets/images/ae_to_vae/vq_vae.png)
*Fig. Model Architecture of Vector Quantized - Variational AutoEncoder (VQ-VAE)*

논문에 따르면 VQ-VAE가 VAE와 크게 다른점은 두 가지라고 하는데요,

- Encoder의 출력을 discrete하게 했다. (VAE는 continuous 였죠? 예를들면 2차원 가우시안 분포상의 어느 점이던 가능했습니다.) 양자화를 함으로써 VAE의 흔한 문제점 (z 정보를 안쓴다는 것)이라고 지적되었던 "posterior collapse" 문제를 해결할 수 있었다.
- Prior가 고정되어 (static) 있지 않고 학습된다 (learnt).

이 결과 VQ-VAE는 Speech, Video Generation 등의 task에서 좋은 퀄리티를 보였다고 합니다.


천천히 VQ-VAE가 어떻게 작동하는지 살펴보자면, 우선 VAE처럼 ($$x \rightarrow z$$), ($$z \rightarrow x$$) 두 가지를 학습하는건 맞지만,
여기서 $$z$$를 양자화 하는 과정을 추가되었고 이 과정이 논문에 아래 그림으로 나타나 있습니다.

![vqvae1](/assets/images/ae_to_vae/vqvae1.png)
*Fig.*

최종적으로 우리가 원하는 것은 VAE와 다르게 `Discrete Latent Space`를 배우는 것입니다.


#### < Objective Function >

먼저 간단한게 `Notation`을 아래처럼 정의하고

***

- $$x$$ : Input (image)
- $$z_e(x)$$ : `Encoder output`
- $$e \in R^{K \times D}$$ : Latent Embedding Space
- $$K$$ : Size of the Discrete Latent Space (i.e. K-way Categorical)
- $$e_i \in R^D$$ : Latent Embedding Vector
- $$D$$ : The Dimensionality of each Latent Embedding Vector
- $$z$$ : Latent Variable
- $$z_q(x) = e_k$$ : `Decoder Input`

***

VAE에서 중요한 아래 세가지가 요소들에 대해서 생각을 해보도록 하겠습니다.

***

- approximate posterior : $$q(z \vert x)$$
- prior : $$p(z)$$
- likelihood : $$p(x \vert z)$$

***

여기서 먼저 approximate posterior를 아래처럼 정의할 수 있는데,

$$
q(z = k \vert x) = 
\left\{\begin{matrix}
1 \text{ for } k = argmin_j \| z_e(x) - e_j \|_2, 
\\ 
0 \text{ otherwise}
\end{matrix}\right.
$$

우리는 이산적인 $$z$$ 분포를 배우고 싶기 때문에, 이 근사 분포는 연속적인 분포가 아니라 이산적인 분포, 즉 `Categorical Distribution`을 가정할 수 있습니다.

![categorical1](/assets/images/ae_to_vae/categorical1.png){: width="40%"}
*Fig. Categorical Distribution*

수식에 따르면 $$q(z \vert x)$$는 인코더 출력 $$z_e(x)$$와 가장 가까운 거리 (L2-norm, 즉 Euclidean Distance로 비교)에 있는 임베딩 벡터 $$e_k$$만 1이고 나머지는 다 0인 `One-hot 분포`가 됩니다.

![categorical2](/assets/images/ae_to_vae/categorical2.png){: width="40%"}
*Fig. One-hot Categorical Distribution*

![vqvae2](/assets/images/ae_to_vae/vqvae2.png){: width="60%"}
*Fig. 임베딩 스페이스에 존재하는 각각의 임베딩 벡터들, 각각의 벡터들, $$e_1, e_2, \cdots$$와 $$z_e(x)$$간의 거리를 재서 선택한다.*


여기서 당연히 거리가 가장 가까운 벡터를 선택하여 인코더의 최종 출력이라고 생각하고, 디코더로 넘겨주며 이 디코더를 통해서 원본 데이터를 `재생 (Reconstruction)` 한다.

$$
\mathbf{z}_q(\mathbf{x}) = \text{Quantize}(E(\mathbf{x})) = \mathbf{e}_k \text{ where } k = \arg\min_i \|E(\mathbf{x}) - \mathbf{e}_i \|_2
$$

![vqvae_paper_figure](/assets/images/ae_to_vae/vqvae_paper_figure.png){: width="50%"}
*Fig. 그림에서 $$z_e(x)$$와 가장 가까운 임베딩 벡터는 $$e_2$$이며, 이 벡터가 곧 $$z_q(x)$$이 된다.*

그리고 사전 분포 $$p(z)$$를 VAE와 마찬가지로 넓게 분포된 이산 분포를 원하기 때문에 `Uniform Distribution` 을 고르게 됩니다.  


![distribution](/assets/images/ae_to_vae/distribution.png)
*Fig. 사실 그림에서 Uniform Distribution이 Categorical Distribution의 엔트로피가 최대버전인 것은 아닙니다.*

***

- approximate posterior : $$q(z \vert x)$$ $$\leftarrow$$ `One-hot Categorical Distribution`
- prior : $$p(z)$$ $$\leftarrow$$ `Uniform Distribution`
- likelihood : $$p(x \vert z)$$ $$\leftarrow$$ (Gaussian Distribution일 경우 Reconstruction Error는 MSE가 됨)

***

이제 최종 Objective를 구하면 아래와 같게 되는데,

$$
L = \underbrace{log p(x \vert z_q(x))}_{\textrm{reconstruction loss}} + 
\underbrace{\| sg[z_e(x)] - e \|_2^2}_{\textrm{VQ loss}} + 
\underbrace{\beta \| z_e(x) - sg[e] \|_2^2}_{\textrm{commitment loss}}
$$

여기서 디코더의 출력분포가 가우시안 분포라면 `Negative Log Likelihood`는 `MSE loss`가 되므로 아래와 같은 수식을 얻을 수 있습니다.

$$
L = \underbrace{\|\mathbf{x} - D(\mathbf{e}_k)\|_2^2}_{\textrm{reconstruction loss}} + 
\underbrace{\| sg[z_e(x)] - e_k \|_2^2}_{\textrm{VQ loss}} + 
\underbrace{\beta \| z_e(x) - sg[e_k] \|_2^2}_{\textrm{commitment loss}}
$$

여기서 $$\text{sq}[.]$$ 는 `stop_gradient` 연산자 (operator)를 의미하며, 이 연산자가 하는 일은 입력값을 네트워크에 forwarding 할 때는 identity function처럼 연산해주고 backwarding, 즉 역전파를 할 때는 gradient가 흐르는것을 막아줍니다. 
즉, 피연산자 (operand)가 업데이트 되지 않도록 해주는 거죠.


- Decoder는 `첫 번째 term` 만을 최적화 하며, 두 번째, 세 번째 term은 쓰지 않습니다.
- Encoder는 `첫 번째와 마지막 term`을 최적화 합니다.
- Discrete Space Embedding을 담당하는 Codebook은 `두 번째 term`만 사용합니다.

여기서 두, 세번째 term이 존재하는 이유는, 인코더의 출력 벡터를 양자화 할 때 사용된 argmin opertaor때문에 gradient가 앞으로 흐르지 않게 되고, 
이에 따라서 양자화를 담당하는 임베딩 벡터들을 모아둔 Codebook이 학습되지 않기 때문입니다.
따라서 두 번째 loss term은 $$z_e(x)$$는 가만히 있고 $$e_k$$ 벡터가 $$z_e(x)$$와 가까워지도록 움직이는 것이고, 세 번째 loss term은 $$z_e(x)$$가 $$e_k$$쪽으로 움직이게 되는 것입니다.

![vqvae_paper_figure](/assets/images/ae_to_vae/vqvae_paper_figure.png){: width="50%"}
*Fig. 빨간색 선으로 표시된 $$\bigtriangledown_z L$$에 따라서 인코더가 출력 벡터값을 바꾸도록 학습된다.*

그리고 모든 VAE의 Obejctive인 `ELBO`에 등장하는 `KLD` term은 우리가 `uniform prior`를 가정했기 때문에 상수가 돼 사라진다고 합니다.


$$
\begin{aligned}
& 
L_{VAE} = - \sum_{i=1}^{N} [ log p_{\theta} (x_i \vert \mu_{\phi} (x_i) + \epsilon \sigma_{\phi} (x_i) ) - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) ] 
& \\

& 
L_{VQ-VAE} = \underbrace{\|\mathbf{x} - D(\mathbf{e}_k)\|_2^2}_{\textrm{reconstruction loss}} + 
\underbrace{\| sg[z_e(x)] - e_k \|_2^2}_{\textrm{VQ loss}} + 
\underbrace{\beta \| z_e(x) - sg[e_k] \|_2^2}_{\textrm{commitment loss}}
& 

\end{aligned}
$$






#### < Autoregressive Prior >

VQ-VAE는 Discrete Latent Space를 학습하는 것 이외에도 Test time에서 사용되는 Prior를 Autoregressive하게 만들어 좋은 결과를 얻어내기도 했는데요,
원래의 학습 시 VQ-VAE가 아래와 같이 학습이 되었을 때는 우리가 constant하고 uniform한 Prior $$p(z)$$를 사용했었죠. 

![vqvae_slide_ar](/assets/images/ae_to_vae/vqvae_slide_ar.png){: width="60%"}

Test time에서 가우시안 분포로 부터 샘플링한 $$z$$ 벡터를 통해 이미지 한 장을 만들어 냈던 Vanilla VAE와는 다르게,
이 전까지 만들어진 이미지나 음성에 대해서 

![vqvae_slide_example2](/assets/images/ae_to_vae/vqvae_slide_example2.png){: width="80%"}
![vqvae_slide_example3](/assets/images/ae_to_vae/vqvae_slide_example3.png){: width="80%"}
![vqvae_slide_example4](/assets/images/ae_to_vae/vqvae_slide_example4.png){: width="80%"}
![vqvae_slide_example5](/assets/images/ae_to_vae/vqvae_slide_example5.png){: width="80%"}



![vqvae_slide_example6](/assets/images/ae_to_vae/vqvae_slide_example6.png){: width="80%"}

![vqvae_slide_wavenet1](/assets/images/ae_to_vae/vqvae_slide_wavenet1.png){: width="80%"}
![vqvae_slide_wavenet2](/assets/images/ae_to_vae/vqvae_slide_wavenet2.png){: width="80%"}
![vqvae_slide_wavenet3](/assets/images/ae_to_vae/vqvae_slide_wavenet3.png){: width="80%"}

![vqvae_slide_example7](/assets/images/ae_to_vae/vqvae_slide_example7.png){: width="80%"}

















### <mark style='background-color: #dcffe4'> Temporal Difference - Variational AutoEncoder (TD-VAE) </mark>

TBC



















## <mark style='background-color: #fff5b1'> + Other Deep Genrative Models </mark>

사실 이러한 `심층 생성 모델 (Deep Generative Models)`은 VAE 말고 다른 것들도 있는데요,
대표적으로 `적대적 생성 신경망 (Generative Adversarial Network, GAN)`이나 `Normalizing Flow Network`등이 있습니다.

![three-generative-models](/assets/images/ae_to_vae/three-generative-models.png)
*Fig. Three Deep Generative Models*

이에 대해서 깊게는 아니고 짧게만 다루고 넘어가도록 해보겠습니다.





### <mark style='background-color: #dcffe4'> Normalizing flow models </mark>

`Normalizing Flow Model`은 VAE와 구조적으로 닮았지만 학습하기는 더 쉬운 생성 모델입니다. 
핵심 아이디어는 $$p(x \vert z)$$가 아닌 `deterministic decoder`을 가지고 있다고 생각 해 보는 겁니다.

![cs285_lec18_normalizing_flow1](/assets/images/ae_to_vae/cs285_lec18_normalizing_flow1.png)
*Fig.*


VAE처럼 $$z$$ 분포에서 샘플링을 한 뒤 이를 통해서 디코딩을 하는게 아니라 $$z \rightarrow x$$로 directly 변환해주는 $$x = f(z)$$를 가지고 있는 것이죠.

사실 VAE랑 별로 차이가 없어보이는데요, 이렇게 할 경우 $$p(x)$$ 수식이 완전히 바뀌게 됩니다.

- VAE

$$
p(x) = \int p(x \vert z) p(z) dz
$$

- Normalizing flow

$$
\begin{aligned}
& p(x) = p(z) \vert det(\frac{df(z)}{dz}) \vert^{-1} & \\
& \text{where } z=f^{-1}(x) &
\end{aligned}
$$

이 수식이 의미하는 바는 즉, 우리가 $$x \rightarrow z$$인 deterministic한 함수를 알고 있다면, `Jacobian` 인 $$\frac{df}{dz}$$의 `판별식 (Determinant)`값을 계산하는 것 만으로도 $$p(z) \rightarrow p(x)$$ 처럼 분포를 바꿀 수 있다는 겁니다.
(당연히 여기서 실제 분포인 $$p(z)$$는 복잡한 분포이며, $$p(z)$$는 평균이 0이고 분산이 1인 가우시안 분포처럼 간단한 분포입니다.)


이럴 경우, `ELBO`를 정해서 이를 최적화할 필요 없이 단박에 likelihood를 얻어낼 수 있다고 합니다.
Normalizing flow model의 Objective를 유도해 보도록 하겠습니다.


![cs285_lec18_normalizing_flow2](/assets/images/ae_to_vae/cs285_lec18_normalizing_flow2.png)
*Fig.*

`likelihood`를 바로 계산할 것이기 때문에 모든 데이터 샘플에 대해서 `log likelihood`를 더하면

$$
max_{\theta} \frac{1}{N} \sum_{i=1}^{N} log p(x_i)
$$

가 됩니다. 이제 여기에 아래의 관계식을 적용하면

$$
\begin{aligned}
& p(x) = p(z) \vert det(\frac{df(z)}{dz}) \vert^{-1} & \\
& \text{where } z=f^{-1}(x) &
\end{aligned}
$$

최종적인 Objective는

$$
max_{\theta} \frac{1}{N} \sum_{i=1}^{N} [ log p(f^{-1}(x_i)) - log \vert det(\frac{df(z)}{dz}) \vert^{-1} ]
$$

이 됩니다.
이제 우리가 할 일은 역연산 $$f^{-1}$$과 판별식 계산을 쉽게 할 수 있는 네트워크 $$f$$를 정하기만 하면 됩니다.


예를 들어봅시다. 네트워크 $$f(z)$$가 4층으로 이루어진 네트워크라고 생각해보면,

$$
f(z) = f_4 ( f_3 ( f_2 ( f_1 (z) ) ) )
$$

이제 각 층들을 `invertible`하게 만들어서 전체 네트워크를 `fully-invertible` 네트워크로 만들면 됩니다. 
`Log-determinant`는 레이어들이 invertible할 때 간단하게 `모든 레이어의 determinant`를 계산해서 더하면 되니 일단은 문제가 되지 않는다고 생각하겠습니다.


네트워크를 invertible하게 만드는 방법은 여러 가지가 있지만, 간단한 방법 하나만 소개해보도록 하겠습니다.


![cs285_lec18_normalizing_flow3](/assets/images/ae_to_vae/cs285_lec18_normalizing_flow3.png)
*Fig.*

![cs285_lec18_normalizing_flow4](/assets/images/ae_to_vae/cs285_lec18_normalizing_flow4.png)
*Fig.*

![cs285_lec18_normalizing_flow5](/assets/images/ae_to_vae/cs285_lec18_normalizing_flow5.png)
*Fig.*

![cs285_lec18_normalizing_flow6](/assets/images/ae_to_vae/cs285_lec18_normalizing_flow6.png)
*Fig.*

![cs285_lec18_normalizing_flow7](/assets/images/ae_to_vae/cs285_lec18_normalizing_flow7.png)
*Fig.*



이러한 flow-based model은 convinient 하지만 expressive한 네트워크는 아니게 됩니다.




이처럼 Normalizing flow는 아래와 같은 장단점이 있습니다.

- Pros
  - can get exact probabilities/likelihoods
  - no need for lower bounds
  - conceptually simpler (perhaps)
- Cons
  - requires special architecture
  - $$z$$ must have same dimensionality as $$x$$




### <mark style='background-color: #dcffe4'> Generative Adversarial Networks (GAN) </mark>

TBC














## <mark style='background-color: #fff5b1'> References </mark>

- Blogs
  - 1.['from AutoEncoder to beta VAE' form lillog](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)
  - 2.[A Beginner's Guide to Variational Methods: Mean-Field Approximation from Eric Jang](https://blog.evjang.com/2016/08/variational-bayes.html)
  - 3.[Tutorial #5 variational autoencoders from BorealisAI](https://www.borealisai.com/en/blog/tutorial-5-variational-auto-encoders/)
  - 4.[Variational autoencoders from JEREMY JORDAN](https://www.jeremyjordan.me/variational-autoencoders/)
- Papers
  - 1.[Learning Structured Output Representation using Deep Conditional Generative Models](https://papers.nips.cc/paper/2015/file/8d55a249e6baa5c06772297520da2051-Paper.pdf)
- Lecture Videos
  - 1.[CS W182 / 282A at UC Berkeley - Designing, Visualizing and Understanding Deep Neural Networks](https://cs182sp21.github.io/)
  - 2.[CS 182 - Lecture 17 - Generative Models](https://www.youtube.com/watch?v=AX5v5med3Rw&list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A&index=53)
  - 3.[CS 182 - Lecture 18 - Latent Variable Models](https://www.youtube.com/watch?v=9KTrUea1apo&list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A&index=55)
  - 4.[CS 182 - Lecture 19 - GANs](https://www.youtube.com/watch?v=39CmbTX1S8M&list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A&index=59)
  - 5.[L4 Latent Variable Models (VAE) -- CS294-158-SP20 Deep Unsupervised Learning -- UC Berkeley from Pieter Abbeel](https://www.youtube.com/watch?v=FMuvUZXMzKM)
  - 6.['오토 인코더의 모든 것 (1~3)' from Hwalseok Lee](https://www.youtube.com/watch?v=o_peo6U7IRM) 
- Other 
  - 1.['On manifolds and autoencoders' from Pascal Vincent](http://videolectures.net/deeplearning2015_vincent_autoencoders/?q=vincent%20autoencoder)


