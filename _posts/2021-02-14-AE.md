---
title: From AutoEncoder(AE) to Variational AutoEncoder(VAE)
categories: MachineLearning
tag: [MachineLearning,ML]

toc: true
toc_sticky: true
---

본 포스트는 [lillog의 'from AutoEncoder to beta VAE' 블로그 post](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)와 [이활석(전 Clova leader)님의 '오토 인코더의 모든 것 (1~3)'](https://www.youtube.com/watch?v=o_peo6U7IRM) [+(presentation slide)](https://www.slideshare.net/NaverEngineering/ss-96581209) 등의 자료들을 참고하여 만들었습니다.

- <mark style='background-color: #fff5b1'> Dimensionality Reduction </mark>

오토인코더(AutoEncoder, AE)는 비지도 학습(Unsupervised Learning)을 통해서 어떻게하면 큰 차원의 입력 데이터를 작은 차원의 데이터로 줄일까? 근데 또 막무가내로 줄이는건 아니고 의미있는 정보는 최대한 가지면서(혹은 더 대단한 성분(more efficient and compressed representation)을 추출하면서) 줄일 수 있을까? 라는 생각에서 디자인된 뉴럴 네트워크(Neural Network, NN) 입니다.  

물론 차원 축소(Dimensionality Reduction) 알고리즘에는 오토인코더만 있는게 아니고, non-parametric한 방법인 주성분 분석(Principal Components Analysis)이나 선형 판별 분석(Linear Discriminant Analysis, LDA) 등 다양한 방법이 존재합니다. 

|Dimensionality Reduction|
|---|
|1.	Principal component analysis (PCA)|
|2.	Non-negative matrix factorization (NMF)|
|3.	Kernel PCA|
|4.	Graph-based kernel PCA|
|5.	Linear discriminant analysis (LDA)|
|6.	Generalized discriminant analysis (GDA)|
|7.	Autoencoder|
|8.	t-SNE|
|9.	UMAP|

*출처 : [Wikipidea 문서](https://en.wikipedia.org/wiki/Dimensionality_reduction), 물론 위키에 있는 방법이 전부가 아니며, 다른 방법들도 많이 있습니다.*

![pcavslda](https://user-images.githubusercontent.com/48202736/107734574-122a5c80-6d41-11eb-85fe-aa05b23df9f4.png)
{: style="width: 70%;" class="center"}
*Fig. 차원 축소 알고리즘의 대표적인 예인 PCA, LDA 출처 : [lecture slide from Haesun Park](https://project.inria.fr/siamsummerschool/files/2019/06/Lec2LRA.pdf)*

하지만 이번 글에서는 이 많은 것들을 전부 다룰 수는 없고, 딥러닝의 AE만 다루게 될 것입니다.

- <mark style='background-color: #fff5b1'> AutoEncoder (AE) </mark>

<img width="850" alt="ae1" src="https://user-images.githubusercontent.com/48202736/107733559-a7782180-6d3e-11eb-8cfc-35be14f7d4eb.png">
*Fig. 오토인코더 (AutoEncoder, AE) 모델 아키텍쳐, 이미지 출처 : [lilian's blog](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)*


- <mark style='background-color: #dcffe4'> Principal Components Analysis (PCA) vs AE </mark>

![pca3](https://user-images.githubusercontent.com/48202736/107734572-10f92f80-6d41-11eb-857e-18388f3dbe9c.png)
*Fig. 선형 차원 축소 알고리즘인 PCA (Kernel PCA아님) vs 비선형 차원 축소 알고리즘인 AE, 이미지 출처 : [link](https://www.researchgate.net/figure/Comparison-between-PCA-and-Autoencoder-15_fig1_340049776)*


![pca1](https://user-images.githubusercontent.com/48202736/107734566-0fc80280-6d41-11eb-9fd5-f461f94fc255.png)
![pca2](https://user-images.githubusercontent.com/48202736/107734571-10609900-6d41-11eb-91c7-c533d738b9a5.png)
*Fig. PCA vs AE 의 embedding space representation, 이미지 출처 : [link](https://stats.stackexchange.com/questions/190148/building-an-autoencoder-in-tensorflow-to-surpass-pca)*


- <mark style='background-color: #dcffe4'> Restricted Boltzman Machine (RBM) vs AE </mark>

- <mark style='background-color: #dcffe4'> Denoising AutoEncoder (DAE) </mark>

<img width="1035" alt="dae1" src="https://user-images.githubusercontent.com/48202736/107733564-aa731200-6d3e-11eb-9c43-5af450a2c0fb.png">

- <mark style='background-color: #dcffe4'> Contractive AutoEncoder (CAE) </mark>





- <mark style='background-color: #fff5b1'> Variational AutoEncoder (VAE) </mark>

<img width="961" alt="vae1" src="https://user-images.githubusercontent.com/48202736/107733571-ac3cd580-6d3e-11eb-99b9-92cd42df5d65.png">

- <mark style='background-color: #dcffe4'> AE vs VAE </mark>

<img width="850" alt="ae1" src="https://user-images.githubusercontent.com/48202736/107733559-a7782180-6d3e-11eb-8cfc-35be14f7d4eb.png">

<img width="1183" alt="vae2" src="https://user-images.githubusercontent.com/48202736/107733574-acd56c00-6d3e-11eb-8f4a-2c65d331c84d.png">


- <mark style='background-color: #dcffe4'> Objective Function of VAE : ELBO </mark>

- <mark style='background-color: #dcffe4'> Reparamaterization Trick </mark>

![reparam1](https://user-images.githubusercontent.com/48202736/107733569-aba43f00-6d3e-11eb-8f4d-4994745f83eb.png)






- <mark style='background-color: #dcffe4'> Conditional Variational AutoEncoder (CVAE) </mark>

- <mark style='background-color: #dcffe4'> Vector Quantized - Variational AutoEncoder (VQ-VAE) </mark>

<img width="1617" alt="vq-vae" src="https://user-images.githubusercontent.com/48202736/107733581-ae9f2f80-6d3e-11eb-94cf-f5b9e70f1812.png">







- <mark style='background-color: #dcffe4'> + Generative Adversarial Networks (GAN) </mark>
