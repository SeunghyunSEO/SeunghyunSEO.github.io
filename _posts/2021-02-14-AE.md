---
title: (미완) A Long Way to Deep Generative Models - From AutoEncoder (AE) to Variational AutoEncoders (VAEs)
categories: DeepLearning
tag: [DeepLearning]

toc: true
toc_sticky: true
---

본 포스트는 [CS W182 / 282A at UC Berkeley - Designing, Visualizing and Understanding Deep Neural Networks](https://cs182sp21.github.io/)강의, [lillog의 'from AutoEncoder to beta VAE'](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html) 블로그 포스트 그리고 [이활석님의 '오토 인코더의 모든 것 (1~3)'](https://www.youtube.com/watch?v=o_peo6U7IRM) 강의 [+(presentation slide)](https://www.slideshare.net/NaverEngineering/ss-96581209) 등의 자료들을 참고하여 만들었습니다.




---
< 목차 >
{: class="table-of-content"}
* TOC
{:toc}
---



이번 글에서는 `심층 생성 모델 (Deep Generative Models)`의 대표적인 예인 `Variational AutoEncoder (VAE)`와 이의 다양한 Variation인 VQ-VAE 등에 대해서 알아볼 것이며, 이를 위해 AutoEncoder (AE)란 무엇인지? 변분 추론 (Variational Inference)란 무엇인지? 등에 대해서도 깊게 알아볼 것입니다.  



## <mark style='background-color: #fff5b1'> AutoEncoder (AE) </mark>


`오토인코더(AutoEncoder, AE)`는 "어떻게하면 큰 차원의 입력 데이터를 작은 차원의 데이터로 줄일까? 근데 또 막무가내로 줄이는건 아니고 의미있는 정보는 최대한 가지면서(혹은 더 대단한 성분(more efficient and compressed representation)을 추출하면서) 줄일 수 있을까?" 라는 생각에서 디자인된 뉴럴 네트워크(Neural Network, NN) 입니다.  

![cs285_lec17_ae1](/assets/images/ae_to_vae/cs285_lec17_ae1.png)
*Fig. 오토인코더 (AutoEncoder, AE) 모델 아키텍쳐*

AE는 위와 같이 구성되어 있고, `비지도 학습(Unsupervised Learning)` 방법으로 학습이 됩니다.
사실 우리가 위의 그림에서 정말 원하는 것은 `인코더(Encoder)` 부분인데요,
그러니까 고차원의 입력 데이터를 저차원으로, 정보를 압축(Encoding)하는 부분을 원한다는 겁니다.

그렇기 때문에, 우리는 원래는 디코더가 필요 없었으나, 입력 데이터 x를 네트워크에 통과시켜 다시 x를 만들어내게끔 하는 `비지도 학습 방법으로 인코더 네트워크를 학습`하기 위해서 다시 저차원의 압축된 정보를 원래의 차원으로 복원시켜줄 디코더(Decoder)를 추가적으로 덧붙힌 겁니다.


![cs285_lec17_ae2](/assets/images/ae_to_vae/cs285_lec17_ae2.png)
*Fig. AE가 원하는 것은 입력 데이터보다 상대적으로 저 차원 인 잠재 벡터 (hidden vector)를 출력해주는 Encoder를 학습하는 것이다. (여기서는 인코더를 통해 128차원의 벡터를 얻을 수 있는데, MNIST가 768차원인 것에 비하면 많이 줄었다는 것을 알 수 있다)*

오토인코더는 위와같이 네트워크가 좁아졌다가 다시 넓어지는 형태로 생겼기 때문에, 가운데 차원이 확 좁아지는 곳은 물병의 목 같다고 해서 `Bottle Neck` 이라고 합니다. 






### <mark style='background-color: #dcffe4'> Dimensionality Reduction </mark>

물론 `차원 축소(Dimensionality Reduction)` 목적으로 개발된 알고리즘에는 오토인코더만 있는게 아니고, non-parametric한 방법인 주성분 분석(Principal Components Analysis)이나 선형 판별 분석(Linear Discriminant Analysis, LDA) 등 다양한 방법이 존재하지만 이번 글에서는 AE만 다룰 것입니다. 

![lda](/assets/images/ae_to_vae/pca_vs_lda.png)
*Fig. 차원 축소 알고리즘의 대표적인 예인 PCA, LDA 출처 : [lecture slide from Haesun Park](https://project.inria.fr/siamsummerschool/files/2019/06/Lec2LRA.pdf)*

 





### <mark style='background-color: #dcffe4'> Principal Components Analysis (PCA) vs AE </mark>

사실 차원 축소 방법론에는 PCA와 같은 방법론도 있는데요, AE가 비선형 활성함수들을 사용한 신경망 (Neural Network, NN)이 아니라, 선형적인 특성만 이용한다면 이는 PCA와 크게 다르지 않은 결과를 만들어 냅니다.


(증명은 하지 않겠습니다.)


![pca_vs_ae](/assets/images/ae_to_vae/pca_vs_ae.png){: width="50%"}
*Fig. 선형 차원 축소 알고리즘인 PCA (Kernel PCA아님) vs 비선형 차원 축소 알고리즘인 AE, 이미지 출처 : [link](https://www.researchgate.net/figure/Comparison-between-PCA-and-Autoencoder-15_fig1_340049776)*

위의 그림에서는 원 데이터들이 일반적인 AE를 사용할 경우 `비선형 매니폴드 (Non-linear Manifold)`에 매핑된 것을 볼 수 있고, PCA를 사용할 경우 `선형 매니폴드 (Linear Manifold)`에 매핑된 것을 볼 수 있습니다.


또한 각각의 차원 축소 방법론을 사용해 (인코더를 사용해) MNIST 분류를 하는 경우 아래처럼 얼마나 같은 Class의 숫자끼리 뭉치는지 차이가 많이 나는 것을 확인할 수 있습니다.

![pca_vs_ae_embedding](/assets/images/ae_to_vae/pca_vs_ae_embedding.png)

![pca_vs_ae_embedding2](/assets/images/ae_to_vae/pca_vs_ae_embedding2.png)
*Fig. PCA vs AE 의 embedding space representation, 이미지 출처 : [link](https://stats.stackexchange.com/questions/190148/building-an-autoencoder-in-tensorflow-to-surpass-pca)*










### Notation

이제 수식적을 가지고 글을 전개하기 위해 몇 가지 Notation을 아래와 정의하고 이야기하도록 하겠습니다.  

{: class="info"}
| Symbol | Mean(Kor) | Mean(Eng) |
| ---------- | ---------- ||
| $$\mathcal{D}$$ | 데이터 셋 집합, 크기는 n | The dataset, $$\mathcal{D} = \{ \mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \dots, \mathbf{x}^{(n)} \}$$, contains $$n$$ data samples; $$\vert\mathcal{D}\vert =n $$. |
| $$\mathbf{x}^{(i)}$$ | 각 데이터 포인트는 d차원으로 이루어져 있음. | Each data point is a vector of $$d$$ dimensions, $$\mathbf{x}^{(i)} = [x^{(i)}_1, x^{(i)}_2, \dots, x^{(i)}_d]$$. |
| $$\mathbf{x}$$ | 데이터 셋 집합으로 부터 샘플링한 데이터 1개 | One data sample from the dataset, $$\mathbf{x} \in \mathcal{D}$$. |
| $$\mathbf{x}’$$| 축소했다가 디코더로부터 복원된 데이터 x | The reconstructed version of $$\mathbf{x}$$. |
| $$\tilde{\mathbf{x}}$$ | 노이즈가 섞인 데이터 x | The corrupted version of $$\mathbf{x}$$. |
| $$\mathbf{z}$$ | 인코더가 뱉은 표현 벡터 | The compressed code learned in the bottleneck layer. |
| $$g_{\phi}(.)$$ | - | The **encoding** function parameterized by $$\phi$$. |
| $$f_{\theta}(.)$$ | - | The **decoding** function parameterized by $$\theta$$. |
| $$q_{\phi}(\mathbf{z}\vert\mathbf{x})$$ | 확률적 인코더 (VAE에서 사용하므로 후술할 것임) |Estimated posterior probability function, also known as **probabilistic encoder**.  |
| $$p_{\theta}(\mathbf{x}\vert\mathbf{z})$$ | 확률적 인코더 (VAE에서 사용하므로 후술할 것임) | Likelihood of generating true data sample given the latent code, also known as **probabilistic decoder**. |
| ---------- | ---------- |

수식을 포함해서 다시 얘기하자면,
기본적인 오토인코더 모델은 (추후에 기술할 예정인 VAE는 조금 다릅니다) 파라메터 $$\phi$$로 모델링 된 인코더 함수 $$g(.)$$와 파라메터 $$\theta$$로 모델링 된 디코더 $$f(.)$$로 이루어져있습니다.
병목 층(bottle neck layer)에서 학습이 된 representation은 $$\mathbf{z} = g_\phi(\mathbf{x})$$ 이며, 이를 입력받아 디코더를 통해 얻은 복원된 데이터는 $$\mathbf{x}' = f_\theta(g_\phi(\mathbf{x}))$$ 라고 합니다.

인코더와 디코더의 파라메터인 $$(\theta, \phi)$$는 각각 따로 학습되는것이 아니라 $$x$$를 넣어서 원래 입력값인 $$\mathbf{x} \approx f_\theta(g_\phi(\mathbf{x}))$$를 복원하는 과정에서 함께 학습이 됩니다.



![ae](/assets/images/ae_to_vae/ae.png)
*Fig. 일반적인 AutoEncoder의 모식도*

이렇게 학습을 시키는 것은 `Cross Entropy Loss`를 사용하는 등 다양한 방법이 있지만, 일반적으로 간단하게 `Mean Squared Error Loss`를 사용해서 학습하게 됩니다.

$$
L_\text{AE}(\theta, \phi) = \frac{1}{n}\sum_{i=1}^n (\mathbf{x}^{(i)} - f_\theta(g_\phi(\mathbf{x}^{(i)})))^2
$$







### <mark style='background-color: #dcffe4'> Denoising AutoEncoder (DAE) </mark>

AE는 $$x$$를 given으로 다시 $$x$$를 예측하는 방법론으로, 오버피팅을 하게 되는 문제가 필연적으로 발생하는데,
`디노이징 오토인코더 (Denoisig Autoencoder, DAE)`는 이를 해결하기 위해 제안되었습니다.

의도적으로 입력 데이터에 노이즈 (Noise) 를 섞어서 (corrupt) 이를 다시 없애는 말 그대로 "De-Noise"하게 끔 인코더를 학습시키는 겁니다.
가장 간단하게는 단순히 입력값의 벡터 요소들을 "0" 으로 마스킹한다고 생각할 수 있습니다.
이렇게 함으로써 데이터를 증강 (Augmentation) 시키는 효과를 본다고 할 수도 있겠죠.

![cs285_lec17_dae1](/assets/images/ae_to_vae/cs285_lec17_dae1.png)
*Fig. Denoising AutoEncoder (DAE)는 더럽힌 이미지를 원본으로 복원시키는 방식으로 학습해 AE보다 더욱 강건한 (robust) Encoder를 얻는게 목적이다.*

DAE는 수식적으로 아래처럼 간단히 나타낼 수 있습니다.

$$
\begin{aligned}
\tilde{\mathbf{x}}^{(i)} &\sim \mathcal{M}_\mathcal{D}(\tilde{\mathbf{x}}^{(i)} \vert \mathbf{x}^{(i)})\\
L_\text{DAE}(\theta, \phi) &= \frac{1}{n} \sum_{i=1}^n (\mathbf{x}^{(i)} - f_\theta(g_\phi(\tilde{\mathbf{x}}^{(i)})))^2
\end{aligned}
$$

여기서 원본 이미지를 마스킹 하는 것은 확률적인 분포로부터 샘플링 하여 진행합니다.



이러한 `Denoising Auto-Encoding` 방법론은 간단하지만 현대의 강력한 딥러닝 모델들에서도 계속해서 쓰이는 방법론인데요,
그 대표적인 예로 `BERT`를 들 수 있습니다. 

![jay_bert](/assets/images/ae_to_vae/jay_bert.png)
*Fig. [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805)의 모식도. 버트는 DAE와 마찬가지로 sequence의 토큰 일부를 랜덤하게 마스크 토큰으로 바꾼 뒤, 해당 부분을 예측하는 비지도 학습 방식으로 학습한다.*

(이미지 출처 : [The Illustrated BERT, ELMo, and co. from Jay Alammar](http://jalammar.github.io/illustrated-bert/))




BERT가 DAE와 유사하다는 것은 논문에 기술된 방법론을 봐도 그렇지만 이의 후속 논문이라고 할 수 있는 XLNet 논문에서의 묘사로 더 확실히 알 수 있습니다.

![xlnet_bert](/assets/images/ae_to_vae/xlnet_bert.png)
*Fig. [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/pdf/1906.08237)에서 언급된 버트. 버트는 Denoising Auto-Encoding 방법론의 일종이다.*




이 밖에도 목적에 맞는 다양한 AE의 Variation이 존재하지만 그것들은 생략하고, 우리는 앞으로 AE와 비슷하게 생겼으나, 목적은 전혀 다른 (생성 모델을 만드는게 목적임) `Variational AutoEncoder (VAE)`에 대해서 알아보도록 할 것입니다.










## <mark style='background-color: #fff5b1'> Variational AutoEncoder (VAE) </mark>

`Variational AutoEncoder (VAE)`는 Kingma라는 연구자에 의해서 2014년에 처음 제안되었습니다. [Kingma, Diederik P., and Max Welling. "Auto-encoding variational bayes."](https://arxiv.org/pdf/1312.6114)

사실 보기에는 이름 자체가 (Variational) `AutoEncoder`이기 때문에 오토인코더와 다른점이 거의 없어 보이지만, 그렇지 않습니다.

VAE는 논문에서도 저자들이 이야기하듯, variational bayesian 방법과 graphical model과 관련이 있는 모델이며, 
목적 자체도 오토인코더와 같이 차원축소를 목적으로 '저차원의 유의미한 representation을 추출한다' 가 아니라, `'데이터로부터 단순히 고정된 벡터 (fixed vector)가 아닌 잠재 분포(latent distribution)를 찾아내고, 이로부터 샘플링을 통해 데이터셋에 없는 새로운 데이터를 만들어내는 생성 모델(generative model)을 만들자'` 입니다. (VAE는 생성모델)


물론 $$x$$를 넣어서 원래 입력값인 $$\mathbf{x} \approx f_\theta(g_\phi(\mathbf{x}))$$를 복원해내는 비지도 학습 방식으로 학습되는 것은 AE와 똑같습니다, 하지만 학습을 위한 목적 함수도 다르고, 학습이 된 후 네트워크의 어떤 부분을 쓰느냐도 다릅니다.

![lee_ae1](/assets/images/ae_to_vae/lee_ae1.png){: width="80%"}
*Fig. AutoEncoder는 유의미한 공간으로의 차원 축소를 해줄 Encoder를 학습하는게 목적이며, 이를 비지도 학습 방법론으로 학습하기 위해 Decoder를 붙힌 것이다.*

일반적인 오토인코더는 인코더를 앞서 말한 방식과 같이 학습하기 위해서 디코더를 붙힐 수 밖에 없었던 것이고, VAE는 디코더를 학습하기 위해서 인코더를 붙힌것으로 목적 자체가 다릅니다.

![lee_vae1](/assets/images/ae_to_vae/lee_vae1.png){: width="60%"}
*Fig. Variational AutoEncoder는 우리가 어떠한 유의미한 데이터 분포를 알고 있을 때, 이를 입력으로 유의미한 데이터를 만들어내기 위한 (i.e. 이미지) Decoder를 학습하는것이 목적이며, 이를 AE와 마찬가지로 비지도 학습 방법론으로 달성하기 위해서 Encoder를 붙힌 것이다.*

![lee_vae2](/assets/images/ae_to_vae/lee_vae2.png){: width="100%"}
*Fig. Encoder를 붙힌 VAE의 모습은 AE와 유사하다. Sample을 한다는 것의 의미는 후술하기로 한다.*

(+ `Variational` AutoEncoder의 'Variational'이란 앞서 말한 posterior라고 할 수 있는 latent distribution $$z$$를 direct로 학습할 수 없기 때문에 사용하는 근사방법인, 변분 추론(Variational Inference)에서 따온 이름입니다.)  


이제 VAE에 대해서 차분히 알아보도록 할건데, 그 전에 우리는 `잠재 변수 모델 (Latent Variable Model)`이 무엇이며 어떤 의미를 가지는지에 대해 알 필요가 있기 때문에 이에 대해 먼저 알아보도록 하겠습니다.














### <mark style='background-color: #dcffe4'> What is Latent Variable Model ? </mark>

잠재 변수 모델은 과연 뭘까요?


머신러닝은 일반적으로 $$p(x)$$이나 $$p(y \vert x)$$에 대한 분포를 모델링하고 (연속적이거나 이산적인 분포 i.e. 가우시안, 카테고리컬 분포) 이 분포를 통해 구한 데이터 셋 전체에 대한 likelihood를 최대화 하는 분포에 대한 파라메터를 찾는것이 목적입니다.

![jd_likelihood](/assets/images/ae_to_vae/jd_likelihood.png)
*Fig. likelihood를 최대화 한다는 것은 주어진 데이터를 가장 잘 표현하는 분포를 찾는다는 것과 같다.*

여기서 $$p(x)$$는 일반적으로 `확률적 생성 모델 (Probabilistic Generative Model)`, $$p(y \vert x)$$는 `확률적 판별 모델 (Probabilistic Discriminative Model)`이라고 합니다.

![cs285_lec17_generative](/assets/images/ae_to_vae/cs285_lec17_generative.png){: width="40%"}
*Fig. 확률적 생성 모델, $$ p(x) $$*

![cs285_lec17_discriminative](/assets/images/ae_to_vae/cs285_lec17_discriminative.png){: width="80%"}
*Fig. 확률적 판별 모델, $$ p(y \vert x) $$*

하지만 확률적이라고 해도 이러한 모델들에서 랜덤 변수 (random varialbes)라고 할 만한 것들은 데이터의 입출력 $$x,y$$ 밖에 없는데요, 
이러한 확률적 분포 모델 $$p(x)$$, $$p(y \vert x)$$에 랜덤 변수 $$z$$를 추가해서 모델링 하는 것이 바로 잠재 변수 모델이며, 이 때 $$z$$를 잠재 변수라고 합니다.

직관적으로 이해하기 위해 예를 들어 보도록 하겠습니다.
우리가 다음과 같이 복잡한 분포로 부터 샘플링 된 데이터를 가지고 있다고 해보도록 하겠습니다. (당연히 실제 분포는 몰라야 정상이지만 안다고 하겠습니다.)

![cs285_lec17_px](/assets/images/ae_to_vae/cs285_lec17_px.png){: width="60%"}
*Fig. 복잡한 분포를 가지는 $$p(x)$$*

우리가 원하는건 당연히 데이터를 잘 표현하는 분포 $$p(x)$$를 찾는거죠. 
하지만 우리가 일반적으로 가정하는 봉우리가 하나뿐인 `단봉 가우시안 분포 (Unimodal Univariate Gaussian Distribution)`으로는 표현하는 데 한계가 있습니다.
그래서 우리는 `다봉 가우시안 분포 (Multimodal Univariate Gaussian Distribution)` 같이 좀 더 복잡한 분포로 이를 표현하고 싶은데,
이를 위해서는 아래처럼 단순히 단봉 분포를 여러 개 weighted sum할 수도 있습니다.

![jd_gmm6](/assets/images/ae_to_vae/jd_gmm6.png){: width="50%"}
*Fig. 우리가 원하는 것은 복잡한 $$p(x)$$이다. 이를 위해 단봉 가우시안 분포 여러갤르 합치면 어떨까?*

하지만 이보다 더 복잡하고 표현력이 좋은 방법이 있는데요, 이것이 바로 잠재 변수를 활용한 `잠재 변수 모델 (latent variable model)`입니다.

잠재 변수 모델은 앞서 말한 것 처럼 원 데이터에는 존재하지 않았던 변수를 데이터 속으로 부터 분리하는 `주변화 (Marginalization)` 테크닉을 통해 정의하는데요,
즉 이를 통해서 전에 없던 결합 분포를 만들어 낸다는 겁니다.

![jd_gmm1](/assets/images/ae_to_vae/jd_gmm1.png){: width="50%"}
*Fig. 잠재 변수 (여기서는 $$h$$라는 노테이션으로 쓰임)와 원본 데이터 $$x$$와의 결합 분포, $$h$$의 분포는 그림에서는 연속적인 분포다 (i.e.가우시안)*

$$
p(x) = \int p(x,h) dh 
$$

만약에 잠재 변수가 이산적인 분포를 갖는 경우를 가정하면 이는 아래와 같은 그림으로 표현할 수 있게 되는데요,

![jd_gmm7](/assets/images/ae_to_vae/jd_gmm7.png){: width="60%"}
*Fig. 만약 잠재 변수 $$h$$의 분포가 이산적인, 예를 들어 3개의 클래스를 가지는 카테고리컬 분포라면, 위의 그림처럼 된다.*

그림에서 볼 수 있듯, 같은 데이터 포인트 $$x$$라도 $$h=1,2,3$$일 때 각각 리턴하는 확률 값이 다르다는 것을 알 수 있습니다. 
즉 x좌표상 왼쪽 부근에 있는 데이터들은 $$h=1$$에 속할 확률이 높겠네요.


이런식으로 우리는 실제로는 주어진 정보가 $$x$$밖에 없지만 존재하지 않던 $$h$$라는 내재되어있는 변수를 도입하고, 
이를 학습을 통해서 fitting하면서, 실제로는 각 데이터 포인트에 대해서 어느 클래스에 속한다는 정답은 없었지만, 
$$h=1,2,\cdots$$ 같은 `가짜 정답 (Fake Label)`에 대한 분포를 만들고 알아서 학습하게 되는거죠.

![jd_gmm3](/assets/images/ae_to_vae/jd_gmm3.png){: width="60%"}
![jd_gmm4](/assets/images/ae_to_vae/jd_gmm4.png){: width="60%"}
*Fig. 학습을 통해 알아서 데이터의 분포를 더욱 잘 설명하는 복잡한 분포를 찾아내는 것을 알 수 있다.*

```
이 때 중요한 점은 이렇게 만들어진 정보 (i.e x라는 데이터는 h=1일 확률이 가장 높다.)가 맞다고 가정하고 진행한다는 겁니다.
```

이를 2차원이나 고차원으로 확장시켜도 당연히 문제가 없으며,

![cs285_lec17_latent1](/assets/images/ae_to_vae/cs285_lec17_latent1.png){: width="40%"}
*Fig. 당연히 여기서 색을 입힌건 편의를 위해서지 정답이 주어진게 아니며, 검은색 원 또한 잠재 변수 모델로 얻어낸 다변량 다봉 정규 분포 (Multi-modal Multivariate Gaussian Distribution)를 나타내는 것이지, 실제로 우리가 알고 있는 것은 데이터 $$x$$ 정보 밖에 없습니다.*

이러한 잠재 변수 모델은 전통적인 머신러닝 기법인 `EM Algorithm`을 통해서 학습하곤 합니다.


![jd_gmm5](/assets/images/ae_to_vae/jd_gmm5.png){: width="70%"}
*Fig. $$h$$라는 잠재 변수가 어떻게 돼야 한다고 강제한건 아니지만, 학습되는 과정에서 알아서 데이터 분포를 잘 설명하기 위해서 군집끼리 묶는다.*


잠재 변수 모델을 수식적으로 생각해보자면, 우리는 잠재 변수를 표현하기 위해서 원래 우리가 추정하고자 하는 분포 $$p(x)$$를 Marginalization (혹은 integrated out)해서 아래처럼 표현하고, 

$$
p(x) \rightarrow p(x) = \sum_z p(x,z)
$$

간단한 확률 테크닉을 통해 아래처럼 나타낼 수 있습니다.

$$
p(x) = \sum_z p(x \vert z) p(z)
$$

이는 마찬가지로 아래와 같은 판별 모델에도 적용할 수 있습니다.

$$
p(y \vert x) \rightarrow p(y \vert x) = \sum_z p(y \vert x,z) p(z)
$$

이제 이를 더 확장해서 생각해보도록 하겠습니다 (generalization).


우리가 가지는 데이터에 대한 분포 $$p(x)$$가 연속적이며, 굉장히 복잡한 분포라고 가정해보도록 하겠습니다.
단순히 3개의 가우시안 분포를 합쳐서 표현할 정도가 아니라 굉장히 복잡한 (complicated monstrous) 분포입니다.

![cs285_lec17_px](/assets/images/ae_to_vae/cs285_lec17_px.png){: width="60%"}
*Fig.*

여기에 위에서 한 것 처럼 잠재 변수를 도입할건데요, 이 때 $$p(z)$$는 매우 다루기 쉬운 연속적인 분포인 가우시안 분포라고 해보도록 하겠습니다. 

![cs285_lec17_pz](/assets/images/ae_to_vae/cs285_lec17_pz.png){: width="60%"}
*Fig.*

우리가 필요한 것은 어떤 데이터 포인트 $$x$$가 주어졌을 때 이 데이터에 대한 알려지지 않은 "Fake Label" $$z$$에 대한 정보 $$p(x \vert z)$$ 입니다.
$$p(x \vert z)$$ 또한 굉장히 다루기 쉬운 가우시안 분포라고 가정 해 보도록 하겠습니다.

![cs285_lec17_pxz1](/assets/images/ae_to_vae/cs285_lec17_pxz1.png){: width="70%"}
*Fig.*

우리는 이미 잠재 변수를 도입할 때 아래의 식이 성립한다는 것을 알고 있죠.

$$
p(x) = \int p(x \vert z) p(z) dz
$$

(여기서 우변이 아까와 다르게 $$\sum$$이 아닌 $$\int$$인 이유는 $$p(z)$$가 이번에는 연속적인 분포이기 때문입니다.)


$$\int p(x \vert z) p(z) dz$$의 의미는 z 분포의 가능한 모든 value에 대해 생각을 한다는 겁니다.


우리가 이로부터 알 수 있는 중요한 사실은 바로, 원래는 표현하기 복잡하며 어떻게 표현해야 할 지도 감이 안 왔던 $$p(x)$$를 배우는 것을, 매우 간단한 분포인 가우시안 분포 두개를 배우는 것으로 바꿔서 생각할 수 있게 됐다는 겁니다.

여기서 $$p(z)$$는 고정된 분포이며 (i.e. zero mean, unit variance $$N(0,I)$$), 가우시안 분포 $$p(x \vert z)$$의 평균 (mean, $$\mu$$), 분산 (variance, $$\sigma$$)는 뉴럴 네트워크의 출력이며, 이 뉴럴 네트워크를 학습하는것도 사실 그리 쉬운 일은 아니지만 적어도 $$p(x \vert z)$$는 deterministic하며, 이러한 방법으로 학습하는게 $$p(x)$$를 학습하는 것보다는 낫습니다.


자 이제 우리가 어떻게 잠재 변수 모델을 학습하는지에 대해서만 생각해보고, VAE로 넘어가도록 하겠습니다.
이를 설명하기 위해 우선 다음을 정의하도록 하겠습니다.

- The model : $$p_{\theta} (x)$$
- The data : $$D = \{ x_1,x_2, \cdots, x_N \}$$
- Maximum likelihood fit : $$ \theta \leftarrow argmax_{\theta} \frac{1}{N} \sum_i log p_{\theta} (x_i) $$

우리가 잠재 변수 모델을 정의하기 위해 $$p(x)$$를 Marginalization 했으니 아래와 같이 표현할 수 있겠습니다.

$$ 
\theta \leftarrow argmax_{\theta} \frac{1}{N} \sum_i log p_{\theta} (x_i)  \\ 
\theta \leftarrow argmax_{\theta} \frac{1}{N} \sum_i log ( \int p_{\theta}(x_i \vert z) p(z) dz ) \\
$$

적분식이 가지는 의미는 우리가 연속적인 분포 $$p(z)$$의 가능한 모든 변수들을 고려하겠 다는 것인데, 이는 불가능 하기 때문에 적분식을 계산하는 것은 intractable합니다. (즉 no closed-form solution). 


(여기서 우리는 $$p(z)$$를 prior라고 부르며 (학습이 되는게 아님, 정해진 분포 그대로), $$p(x \vert z)$$는 mapping function으로 우리가 학습을 통해 배우게 될 것입니다 (즉 mean, variance가 학습을 통해 변함).)


하지만 적분식을 계산할 수 없다고 학습을 할 수 없는건 아닙니다. 
바로 아래의 `Expected log-likelihood` 식을 정의하고 이를 최대화 하는 방향으로 학습을 하면 $$p(x \vert z)$$를 fit할 수 있게 되는데요,

$$
\theta \leftarrow argmax_{\theta} \frac{1}{N} \sum_i \mathbb{E}_{z \sim p(z \vert x_i)} [log p_{\theta} (x_i, z)] 
$$

이는 전체 적분을 계산하지 않고, 우리가 가지는 학습 데이터 $$x_1, \cdots, x_N$$에 대해서 각각에 대해 가장 그럴듯한 정답 $$z_1, \cdots, z_N$$이 존재하며, 이게 맞다고 가정하고 두 $$(x_i,z_i)$$의 결합 분포 (joint distribution)을 최대화 하겠다는 겁니다. 
적분은 없어졌지만 여전히 기대값이 취해져 있기 때문에 i번째 데이터에 대해서 $$z~p(z \vert x_i)$$의 모든 확률들에 대해서 평균을 내기는 합니다.
하지만 practical하게는 우리는 1번 혹은 몇 번의 샘플링을 통해서 얻은 z 몇개에 대해서만 계산할 것이기 때문에 부담이 확 줄어들었습니다. 

***

![jd_prob1](/assets/images/ae_to_vae/jd_prob1.png){: width="40%"}
![jd_prob2](/assets/images/ae_to_vae/jd_prob2.png){: width="70%"}
*Fig. Recap. 결합 분포와 조건부 분포의 관계, 우리는 한 데이터 $$x_i$$당 전체 $$z$$ (그림에서는 $$y$$)에 대한 probability를 계산하는 것이 아닌 몇 개의 $$z$$ 샘플에 대해서만 probability를 계산하면 된다.*


***

```
다시한번,

Intuition : "guess" most likely z given x_i, and pretend it's the right one
...but there are many possible values of z, so use distribution p(z|x_i) and sample a few z from it

```


이제 "과연 $$p(x_i \vert z)$$ 분포는 무엇인지, 그리고 이는 어떻게 계산할 것인지?" 가 관건입니다.
이를 해결하기는 과정은 `확률적 추론 (Probabilistic Inference)`이라고 불리는데, 추론이라고 불리는 이유는 각각의 입력, $$x_i$$ (i.e. 이미지)에 대해서 어떤 $$z$$가 동반되어야 하는지를 `추론 (infer)`하기 때문입니다. 


즉, 우리가 정말로 원하는 것은 $$p(z)$$로 부터 샘플링한 벡터를 이용해서 새로운 $$x_i' \approx x_i$$를 만드는, $$p(x_i \vert z)$$라는 mapping function을 학습하는 것이지만,

![lee_vae1](/assets/images/ae_to_vae/lee_vae1.png){: width="60%"}

![cs285_lec17_pxz1](/assets/images/ae_to_vae/cs285_lec17_pxz1.png){: width="70%"}
*Fig. $$p(x \vert z)$$*


이를 위해서 역으로 $$p(z \vert x_i)$$ 라는 주어진 입력으로 부터 주어지는 $$z$$는 과연 어떤 분포일까?를 나타내는 $$p(z \vert x_i)$$도 추론해야 한다는 거죠.   

![cs285_lec17_pxz2](/assets/images/ae_to_vae/cs285_lec17_pxz2.png){: width="60%"}
*Fig. $$p(z \vert x)$$*

만약에 이 분포가 학습이 잘된다면, 우리는 예를 들어, 강아지 사진이 어떤 분포 $$p(z \vert x)$$로 부터 기인했는지를 알 수 있게 되고 (물론 이 분포는 복잡합니다), 이 분포에서 다른 데이터 포인트를 샘플링해서 $$z \sim p(z \vert x)$$ 디코더에 넣어주면 $$p(x \vert z)$$ 우리가 학습한 강아지 사진과 비슷하지만, 다른 모양의 강아지 (털 색이 다르다던가)를 만들어 낼 수 있게 됩니다.
그래서 이 모델이 `심층 생성 모델 (Deep Generative Model)`이라고 불릴 수 있는 것이죠.



하지만 이 추론을 하는 과정 자체가 엄청나게 어려운데요, 그렇기 때문에 우리는 `근사 추론 (approximate inference)` 방법을 사용해서 학습을 하게 되고, 
이 때 자주 쓰이는 방법이 바로 지금 우리가 논하려고 하는 VAE에서도 쓰는 방법인 `변분 근사 (variational approximation)` 혹은 `변분 추론 (variational Inference)`이 됩니다.













### <mark style='background-color: #dcffe4'> Variational Inference (Variational Approximation) </mark>

변분 추론의 핵심 아이디어는 계산하기 복잡한 $$p(z \vert x)$$ 대신에, 이와 유사하지만 간단한 분포 (i.e. 가우시안 분포)를 사용하자는 겁니다.

$$
p(z \vert x_i) \rightarrow q_i(z) = N(\mu_i, \sigma_i)
$$

수식에서도 알 수 있듯이, 이는 각각의 학습 데이터셋의 데이터 포인트인 $$x_i$$마다 서로 다른 $$\mu_i,\sigma_i$$를 가지고 있을 겁니다.

![elbo](/assets/images/ae_to_vae/elbo.png){: width="70%"}
*Fig. Variational Approximation*





(말씀을 드리지 않았는데, 여기서 $$p(z \vert x)$$를 `진짜 사후 분포 (real posterior distribution)` 라고 표현합니다. 이는 단순한 가우시안 분포가 아니라 굉장히 복잡하게 생겨 모델링 하기도 힘들며, 실제로 우리가 알지 못하는 분포입니다.)


- $$p(x_i)$$ : real data distribution
- $$p(z \vert x_i)$$ : real posterior
- $$p(z)$$ : prior
- $$q_i(z)$$ : approximate posterior


여기서 어떤 $$q_i(z)$$를 설정하던지, 우리는 $$logp(x_i)$$에 대한 `하계 (Lower Bound)`를 설정할 수가 있는데요,
이는 아래의 수식을 통해서 정의할 수 있습니다.

$$
\begin{aligned}

& log p(x_i) = log \int_z p(x_i \vert z) p(z) & \\
& = log \int_z p(x_i \vert z) p(z) \frac{q_i(z)}{q_i(z)} & \\
& = log \mathbb{E}_{z \sim q_i(z)} [p(x_i \vert z) p(z) \frac{1}{q_i(z)}] & \\
& = log \mathbb{E}_{z \sim q_i(z)} [ \frac{p(x_i \vert z) p(z) }{q_i(z)} ] & 

\end{aligned}
$$

위에서 사용된 테크닉은 $$\frac{q_i(z)}{q_i(z)} = 1 $$을 추가하고, 기대값의 정의를 사용한 것 밖에 없습니다.
여기서 추가적으로 `변분 추론의 핵심`이 되는 아래와 같은 특성을 이용하면, ([Jensen's Inequality](https://en.wikipedia.org/wiki/Janson_inequality))

$$
log \mathbb{E} [y] \geq \mathbb [log y]
$$

우리는 비로소 아래와 같은 수식을 얻을 수 있게 됩니다.

$$
\begin{aligned}

& log p(x_i) = log \mathbb{E}_{z \sim q_i(z)} [ \frac{p(x_i \vert z) p(z) }{q_i(z)} ] & \\
& \geq \mathbb{E}_{z \sim q_i(z)} [ log \frac{p(x_i \vert z) p(z) }{q_i(z)} ] = \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] - \mathbb{E}_{z \sim q_i(z)} [log q_i(z)] &

\end{aligned}
$$


생성 모델 이란 결국 모든 데이터 포인트들에 대한 log-likelihood, $$log p(x_i)$$의 합인 $$log p(x) = \sum_i log p(x_i) $$를 최대화 하는 문제인데, $$\mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] - \mathbb{E}_{z \sim q_i(z)} [log q_i(z)]$$ 라는 term이 lower bound이기 때문에 이를 최대화 하는 것이 곧 $$log p(x)$$ 를 최대화 하는 문제를 푸는 것과 다름 없게 됩니다.


여기서 우리가 최대화 하고자 하는 lower bound수식의 두번째 term은 사실 `음의 엔트로피 (negative Entropy)`와 동일한 수식인데요,

$$
\begin{aligned}
& log p(x_i) \geq \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] - \mathbb{E}_{z \sim q_i(z)} [log q_i(z)] & \\
& log p(x_i) \geq \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] + H(q_i) &
\end{aligned}
$$

그렇기 때문에 우리는 수식이 갖는 의미를 조금 더 해석적으로 이야기할 수 있습니다.









#### Entropy

먼저 `엔트로피 (Entropy)`가 의미하는 것은 뭘까요?

$$
H(p) = - \mathbb{E}_{x~p(x)} [log p(x)] = -\int_x p(x) log p(x) dx
$$

엔트로피가 의미하는 바는 직관적으로 다음과 같습니다.

- 얼마나 확률 분포가 랜덤한가? (how random is the random variable?)
- 주어진 확률 분포 하에서 log 확률값에 대한 기대값이 얼마나 큰가? (how large is the log probability in expectation under itself?)

![entropy](/assets/images/ae_to_vae/entropy.png)
*Fig. 마찬가지로 더욱 랜덤한 오른쪽 분포가 더 엔트로피가 높다.*

![entropy_ber](/assets/images/ae_to_vae/entropy_ber.png){: width="40%"}
*Fig. 베르누이 분포 하에서의 Entropy, 나올 수 있는 경우 2가지가 모두 0.5일 때, 가장 헷갈리는 상황으로 엔트로피가 가장 높다.*

즉 엔트로피는 얼마나 확률 분포가 랜덤한가? 인데, 우리가 최대화 하려고 하는 수식이 바로 $$q_i(z)$$ 의 엔트로피를 포함하고 있기 때문에, 
아래의 수식을 최대화 하는 것은

$$
\mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] + H(q_i)
$$

$$q_i(z)$$ 분포를 평평하게 (랜덤하게) 만들면서, 이로부터 샘플링한 z라는 랜덤 변수 (random variable)을 가지고 만들어낸 이미지가 $$log p(x_i \vert z)$$ 원본 이미지 $$x_i$$가 되게끔 하는 것을 의미하게 된다는 겁니다.

![cs285_lec18_entropy](/assets/images/ae_to_vae/cs285_lec18_entropy.png)
*Fig. 우리가 최대화 하려는 수식의 첫 번째 term과 두 번째 term이 가지는 의미*







#### KL-Divergence (KLD)

이 수식을 해석하는 또 다른 방법은 바로 `쿨백 라이블러 발산 (KL-Divergence, KLD)`을 이용하는 건데요,
KLD는 서로 다른 두 분포에 대해서 다음의 수식을 만족합니다.

$$
\begin{aligned}

& D_{KL} (q \parallel p) = \mathbb{E}_{x \sim q(x)} [log \frac{q(x)}{p(x)}] & \\
& = \mathbb{E}_{x \sim q(x)} [log q(x)] - \mathbb{E}_{x \sim q(x)} [log p(x)] & \\
& = - \mathbb{E}_{x \sim q(x)} [log p(x)] - H(q) &

\end{aligned}
$$

KL-Divergence에 대해서도 할말이 굉장히 많지만, 정말 간단하게 얘기해서 KL-Divergence는 `'두 분포가 얼마나 다른가'` 혹은 `'두 분포간의 거리'`를 의미하며, 수식의 결과값이 작을수록 두 분포가 유사하다는 뜻을 나타내며, 두 분포가 완전히 같다면 이 값은 $$0$$이 됩니다. ($$0$$이 되는지는 수식의 기대값에 같은 분포를 넣어서 계산하면 쉽게 확인할 수 있습니다.)

![kld](/assets/images/ae_to_vae/kld.png){: width="80%"}
*Fig. [Wikipedia](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)에 묘사되어 있는 KLD.*


물론 널리 알려져 있는 것처럼, 이 `거리`는 우리가 흔히 말하는 좌표상의 유클리디안 거리 (Euclidean Distance)가 아니며, $$D_{KL}(p \parallel q)$$와 $$D_{KL}(q \parallel p)$$의 결과값은 서로 같지 않습니다.
그리고 KLD의 특성중 하나는 리턴하는 값이 언제나 양수라는 겁니다. 



어쨌든, 우리가 KLD를 갑자기 가져온 이유가 있습니다.
그건 바로 `우리가 Jensen's Inequality로 유도한 수식이 사실은 KLD를 나타낸다.`라는 사실 때문입니다.

$$
\begin{aligned}

& D_{KL} (q \parallel p) = - \mathbb{E}_{x \sim q(x)} [log p(x)] - H(q) & \\
& log p(x_i) \geq \mathbb{z \sim q_i (z)} [ log p(x_i \vert z) + log p(z)] + H(q_i) &

\end{aligned}
$$

한편, 어떤 $$q_i(z)$$가 좋은 근사 분포일까요? 
이는 유도했던 수식의 bound가 `'얼마나 tight한가'`? 다시 풀어서 말하면, `'얼마나 우변과 좌변이 유사한가?'`를 재보면 알 수 있습니다.
$$q_i(z)$$는 $$p(z \vert x_i)$$ 와 유사하지만 다루기가 쉬운 분포여야 하며, 이를 잘 반영했을 때가 좌변과 우변이 차이가 가장 적어지고, 그런 $$q$$가 좋은 $$q$$가 된다는 겁니다. 
그렇다면 이를 잴 수 있는 도구는 뭘까요? $$q_i(z)$$는 $$p(z \vert x_i)$$ 사이의 KLD가 될겁니다.
두 분포 사이의 KLD를 재보도록 하겠습니다.

$$
\begin{aligned}

& D_{KL} (q_i(z) \parallel p(z \vert x_i)) = \mathbb{E}_{z \sim q_i(z)} [log \frac{q_i(z)}{p(z \vert x_i)}] & \\
& = \mathbb{E}_{z \sim q_i(z)} [log \frac{ q_i(z) p(x_i) }{ p(x_i,z) }] & 

\end{aligned}
$$

우리는 위와 같은 수식을 얻을 수 있고, 이 수식을 아래와 같이 잘 전개하면 우리는 놀라운 결과를 얻을 수 있는데요,

$$
\begin{aligned}
& D_{KL} (q_i(z) \parallel p(z \vert x_i)) = \mathbb{E}_{z \sim q_i(z)} [log \frac{q_i(z)}{p(z \vert x_i)}] = \mathbb{E}_{z \sim q_i(z)} [log \frac{ q_i(z) p(x_i) }{ p(x_i,z) }] & \\
& = -\mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] + \mathbb{E}_{z \sim q_i(z)} [log q_i(z)] + \mathbb{E}_{z \sim q_i(z)} [log p(x_i)] & \\
& = - \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] - H(q_i) + log p(x_i) & \\
& = - L_i (p,q_i) + log p(x_i) &
\end{aligned}
$$

$$log p(x_i)$$가 아까 정의한 `Lower Bound`인 $$L_i(p,q_i)$$와 $$D_{KL} (q_i(z) \parallel p(z \vert x_i))$$의 합이라는 겁니다.

***

+ log p(x)를 일반적으로 증거 값 (Evidence)이라고 부르는데요, 이 값은 정확하게 $$L_i$$와 KLD값의 합이며 이 KLD는 언제나 양수값이기 때문에 $$L_i$$는 언제나 Evidence보다 조금 아래에 놓이게 되는 하계 (Lower Bound)가 됩니다. 그렇기 때문에 일반적으로 $$L_i(p,q_i)$$를 `Evidence Lower Bound (ELBO)` 라고 합니다.

***


$$
log p(x_i) = D_{KL} (q_i(z) \parallel p(z \vert x_i)) + L_i (p,q_i) 
$$

이 수식이 시사하는 바는 큰데요, 이는 $$L_i(p,q_i)$$를 유도하는 또 다른 방법이기도 하며, $$log p(x_i)$$와 `ELBO` $$L_i$$간의 괴리 (error)가 얼마나 크고 작은지를 알 수 있기 때문입니다.


만약 두 진짜 분포와 근사 분포간의 KLD가 작다고 생각하면, $$L_i$$가 $$log p(x_i)$$를 굉장히 잘 근사 (bound가 굉장히 tight해짐) 한다는 걸 알수 있겠죠? (극단적으로 0이면, 둘은 동일함)
이러한 특성은 매우 매우 중요한 특성인데요, 만일 우리가 KLD를 최소화 하면서, 동시에 $$L_i$$를 최대화 하면 우리는 정말 효과적으로 $$p(x_i)$$를 극대화 할 수 있을겁니다.

$$
\begin{aligned}

& log p(x_i) = D_{KL} (q_i(z) \parallel p(z \vert x_i)) + L_i (p,q_i) & \\
& log p(x_i) \geq L_i(p,q_i) &

\end{aligned}
$$


그리고 우리는 KLD가 언제나 양수이며, KLD와 $$L_i$$의 합이 $$logp(x)$$라는 사실로 부터,
즉 우리는 $$L_i$$를 $$q_i$$에 대해서 최대화 하는 것이 즉 KLD를 최소화 한다는걸 알 수 있습니다. 

$$
\begin{aligned}

& D_{KL} (q_i(z) \parallel p(z \vert x_i)) = - \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] - H(q_i) + log p(x_i) & \\
& = - L_i (p, q_i) + log p(x_i) &

\end{aligned}
$$

(여기서 $$logp(x_i)$$ 는 $$q_i$$와 관련이 없기 때문에 (독립임) 고정되어있을 겁니다.)

![elbo_kld](/assets/images/ae_to_vae/elbo_kld.png){: width="60%"}
*Fig. $$L_i$$를 최대화 하는 것은, 실제 분포와 근사 분포의 KLD를 최소화 하는 것이다. (Notation이 다른 이유는 후에 다시 서술하도록 하겠습니다.)*



결론적으로 우리는 `ELBO`를 $$p$$와 $$q$$ 모두에 대해서 최대화 하는 것이 결국 `생성 모델이 원하는 진짜 목적 함수 (Objective Function)`, $$log p(x)$$를 최대화 하게 되는 겁니다.

- ELBO를 $$q$$에 대해서 최대화 : $$p,q$$ 사이의 KLD가 줄어든다 - `bound가 tight해진다`
- ELBO를 $$p$$에 대해서 최대화 : $$log p(x_i) \geq L_i$$의 $$L_i$$이 커지면서 $$log p(x_i)$$, 즉 `Evidence도 덩달아 커진다`.

이렇게 우리는 `잠재 변수 모델 (Latent Variable Model)`을 학습할 수 있는 tractable한 방법을 얻게 되었습니다!





즉, 이제 우리는 아래의 수식이 아니라 

$$
\theta \leftarrow arg max_{\theta} \frac{1}{N} \sum_i log p_{\theta} (x_i) 
$$

`ELBO`를 최대화 함으로써 생성 모델을  학습할 수 있게 된겁니다.

$$
\begin{aligned}

& \theta \leftarrow arg max_{\theta} \frac{1}{N} \sum_i L_i(p,q_i) & \\
& \theta \leftarrow arg max_{\theta} \frac{1}{N} \sum_i \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] + H(q_i) &

\end{aligned}
$$

조금 더 디테일하게는 아래의 `학습 절차 (training procedure)` 따르면 되겠습니다.

***

$$
\begin{aligned}

& \text{for each } x_i (\text{or mini-batch}): &  \scriptstyle{\text{; for every data x_i in our dataset}} \\
& \quad \text{calculate } \bigtriangledown_{\theta} L_i(p,q_i): & \scriptstyle{\text{; calculate gradient of ELBO with respect to model param}} \\
& \quad \quad \text{sample } z \sim q_i(z) & \scriptstyle{\text{; 1. sample z because we have Expectation}}  \\
& \quad \quad \bigtriangledown_{\theta} L_i(p,q_i) \approx \bigtriangledown_{\theta} log p_{\theta} (x_i \vert z) &  \scriptstyle{\text{; 2. calculate gradient for one sample (can use multiple sample). p(z) has no parameter}}  \\
& \quad \theta \leftarrow \theta + \alpha \bigtriangledown_{\theta} L_i(p,q_i) &  \scriptstyle{\text{; 3. update param on } \theta} \\
& \quad \text{update } q_i \text{ to maximize }  L_i(p,q_i) &  \scriptstyle{\text{; 4. also maximize } q_i \text{how? -> will talk bout this later}}

\end{aligned}
$$

***

우리가 힘겹게 목적 함수도 정의 했으며, 어떻게 파라메터를 업데이트 하는지 까지 알아보긴 했지만, 여기서 문제가 하나 있습니다.
예를 들어, 우리가 $$q_i$$를 간단한 분포, 즉 아래와 같은 세팅의 가우시안 분포라고 가정해보도록 하겠습니다.

- $$ q_i(z) = N(\mu_i, \sigma_i) $$

여기서 주의해야 할 점은 $$p(z)$$와 $$q_i(z)$$는 다르다는 겁니다.
$$p(z)$$는 파라메터가 없는 $$N(0,I)$$ 이고, $$q_i$$는 데이터 포인트 $$x_i$$에 대한 파라메터화 된, 즉 학습을 통해 우리가 추정해야 하는 분포인거죠.
우리는 각 데이터 포인트 $$x_i$$마다 평균, $$\mu_i$$ 와 분산, $$\sigma_i$$이 필요합니다.


즉 이는 데이터 포인트가 하나의 이미지라면, `모든 이미지 마다 가짜 정답 (fake label)을 달아주는 것 (annotate)`이 되는 겁니다.
그러니까 우리는 $$L_i$$를 $$q_i$$에 대해 업데이트 하려면 아래와 같이 모든 이미지 마다, 두 파라메터를 전부 다 업데이트 해야 하는 겁니다. 
(한 데이터 포인트마다 샘플링을 여러번 하면 이 과정은 더 오래걸리겠죠?)

- use gradient $$ \bigtriangledown_{\mu_i} L_i(p,q_i) $$ and $$ \bigtriangledown_{\sigma_i} L_i(p,q_i) $$
- gradient ascent on $$\mu_i,\sigma_i$$

우리가 지금까지 정의하고 사용하려는 방법론이 클래식한 변분법이며 분명히 작용하는 알고리즘이겠지만, 이는 업데이트해야 할 파라메터가 너무 많다는 단점이 있습니다.

- How many parameters are there? $$\vert \theta \vert + ( \vert \mu_i \vert + \vert \sigma_i \vert ) \times N $$

$$p_\theta(x_i \vert z)$$를 모델링한 신경망의 모델 파라메터 $$\theta$$개수에 각 데이터 포인트 마다 평균, 분산 2개의 파라메터가 추가적으로 있는거죠.  
이는 데이터가 많으면 많을수록 더 다루기 힘들어 질 것입니다.


그렇다면 이를 해결하기 위해서는 어떻게 해야할까요? 
네 맞습니다, $$x_i$$마다 $$q_i$$를 정하지 말고, 이 둘 사이 관계를 매핑해주는 신경망을 하나 더 두는 것이죠.

- intuition : $$q_i(z)$$ should approximate $$p(z \vert x_i)$$ then what if learn network $$q_i (z) = q(z \vert x_i) \approx p(z \vert x_i)$$? 

바로 두 가지 네트워크를 둬서 approximate하는 것이 변분법을 사용하는 생성 모델, VAE의 핵심입니다.

$$q_i (z) = q(z \vert x_i) \approx p(z \vert x_i)$$

![cs285_lec18_variational](/assets/images/ae_to_vae/cs285_lec18_variational.png)
*Fig. $$x \rightarrow z$$로 매핑해주는 Encoder Network, $$z \rightarrow x'$$, 즉 생성을 담당하는 Decoder Network 두 가지를 학습하면 된다.*









### <mark style='background-color: #dcffe4'> Amortized Variational Inference </mark>

이제 우리는 두 가지 네트워크를 가지게 되었죠.

![cs285_lec18_variational](/assets/images/ae_to_vae/cs285_lec18_variational.png)

그렇기 때문에 `ELBO` 수식도 조금 변경해야할 필요가 있습니다.

$$
log p(x_i) \geq \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] + H(q_i)
$$

모든 데이터 포인트 마다 근사 분포를 가지고 있던 일반적인 변분 추론 (Regular Variational Inference)를 $$q_{\phi}$$라는 네트워크 하나로 바꾸면

$$
\begin{aligned}
& log p(x_i) \geq \mathbb{E}_{z \sim q_i(z)} [log p(x_i \vert z) + log p(z)] + H(q_i) & \\
& \geq \mathbb{E}_{z \sim q_{\phi}(z \vert x_i)} [log p(x_i \vert z) + log p(z)] + H(q_{\phi}(z \vert x_i)) &
\end{aligned}
$$

위와 같은 일반화된 수식을 얻을 수 있습니다. 

(주의해야 할 점은 $$p(z)$$는 prior로 (일반적으로 머신러닝 사용되는 prior 개념 맞습니다.) 변하지 않는 분포입니다. 즉 파라메터가 없습니다. 바뀐건 $$q_i$$ 입니다.) 


이로써 `ELBO`가 아래와 같이 새로 정의됐습니다.

$$
L(p_{\theta}(x_i \vert z), q_{\phi}(z \vert x_i)) = \mathbb{E}_{z \sim q_{\phi}(z \vert x_i)} [log p(x_i \vert z) + log p(z)] + H(q_{\phi}(z \vert x_i))
$$

목적 함수가 바뀌었으니 업데이트 하는 training procedure도 바뀌었겠죠?

***

$$
\begin{aligned}

& \text{for each } x_i (\text{ or mini-batch}): & \\
& \quad \text{calculate } \bigtriangledown_{\theta} L(p_{\theta}(x_i \vert z), q_{\phi}(z \vert x_i)): & \\
& \quad \quad \text{sample } z \sim q_{\phi}(z \vert x_i) & \\
& \quad \quad \bigtriangledown_{\theta} L \approx \bigtriangledown_{\theta} log p_{\theta} (x_i \vert z) & \\
& \quad \theta \leftarrow \theta + \alpha \bigtriangledown_{\theta} L & \\
& \quad \phi \leftarrow \phi + \alpha \bigtriangledown_{\phi} L &
 
\end{aligned}
$$

***

(크게 다를 바 없으니 천천히 음미해 보시면 될 것 같습니다.)


자, 이제는 정말 거의 다 왔습니다. 
마지막 문제점 하나만 해결하면 잠재 변수 모델을 학습시킬 수 있는데요,
그것은 바로

- how $$ \phi \leftarrow \phi + \alpha \bigtriangledown_{\phi} L $$ ???
 
입니다.








### <mark style='background-color: #dcffe4'> Reparameterization Trick </mark>

$$
\begin{aligned}

& J(\phi) = \mathbb{E}_{z \sim q_{\phi} (z \vert x_i)} [log p(x_i \vert z) + log p(z)] & \\
& = \mathbb{E}_{z \sim q_{\phi} (z \vert x_i)} [r(x_i,z)] &

\end{aligned}
$$

$$
q_{\phi} (z \vert x) = N(\mu_{\phi}(x), \sigma_{\phi} (x) ) \\
$$

$$
z = \mu_{\phi} (x) + \epsilon \sigma_{\phi} (x)
$$

여기서 $$\epsilon \sim N(0,1)$$는 $$\phi$$와 무관합니다.


$$
\begin{aligned}

& J(\phi) = \mathbb{E}_{z \sim q_{\phi} (z \vert x_i)} [r(x_i,z)] & \\
& = \mathbb{E}_{\epsilon \sim N(0,1)} [r(x_i,\mu_{\phi} (x_i) + \epsilon \sigma_{\phi} (x_i))] &

\end{aligned}
$$


***

$$
\begin{aligned}

& \text{estimating } \bigtriangledown_{\phi} J(\phi) : & \\
& \quad \text{sample } \epsilon_1,\cdots,\epsilon_M \space from \space N(0,1) & \\
& \quad \bigtriangledown_{\phi} J(\phi) \approx \frac{1}{M} \sum_j \bigtriangledown_{\phi} r(x_i,\mu_{\phi} (x_i) + \epsilon \sigma_{\phi} (x_i)) & 

\end{aligned}
$$

***


![cs285_lec18_reparam](/assets/images/ae_to_vae/cs285_lec18_reparam.png)
*Fig.*

![repram](/assets/images/ae_to_vae/repram.png)
*Fig.*



$$
\begin{aligned}

& L_i = \mathbb{E}_{z \sim q_{\phi}(z \vert x_i)} [log p_{\theta} (x_i \vert z) + log p(z)] + H( q_{\phi}(z \vert x_i) ) &  \\

& = \mathbb{E}_{z \sim q_{\phi}(z \vert x_i)} [log p_{\theta} (x_i \vert z)] + \mathbb{E}_{z \sim q_{\phi}(z \vert x_i)} [log p_(z)] + H( q_{\phi}(z \vert x_i) ) &  \\

& = \mathbb{E}_{z \sim q_{\phi}(z \vert x_i)} [log p_{\theta} (x_i \vert z)] - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) & \\

& = \mathbb{E}_{\epsilon \sim N(0,1)} [log p_{\theta} (x_i \vert \mu_{\phi} (x_i) + \epsilon \sigma_{\phi} (x_i) )] - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) & \\

& \approx log p_{\theta} (x_i \vert \mu_{\phi} (x_i) + \epsilon \sigma_{\phi} (x_i) ) - D_{KL} ( q_{\phi} (z \vert x_i ) \parallel p(z) ) & 

\end{aligned}
$$



![ae](/assets/images/ae_to_vae/ae.png)
*Fig. 일반적인 AutoEncoder의 모식도*

![vae2](/assets/images/ae_to_vae/vae2.png)
*Fig. Variational AutoEncoder의 모식도*





![Tutorial on Variational Autoencoders_fig3](/assets/images/ae_to_vae/Tutorial on Variational Autoencoders_fig3.png)
*Fig. VAE in Training Time*

![Tutorial on Variational Autoencoders_fig4](/assets/images/ae_to_vae/Tutorial on Variational Autoencoders_fig4.png){: width="50%"}
*Fig. VAE in Test Time*








### <mark style='background-color: #dcffe4'> VAE </mark>

![cs285_lec18_vae1](/assets/images/ae_to_vae/cs285_lec18_vae1.png)
*Fig.*

![cs285_lec18_vae2](/assets/images/ae_to_vae/cs285_lec18_vae2.png)
*Fig.*

![cs285_lec18_vae3](/assets/images/ae_to_vae/cs285_lec18_vae3.png){: width="60%"}
*Fig.*










### <mark style='background-color: #dcffe4'> VAEs with various type of decoder </mark>

![lee_gaussian_decoder_vae1](/assets/images/ae_to_vae/lee_gaussian_decoder_vae1.png)
*Fig.*

![lee_bernoulli_decoder_vae1](/assets/images/ae_to_vae/lee_bernoulli_decoder_vae1.png)
*Fig.*

![lee_vae_mnist](/assets/images/ae_to_vae/lee_vae_mnist.png)
*Fig.*







### <mark style='background-color: #dcffe4'> Learned Manifold and Results </mark>

![lee_learned_manifold1](/assets/images/ae_to_vae/lee_learned_manifold1.png)
*Fig.*

![lee_learned_manifold2](/assets/images/ae_to_vae/lee_learned_manifold2.png)
*Fig.*



![Tutorial on Variational Autoencoders_fig1](/assets/images/ae_to_vae/Tutorial on Variational Autoencoders_fig1.png)
*Fig.*

![Tutorial on Variational Autoencoders_fig4](/assets/images/ae_to_vae/Tutorial on Variational Autoencoders_fig4.png){: width="50%"}
*Fig.*






## <mark style='background-color: #fff5b1'> Other Deep Genrative Models </mark>

![cs285_lec17_vae2](/assets/images/ae_to_vae/cs285_lec17_vae2.png)
*Fig.*

### <mark style='background-color: #dcffe4'> + Normalizing flow models </mark>

### <mark style='background-color: #dcffe4'> + Generative Adversarial Networks (GAN) </mark>











## <mark style='background-color: #fff5b1'> various version of VAEs  </mark>

### <mark style='background-color: #dcffe4'> Conditional Variational AutoEncoder (CVAE) </mark>

![Tutorial on Variational Autoencoders_fig3](/assets/images/ae_to_vae/Tutorial on Variational Autoencoders_fig3.png)
*Fig. VAE*

![Tutorial on Variational Autoencoders_fig5](/assets/images/ae_to_vae/Tutorial on Variational Autoencoders_fig5.png)
*Fig. Conditional VAE (CVAE)*

### <mark style='background-color: #dcffe4'> Beta - Variational AutoEncoder (Beta-VAE) </mark>






### <mark style='background-color: #dcffe4'> Vector Quantized - Variational AutoEncoder (VQ-VAE) </mark>

![vq_vae](/assets/images/ae_to_vae/vq_vae.png)


![vqvae_slide_example1](/assets/images/ae_to_vae/vqvae_slide_example1.png)

![vqvae_paper_figure](/assets/images/ae_to_vae/vqvae_paper_figure.png){: width="50%"}




![vqvae_slide_ar](/assets/images/ae_to_vae/vqvae_slide_ar.png){: width="60%"}

![vqvae_slide_example2](/assets/images/ae_to_vae/vqvae_slide_example2.png){: width="80%"}
![vqvae_slide_example3](/assets/images/ae_to_vae/vqvae_slide_example3.png){: width="80%"}
![vqvae_slide_example4](/assets/images/ae_to_vae/vqvae_slide_example4.png){: width="80%"}
![vqvae_slide_example5](/assets/images/ae_to_vae/vqvae_slide_example5.png){: width="80%"}



![vqvae_slide_example6](/assets/images/ae_to_vae/vqvae_slide_example6.png){: width="80%"}

![vqvae_slide_wavenet1](/assets/images/ae_to_vae/vqvae_slide_wavenet1.png){: width="80%"}
![vqvae_slide_wavenet2](/assets/images/ae_to_vae/vqvae_slide_wavenet2.png){: width="80%"}
![vqvae_slide_wavenet3](/assets/images/ae_to_vae/vqvae_slide_wavenet3.png){: width="80%"}

![vqvae_slide_example7](/assets/images/ae_to_vae/vqvae_slide_example7.png){: width="80%"}







### <mark style='background-color: #dcffe4'> Temporal Difference - Variational AutoEncoder (TD-VAE) </mark>













## <mark style='background-color: #fff5b1'> References </mark>

- Blogs
  - 1.['from AutoEncoder to beta VAE' form lillog](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)
  - 2.[A Beginner's Guide to Variational Methods: Mean-Field Approximation from Eric Jang](https://blog.evjang.com/2016/08/variational-bayes.html)
- Papers
  - 1.tmp
- Lecture Videos
  - 1.[CS W182 / 282A at UC Berkeley - Designing, Visualizing and Understanding Deep Neural Networks](https://cs182sp21.github.io/)
  - 2.[CS 182 - Lecture 17 - Generative Models](https://www.youtube.com/watch?v=AX5v5med3Rw&list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A&index=53)
  - 3.[CS 182 - Lecture 18 - Latent Variable Models](https://www.youtube.com/watch?v=9KTrUea1apo&list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A&index=55)
  - 4.[CS 182 - Lecture 19 - GANs](https://www.youtube.com/watch?v=39CmbTX1S8M&list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A&index=59)
  - 5.[L4 Latent Variable Models (VAE) -- CS294-158-SP20 Deep Unsupervised Learning -- UC Berkeley from Pieter Abbeel](https://www.youtube.com/watch?v=FMuvUZXMzKM)
  - 6.['오토 인코더의 모든 것 (1~3)' from Hwalseok Lee](https://www.youtube.com/watch?v=o_peo6U7IRM) 
- Other 
  - 1.['On manifolds and autoencoders' from Pascal Vincent](http://videolectures.net/deeplearning2015_vincent_autoencoders/?q=vincent%20autoencoder)


