---
title: (미완) From WaveNet to Parallel-WaveNet
categories: Speech_Recognition
tag: [wavenet]

toc: true
toc_sticky: true
---

---
< 목차 >
{: class="table-of-content"}
* TOC
{:toc}
---


Alphago로 유명한 DeepMind 는 강화학습 뿐만 아니라 [WaveNet](https://deepmind.com/blog/article/wavenet-generative-model-raw-audio)같은 `Wave Generation Architecture`를 개발하여 Google Assistant에도 적용하는 등 다양한 행보를 보여 왔습니다.



Original `WaveNet`의 아이디어는 심플한데요, 학습시 원본 음성 벡터들을 Autoregressive하게 복원하고, 이렇게 학습된 WaveNet에 어떤 벡터를 던져주면 그 음성을 기반으로 쭉 자연스러운 음성을 만들어냅니다. WaveNet은 아무런 조건을 주지 않으면 웅얼거리면서 사람을 흉내내는 듯한 음성을 뱉게되는데, 여기에 우리가 원하는 문장을 조건으로 주고 생성하라고 하면 더욱 자연스러운 음성을 만들어냅니다. 추가적으로 '남자가 말하는 음성', '여자가 말하는 음성', '사투리를 사용해서' 같은 임베딩 정보를 주면 더욱 다양하게 음성을 만들어 낼 수 있습니다.


이러한 특성 때문에 각종 VQ-VAE 같은 Generation task에서 디코더 같은곳에 사용되거나 Tacotron같은 음성 합성 (Text-To-Speech, TTS) 같은 네트워크에서도 back-end에 사용됩니다. 


WaveNet은 하지만 Autoregressive하게 음성을 만들어낸다는 한계 등이 존재하는데, 이를 해결하기 위해 `Parallel-WaveNet` 같은 네트워크가 지속적으로 제안되어 왔습니다.





## <mark style='background-color: #fff5b1'> Wavenet </mark>

### <mark style='background-color: #dcffe4'> Autoregressive Model </mark>

![ar1](/assets/images/wavenet/ar1.png)
*Fig.*

![ar2](/assets/images/wavenet/ar3.png)
*Fig.*

![ar3](/assets/images/wavenet/ar2.png)
*Fig.*


![ar_vs_pixelcnn](/assets/images/wavenet/ar_vs_pixelcnn.png)
*Fig.*

![ar_audio](/assets/images/wavenet/ar_audio.png)
*Fig.*






### <mark style='background-color: #dcffe4'> Autoregressive Model with Dilated Convolution </mark>


![wavenet_paper_figure1](/assets/images/wavenet/wavenet_paper_figure1.png)
*Fig.*

![wavenet_paper_figure2](/assets/images/wavenet/wavenet_paper_figure2.png)
*Fig.*

![heiga_wavenet_ar](/assets/images/wavenet/heiga_wavenet_ar.png)
*Fig.*

![wavenet_additional](/assets/images/wavenet/wavenet_additional.png)
*Fig.*





### <mark style='background-color: #dcffe4'> WaveNet Output Token </mark>

![heiga_continuous](/assets/images/wavenet/heiga_continuous.png)
*Fig.*

![heiga_softmax](/assets/images/wavenet/heiga_softmax.png)
*Fig.*

![wavenet_arch1](/assets/images/wavenet/wavenet_arch1.png)
*Fig.*






### <mark style='background-color: #dcffe4'> WaveNet Architecture </mark>

![wavenet_paper_figure3](/assets/images/wavenet/wavenet_paper_figure3.png)
*Fig.*

![heiga_wavenet_arch1](/assets/images/wavenet/heiga_wavenet_arch1.png)
*Fig.*

![heiga_wavenet_arch2](/assets/images/wavenet/heiga_wavenet_arch2.png)
*Fig.*

![wavenet_overview](/assets/images/wavenet/wavenet_overview.png){: width="60%"}
*Fig.*





### <mark style='background-color: #dcffe4'> Mu-law Quantization </mark>

![wavenet_dist_before](/assets/images/wavenet/wavenet_dist_before.png)
*Fig.*

![wavenet_dist_after](/assets/images/wavenet/wavenet_dist_after.png)
*Fig.*






## <mark style='background-color: #fff5b1'> Parellel Wavenet </mark>

![parallel_wavenet_figure1](/assets/images/wavenet/parallel_wavenet_figure1.png)
*Fig.*






## <mark style='background-color: #fff5b1'> References </mark>

- Blog
  - [Wavenet from Sergei Turukin](https://sergeiturukin.com/2017/03/02/wavenet.html)
  - [WaveNet - A Generative Model for Raw Audio](http://musyoku.github.io/2016/09/18/wavenet-a-generative-model-for-raw-audio/)
  - [Normalizing Flows Tutorial, Part 2: Modern Normalizing Flows from Eric Jang](https://blog.evjang.com/2018/01/nf2.html)
  - [WaveNet: Google Assistant’s Voice Synthesizer. from Janvijay Singh](https://towardsdatascience.com/wavenet-google-assistants-voice-synthesizer-a168e9af13b1)
  - [Flow-based Deep Generative Models from lillog](https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html)
- Paper
  - [WaveNet: A Generative Model for Raw Audio](https://arxiv.org/pdf/1609.03499)
  - [Parallel WaveNet: Fast High-Fidelity Speech Synthesis](https://arxiv.org/pdf/1711.10433)
