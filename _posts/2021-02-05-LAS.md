---
title: Attention Based Seq2Seq for ASR
categories: Speech_Recognition
tag: [tmp]

toc: true
toc_sticky: true
---

- <mark style='background-color: #fff5b1'> Sequence Generation(Modeling) Tasks </mark>

우리가 하고싶은것은 입력 x를 받았을때 가장 그럴듯한(likely) 출력값 y를 뽑아내는 것입니다.

그러기 위해서 당연히 likelihood 혹은 log-likelihood $$p(y \mid x)$$를 최대화 하는 방식으로 학습하게 될겁니다.

이런 Sequence-to-Sequence (Seq2Seq) likelihood를 모델링 하는 여러 방법들 중 이번에 다룰것은 Encoder-Decoder Seq2Seq Model 입니다.

- <mark style='background-color: #dcffe4'> Encoder-Decoder Seq2Seq </mark>

아래의 그림을 볼까요? (제가 그렸는데 못그려도 이해 부탁드립니다 ㅎㅎ)

![seq2seq](https://user-images.githubusercontent.com/48202736/107010821-35ea2180-67da-11eb-8881-bb9287ea49e7.png)
{: style="width: 80%;" class="center"}
*Fig. 1. Vanilla Encoder-Decoder Seq2Seq Network*

그림이 의미하는 바는 다음과 같습니다.

> 1. 입력값이 Encoder에 들어가고 <br> 
> 2. 어떠한 무슨 정보를 디코더에 넘겨줌 <br>
> 3. 디코더가 예측한 hypothesis y값을 뱉음 <br>

뭐 당연히 추론한 $$\hat{y}$$랑 진짜 정답 $$y$$를 비교해서 모델 파라메터를 학습하겠죠. 

이제 이 과정을 순차적으로 다시 생각해볼까요?

![seq2seq2](https://user-images.githubusercontent.com/48202736/107010828-37b3e500-67da-11eb-927a-64fd6251d849.png)
{: style="width: 80%;" class="center"}
```
1. 인코더(일단 RNN 이라고 하겠습니다) 에 입력 값을 넣습니다.*
```

![seq2seq3](https://user-images.githubusercontent.com/48202736/107010829-384c7b80-67da-11eb-972d-1933a7d0532f.png)
{: style="width: 80%;" class="center"}
```
2. RNN 인코더를 쭉 통과한 어떤 벡터가 나온다, 이를 입력 seqeunce에 대한 문맥 정보가 압축된 표현 벡터(Representation Vector)라고 한다
```

![seq2seq4](https://user-images.githubusercontent.com/48202736/107010831-384c7b80-67da-11eb-8ee8-6fdc9a859c03.png)
{: style="width: 90%;" class="center"}
```
3. 디코더에서 '자 이제 출력 sequence를 뽑아낼거다'라는 사인을 의미하는 <s> 토큰과 representation vector를 받아서 첫번째 토큰을 출력한다.
```

![seq2seq5](https://user-images.githubusercontent.com/48202736/107010836-38e51200-67da-11eb-8665-604fbb91df86.png)
{: style="width: 90%;" class="center"}
```
4. 처음 출려된 값을 다음 디코더 입력값에 넣어주고, representation vector또한 디코더 rnn cell 하나를 통과했으니 정보가 업데이트 된다
```

![seq2seq6](https://user-images.githubusercontent.com/48202736/107010838-397da880-67da-11eb-86b4-9bc97f2909e6.png)
```
5. 이렇게 디코더에서 iterative하게 (Auto-Regressive, AR)하게 출력된 토큰들은 각각 앞토큰에 대한 정보가 conditional하게 반영되면서 뽑힌 토큰들이다.
```

![seq2seq7](https://user-images.githubusercontent.com/48202736/107010840-3a163f00-67da-11eb-9e49-932e09f6bd84.png)
```
6. 이를 다 곱하면 likelihood가 된다.
```

![seq2seq8](https://user-images.githubusercontent.com/48202736/107010842-3a163f00-67da-11eb-825d-7e526ceae0d7.png)
```
7. log-likelihood를 최대화 하는것, 다르게 표현하면 여기서는 각 토큰마다 정답과 일일히 분류 문제를 푸는것이라고 볼 수 있는데, 그렇기 때문에 Cross Entropy Loss를 사용해서 Loss를 구한다
```
```
8. 오차 역전파 (Error Back Propagation)을 통해 파라메터를 업데이트 하여 Loss를 최소화 하는 방향으로 최적화한다.
```

- <mark style='background-color: #dcffe4'> Applications </mark>


- <mark style='background-color: #fff5b1'> Listen, Attend and Spell (LAS) </mark>
