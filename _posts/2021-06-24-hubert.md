---
title: (미완) (Paper) Hubert, How Much Can a Bad Teacher Benefit ASR Pre-Training?
categories: Speech_Recognition
tag: [tmp]

toc: true
toc_sticky: true

comments: true
---

asd
---
< 목차 >
{: class="table-of-content"}
* TOC
{:toc}
---






## <mark style='background-color: #fff5b1'> Problem Definition and Contibution Points </mark>



## <mark style='background-color: #fff5b1'> Preliminaries </mark>

### <mark style='background-color: #dcffe4'> Pseudo-Labeling </mark>

`Self-Training`이라고도 알려진 Pseudo-Lbaeling은 unlabeld speech 데이터를 사용하기 위해 적은량의 labeld speech-text pair data $$D_l = \{ (X_j,Y_j) \}_{j=1}^{N_l}$$를 사용해 학습한 Teacher ASR model, $$g$$를 우선 학습하고, 이를 unlabeld data의 label을 만들어내는 용도로 사용하는 겁니다.

### <mark style='background-color: #dcffe4'> Masked Prediction </mark>

## <mark style='background-color: #fff5b1'> Clustering for Unsupervised Pseudo Lebeling </mark>

## <mark style='background-color: #fff5b1'> Pre-Training via Masked Pseudo Label Prediction </mark>


## <mark style='background-color: #fff5b1'> Teacher Ensembling and Iterative Refinement </mark>

## <mark style='background-color: #fff5b1'> Implementation </mark>

## <mark style='background-color: #fff5b1'> Experiments and Results </mark>





## <mark style='background-color: #fff5b1'> Reference </mark>

